---
title: "main"
format: html
editor: visual
---

# Part 1: Evaluation of the Kidney Failure Risk Equation (KFRE) with ALL OF US DATA: North American Equation

## Comparison Between individual classification among methods

```{r}
inrange_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine_albumin.csv")
summary(inrange_person_with_summary$age_precise)
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(gridExtra) # For arranging multiple plots
library(parallel)  # For parallel computing
library(doParallel) # For registering parallel backend

# Step 1: Calculate the differences and averages between eGFR methods
inrange_person_with_summary <- inrange_person_with_summary %>%
  mutate(
    diff_MDRD_ckd_epi_2009 = eGFR_MDRD - eGFR_ckd_epi_2009,
    avg_MDRD_ckd_epi_2009 = (eGFR_MDRD + eGFR_ckd_epi_2009) / 2,
    diff_MDRD_ckd_epi_2021 = eGFR_MDRD - eGFR_ckd_epi_2021,
    avg_MDRD_ckd_epi_2021 = (eGFR_MDRD + eGFR_ckd_epi_2021) / 2,
    diff_ckd_epi_2009_ckd_epi_2021 = eGFR_ckd_epi_2009 - eGFR_ckd_epi_2021,
    avg_ckd_epi_2009_ckd_epi_2021 = (eGFR_ckd_epi_2009 + eGFR_ckd_epi_2021) / 2
  )

# Step 2: Function to create Bland-Altman plots with limits of agreement
create_bland_altman_plot <- function(data, avg_col, diff_col, title) {
  mean_diff <- mean(data[[diff_col]], na.rm = TRUE)
  sd_diff <- sd(data[[diff_col]], na.rm = TRUE)
  upper_limit <- mean_diff + 1.96 * sd_diff
  lower_limit <- mean_diff - 1.96 * sd_diff

  ggplot(data, aes_string(x = avg_col, y = diff_col)) +
    geom_point(alpha = 0.6, size = 1.5) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    geom_hline(yintercept = mean_diff, linetype = "dashed", color = "blue") +
    geom_hline(yintercept = upper_limit, linetype = "dashed", color = "darkgreen") +
    geom_hline(yintercept = lower_limit, linetype = "dashed", color = "darkgreen") +
    labs(
      title = title, 
      x = "Average eGFR (mL/min/1.73 m²)", 
      y = "Difference in eGFR (mL/min/1.73 m²)"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      axis.title = element_text(size = 12),
      axis.text = element_text(size = 10)
    )
}

# Step 3: Function to generate plots for each race
generate_race_plots <- function(race_data, race_label) {
  list(
    create_bland_altman_plot(race_data, "avg_MDRD_ckd_epi_2009", "diff_MDRD_ckd_epi_2009", paste("MDRD vs. CKD-EPI 2009 (", race_label, ")", sep = "")),
    create_bland_altman_plot(race_data, "avg_MDRD_ckd_epi_2021", "diff_MDRD_ckd_epi_2021", paste("MDRD vs. CKD-EPI 2021 (", race_label, ")", sep = "")),
    create_bland_altman_plot(race_data, "avg_ckd_epi_2009_ckd_epi_2021", "diff_ckd_epi_2009_ckd_epi_2021", paste("CKD-EPI 2009 vs. CKD-EPI 2021 (", race_label, ")", sep = ""))
  )
}

# Step 4: Split data by race and generate plots
plot_list <- list()
races <- c("Black or African American", "White", "Asian")
race_labels <- c("Black", "White", "Asian")

for (i in seq_along(races)) {
  race_data <- inrange_person_with_summary %>% filter(race == races[i])
  race_plots <- generate_race_plots(race_data, race_labels[i])
  plot_list <- c(plot_list, race_plots)
}

# Step 5: Arrange the plots in a multi-panel figure
multi_panel_plot <- grid.arrange(grobs = plot_list, ncol = 3)

# Step 6: Save the multi-panel plot as a high-resolution image
ggsave("Bland_Altman_Race_Subgroup_Multi_Panel_Updated.png", multi_panel_plot, dpi = 300, width = 15, height = 10)

# Optionally, save as a PDF for high-quality printing
ggsave("Bland_Altman_Race_Subgroup_Multi_Panel_Updated.pdf", multi_panel_plot, width = 15, height = 10)

# Display the multi-panel plot
print(multi_panel_plot)

```

# Populations for assessment

### CKD

```{r}
library(tidyverse)
library(bigrquery)

# This query represents dataset "followup_cohort_data" for domain "person" and was generated for All of Us Controlled Tier Dataset v7
dataset_87211287_person_sql <- paste("
    SELECT
        person.person_id,
        p_gender_concept.concept_name as gender,
        person.birth_datetime as date_of_birth,
        p_race_concept.concept_name as race,
        p_ethnicity_concept.concept_name as ethnicity,
        p_sex_at_birth_concept.concept_name as sex_at_birth 
    FROM
        `person` person 
    LEFT JOIN
        `concept` p_gender_concept 
            ON person.gender_concept_id = p_gender_concept.concept_id 
    LEFT JOIN
        `concept` p_race_concept 
            ON person.race_concept_id = p_race_concept.concept_id 
    LEFT JOIN
        `concept` p_ethnicity_concept 
            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id 
    LEFT JOIN
        `concept` p_sex_at_birth_concept 
            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  
    WHERE
        person.PERSON_ID IN (SELECT
            distinct person_id  
        FROM
            `cb_search_person` cb_search_person  
        WHERE
            cb_search_person.person_id IN (SELECT
                person_id 
            FROM
                `person` p 
            WHERE
                race_concept_id IN (8527, 8516, 2100000001, 8515, 903096, 2000000008, 45882607, 1177221, 38003615, 8557) ) 
            AND cb_search_person.person_id IN (SELECT
                criteria.person_id 
            FROM
                (SELECT
                    DISTINCT person_id, entry_date, concept_id 
                FROM
                    `cb_search_all_events` 
                WHERE
                    (concept_id IN(SELECT
                        DISTINCT c.concept_id 
                    FROM
                        `cb_criteria` c 
                    JOIN
                        (SELECT
                            CAST(cr.id as string) AS id       
                        FROM
                            `cb_criteria` cr       
                        WHERE
                            concept_id IN (46271022)       
                            AND full_text LIKE '%_rank1]%'      ) a 
                            ON (c.path LIKE CONCAT('%.', a.id, '.%') 
                            OR c.path LIKE CONCAT('%.', a.id) 
                            OR c.path LIKE CONCAT(a.id, '.%') 
                            OR c.path = a.id) 
                    WHERE
                        is_standard = 1 
                        AND is_selectable = 1) 
                    AND is_standard = 1 )) criteria ) 
            AND cb_search_person.person_id NOT IN (SELECT
                criteria.person_id 
            FROM
                (SELECT
                    DISTINCT person_id, entry_date, concept_id 
                FROM
                    `cb_search_all_events` 
                WHERE
                    (concept_id IN(SELECT
                        DISTINCT c.concept_id 
                    FROM
                        `cb_criteria` c 
                    JOIN
                        (SELECT
                            CAST(cr.id as string) AS id       
                        FROM
                            `cb_criteria` cr       
                        WHERE
                            concept_id IN (440508)       
                            AND full_text LIKE '%_rank1]%'      ) a 
                            ON (c.path LIKE CONCAT('%.', a.id, '.%') 
                            OR c.path LIKE CONCAT('%.', a.id) 
                            OR c.path LIKE CONCAT(a.id, '.%') 
                            OR c.path = a.id) 
                    WHERE
                        is_standard = 1 
                        AND is_selectable = 1) 
                    AND is_standard = 1 )) criteria ) 
            AND cb_search_person.person_id NOT IN (SELECT
                person_id 
            FROM
                `person` p 
            WHERE
                race_concept_id IN (2100000001, 903096, 2000000008, 45882607, 1177221, 38003615, 8557) ) )", sep="")

# Formulate a Cloud Storage destination path for the data exported from BigQuery.
# NOTE: By default data exported multiple times on the same day will overwrite older copies.
#       But data exported on a different days will write to a new location so that historical
#       copies can be kept as the dataset definition is changed.
person_87211287_path <- file.path(
  Sys.getenv("WORKSPACE_BUCKET"),
  "bq_exports",
  Sys.getenv("OWNER_EMAIL"),
  strftime(lubridate::now(), "%Y%m%d"),  # Comment out this line if you want the export to always overwrite.
  "person_87211287",
  "person_87211287_*.csv")
message(str_glue('The data will be written to {person_87211287_path}. Use this path when reading ',
                 'the data into your notebooks in the future.'))

# Perform the query and export the dataset to Cloud Storage as CSV files.
# NOTE: You only need to run `bq_table_save` once. After that, you can
#       just read data from the CSVs in Cloud Storage.
bq_table_save(
  bq_dataset_query(Sys.getenv("WORKSPACE_CDR"), dataset_87211287_person_sql, billing = Sys.getenv("GOOGLE_PROJECT")),
  person_87211287_path,
  destination_format = "CSV")


# Read the data directly from Cloud Storage into memory.
# NOTE: Alternatively you can `gsutil -m cp {person_87211287_path}` to copy these files
#       to the Jupyter disk.
read_bq_export_from_workspace_bucket <- function(export_path) {
  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())
  bind_rows(
    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),
        function(csv) {
          message(str_glue('Loading {csv}.'))
          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)
          if (is.null(col_types)) {
            col_types <- spec(chunk)
          }
          chunk
        }))
}
dataset_87211287_person_df <- read_bq_export_from_workspace_bucket(person_87211287_path)

dim(dataset_87211287_person_df)

head(dataset_87211287_person_df, 5)

ckd_cohort <- dataset_87211287_person_df
```

### Diabetic

```{r}
library(tidyverse)
library(bigrquery)

# This query represents dataset "followup_cohort_data" for domain "person" and was generated for All of Us Controlled Tier Dataset v7
dataset_58833992_person_sql <- paste("
    SELECT
        person.person_id,
        p_gender_concept.concept_name as gender,
        person.birth_datetime as date_of_birth,
        p_race_concept.concept_name as race,
        p_ethnicity_concept.concept_name as ethnicity,
        p_sex_at_birth_concept.concept_name as sex_at_birth 
    FROM
        `person` person 
    LEFT JOIN
        `concept` p_gender_concept 
            ON person.gender_concept_id = p_gender_concept.concept_id 
    LEFT JOIN
        `concept` p_race_concept 
            ON person.race_concept_id = p_race_concept.concept_id 
    LEFT JOIN
        `concept` p_ethnicity_concept 
            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id 
    LEFT JOIN
        `concept` p_sex_at_birth_concept 
            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  
    WHERE
        person.PERSON_ID IN (SELECT
            distinct person_id  
        FROM
            `cb_search_person` cb_search_person  
        WHERE
            cb_search_person.person_id IN (SELECT
                person_id 
            FROM
                `person` p 
            WHERE
                race_concept_id IN (8527, 8516, 2100000001, 8515, 903096, 2000000008, 45882607, 1177221, 38003615, 8557) ) 
            AND cb_search_person.person_id IN (SELECT
                criteria.person_id 
            FROM
                (SELECT
                    DISTINCT person_id, entry_date, concept_id 
                FROM
                    `cb_search_all_events` 
                WHERE
                    (concept_id IN(SELECT
                        DISTINCT c.concept_id 
                    FROM
                        `cb_criteria` c 
                    JOIN
                        (SELECT
                            CAST(cr.id as string) AS id       
                        FROM
                            `cb_criteria` cr       
                        WHERE
                            concept_id IN (201820)       
                            AND full_text LIKE '%_rank1]%'      ) a 
                            ON (c.path LIKE CONCAT('%.', a.id, '.%') 
                            OR c.path LIKE CONCAT('%.', a.id) 
                            OR c.path LIKE CONCAT(a.id, '.%') 
                            OR c.path = a.id) 
                    WHERE
                        is_standard = 1 
                        AND is_selectable = 1) 
                    AND is_standard = 1 )) criteria ) 
            AND cb_search_person.person_id NOT IN (SELECT
                criteria.person_id 
            FROM
                (SELECT
                    DISTINCT person_id, entry_date, concept_id 
                FROM
                    `cb_search_all_events` 
                WHERE
                    (concept_id IN(SELECT
                        DISTINCT c.concept_id 
                    FROM
                        `cb_criteria` c 
                    JOIN
                        (SELECT
                            CAST(cr.id as string) AS id       
                        FROM
                            `cb_criteria` cr       
                        WHERE
                            concept_id IN (440508)       
                            AND full_text LIKE '%_rank1]%'      ) a 
                            ON (c.path LIKE CONCAT('%.', a.id, '.%') 
                            OR c.path LIKE CONCAT('%.', a.id) 
                            OR c.path LIKE CONCAT(a.id, '.%') 
                            OR c.path = a.id) 
                    WHERE
                        is_standard = 1 
                        AND is_selectable = 1) 
                    AND is_standard = 1 )) criteria ) 
            AND cb_search_person.person_id NOT IN (SELECT
                person_id 
            FROM
                `person` p 
            WHERE
                race_concept_id IN (2100000001, 903096, 2000000008, 45882607, 1177221, 38003615, 8557) ) )", sep="")

# Formulate a Cloud Storage destination path for the data exported from BigQuery.
# NOTE: By default data exported multiple times on the same day will overwrite older copies.
#       But data exported on a different days will write to a new location so that historical
#       copies can be kept as the dataset definition is changed.
person_58833992_path <- file.path(
  Sys.getenv("WORKSPACE_BUCKET"),
  "bq_exports",
  Sys.getenv("OWNER_EMAIL"),
  strftime(lubridate::now(), "%Y%m%d"),  # Comment out this line if you want the export to always overwrite.
  "person_58833992",
  "person_58833992_*.csv")
message(str_glue('The data will be written to {person_58833992_path}. Use this path when reading ',
                 'the data into your notebooks in the future.'))

# Perform the query and export the dataset to Cloud Storage as CSV files.
# NOTE: You only need to run `bq_table_save` once. After that, you can
#       just read data from the CSVs in Cloud Storage.
bq_table_save(
  bq_dataset_query(Sys.getenv("WORKSPACE_CDR"), dataset_58833992_person_sql, billing = Sys.getenv("GOOGLE_PROJECT")),
  person_58833992_path,
  destination_format = "CSV")


# Read the data directly from Cloud Storage into memory.
# NOTE: Alternatively you can `gsutil -m cp {person_58833992_path}` to copy these files
#       to the Jupyter disk.
read_bq_export_from_workspace_bucket <- function(export_path) {
  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())
  bind_rows(
    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),
        function(csv) {
          message(str_glue('Loading {csv}.'))
          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)
          if (is.null(col_types)) {
            col_types <- spec(chunk)
          }
          chunk
        }))
}
dataset_58833992_person_df <- read_bq_export_from_workspace_bucket(person_58833992_path)

dim(dataset_58833992_person_df)

head(dataset_58833992_person_df, 5)

diabetic_cohort <- dataset_58833992_person_df
```

### Hypertensive

```{r}
library(tidyverse)
library(bigrquery)

# This query represents dataset "followup_cohort_data" for domain "person" and was generated for All of Us Controlled Tier Dataset v7
dataset_93359157_person_sql <- paste("
    SELECT
        person.person_id,
        p_gender_concept.concept_name as gender,
        person.birth_datetime as date_of_birth,
        p_race_concept.concept_name as race,
        p_ethnicity_concept.concept_name as ethnicity,
        p_sex_at_birth_concept.concept_name as sex_at_birth 
    FROM
        `person` person 
    LEFT JOIN
        `concept` p_gender_concept 
            ON person.gender_concept_id = p_gender_concept.concept_id 
    LEFT JOIN
        `concept` p_race_concept 
            ON person.race_concept_id = p_race_concept.concept_id 
    LEFT JOIN
        `concept` p_ethnicity_concept 
            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id 
    LEFT JOIN
        `concept` p_sex_at_birth_concept 
            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  
    WHERE
        person.PERSON_ID IN (SELECT
            distinct person_id  
        FROM
            `cb_search_person` cb_search_person  
        WHERE
            cb_search_person.person_id IN (SELECT
                person_id 
            FROM
                `person` p 
            WHERE
                race_concept_id IN (8527, 8516, 2100000001, 8515, 903096, 2000000008, 45882607, 1177221, 38003615, 8557) ) 
            AND cb_search_person.person_id IN (SELECT
                criteria.person_id 
            FROM
                (SELECT
                    DISTINCT person_id, entry_date, concept_id 
                FROM
                    `cb_search_all_events` 
                WHERE
                    (concept_id IN(SELECT
                        DISTINCT c.concept_id 
                    FROM
                        `cb_criteria` c 
                    JOIN
                        (SELECT
                            CAST(cr.id as string) AS id       
                        FROM
                            `cb_criteria` cr       
                        WHERE
                            concept_id IN (316866)       
                            AND full_text LIKE '%_rank1]%'      ) a 
                            ON (c.path LIKE CONCAT('%.', a.id, '.%') 
                            OR c.path LIKE CONCAT('%.', a.id) 
                            OR c.path LIKE CONCAT(a.id, '.%') 
                            OR c.path = a.id) 
                    WHERE
                        is_standard = 1 
                        AND is_selectable = 1) 
                    AND is_standard = 1 )) criteria ) 
            AND cb_search_person.person_id NOT IN (SELECT
                criteria.person_id 
            FROM
                (SELECT
                    DISTINCT person_id, entry_date, concept_id 
                FROM
                    `cb_search_all_events` 
                WHERE
                    (concept_id IN(SELECT
                        DISTINCT c.concept_id 
                    FROM
                        `cb_criteria` c 
                    JOIN
                        (SELECT
                            CAST(cr.id as string) AS id       
                        FROM
                            `cb_criteria` cr       
                        WHERE
                            concept_id IN (440508)       
                            AND full_text LIKE '%_rank1]%'      ) a 
                            ON (c.path LIKE CONCAT('%.', a.id, '.%') 
                            OR c.path LIKE CONCAT('%.', a.id) 
                            OR c.path LIKE CONCAT(a.id, '.%') 
                            OR c.path = a.id) 
                    WHERE
                        is_standard = 1 
                        AND is_selectable = 1) 
                    AND is_standard = 1 )) criteria ) 
            AND cb_search_person.person_id NOT IN (SELECT
                person_id 
            FROM
                `person` p 
            WHERE
                race_concept_id IN (2100000001, 903096, 2000000008, 45882607, 1177221, 38003615, 8557) ) )", sep="")

# Formulate a Cloud Storage destination path for the data exported from BigQuery.
# NOTE: By default data exported multiple times on the same day will overwrite older copies.
#       But data exported on a different days will write to a new location so that historical
#       copies can be kept as the dataset definition is changed.
person_93359157_path <- file.path(
  Sys.getenv("WORKSPACE_BUCKET"),
  "bq_exports",
  Sys.getenv("OWNER_EMAIL"),
  strftime(lubridate::now(), "%Y%m%d"),  # Comment out this line if you want the export to always overwrite.
  "person_93359157",
  "person_93359157_*.csv")
message(str_glue('The data will be written to {person_93359157_path}. Use this path when reading ',
                 'the data into your notebooks in the future.'))

# Perform the query and export the dataset to Cloud Storage as CSV files.
# NOTE: You only need to run `bq_table_save` once. After that, you can
#       just read data from the CSVs in Cloud Storage.
bq_table_save(
  bq_dataset_query(Sys.getenv("WORKSPACE_CDR"), dataset_93359157_person_sql, billing = Sys.getenv("GOOGLE_PROJECT")),
  person_93359157_path,
  destination_format = "CSV")


# Read the data directly from Cloud Storage into memory.
# NOTE: Alternatively you can `gsutil -m cp {person_93359157_path}` to copy these files
#       to the Jupyter disk.
read_bq_export_from_workspace_bucket <- function(export_path) {
  col_types <- cols(gender = col_character(), race = col_character(), ethnicity = col_character(), sex_at_birth = col_character())
  bind_rows(
    map(system2('gsutil', args = c('ls', export_path), stdout = TRUE, stderr = TRUE),
        function(csv) {
          message(str_glue('Loading {csv}.'))
          chunk <- read_csv(pipe(str_glue('gsutil cat {csv}')), col_types = col_types, show_col_types = FALSE)
          if (is.null(col_types)) {
            col_types <- spec(chunk)
          }
          chunk
        }))
}
dataset_93359157_person_df <- read_bq_export_from_workspace_bucket(person_93359157_path)

dim(dataset_93359157_person_df)

head(dataset_93359157_person_df, 5)

hypertensive_cohort <- dataset_93359157_person_df
```

# MDRD Population

```{r}
# Install doParallel package if it's not installed
# install.packages("doParallel")

# Load the parallel processing libraries
library(doParallel)

# Set up parallel backend to use multiple processors
cores <- detectCores() - 1  # Detect the number of cores and use all but one
cl <- makeCluster(cores)
registerDoParallel(cl)

# Load necessary libraries
library(dplyr)
library(survival)

# Load dataset
inrange_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine_albumin.csv")

# # Define a plausible range for eGFR and Albumin/Creatinine based on clinical thresholds for eGFR ≤ 60
# plausible_eGFR_min <- 0
# plausible_eGFR_max <- 60  # Kidney disease defined as eGFR < 60 mL/min/1.73 m²
# #
# plausible_acr_min <- 0
# plausible_acr_max <- 3000
# albuminuria_cutoff <- 10

# Step 1: Select relevant columns and rename Albumin_Creatinine for consistency
person_filtered_KFRE <- inrange_person_with_summary %>%
  select(
    person_id,
    sex_at_birth,
    eGFR_MDRD,
    Albumin_Creatinine = `Albumin.Creatinine`,
    age_precise,
    race,
    disease_status,
    time_to_event
    )

# Step 2: Data preprocessing and filtering based on the combination of eGFR and ACR for low-risk group
person_filtered_KFRE <- person_filtered_KFRE %>%
  mutate(
    event = disease_status
  ) %>%

  # Log-transform Albumin/Creatinine ratio (ACR)
  mutate(logACR = log(Albumin_Creatinine)) %>%
  # Ensure complete cases (remove rows with missing data)
  filter(complete.cases(.))


# Filter out rows with non-NA time_to_event values
case_control_time_to_event_counts <- person_filtered_KFRE %>%
  filter(!is.na(time_to_event)) %>%  # Keep only rows with non-NA time_to_event
  group_by(disease_status) %>%  # Assuming "disease_status" column indicates cases and controls
  summarise(count = n())  # Count the number of rows in each group

# Print the result
print("Number of cases and controls with non-NA time_to_event values:")
print(case_control_time_to_event_counts)


# Step 3: Verify summary statistics for eGFR and Albumin/Creatinine
summary(person_filtered_KFRE$eGFR_value)
summary(person_filtered_KFRE$Albumin_Creatinine)

# Check how many records are retained after filtering
cat("Number of records after filtering:", nrow(person_filtered_KFRE), "\n")

# Perform a complete case analysis
initial_row_count <- nrow(person_filtered_KFRE)

complete_cases <- person_filtered_KFRE %>%
  filter(complete.cases(.))

final_row_count <- nrow(complete_cases)

# Check if any rows have been removed
rows_removed <- initial_row_count - final_row_count

if (rows_removed > 0) {
  cat(rows_removed, "rows have been removed during the complete case analysis.\n")
} else {
  cat("No rows have been removed during the complete case analysis.\n")
}

# Report the number of complete cases
num_complete_cases <- nrow(complete_cases)
cat("Number of complete cases:", num_complete_cases, "\n")

# Remove any rows with NA in time_to_event or disease_status
complete_cases <- complete_cases %>%
  filter(!is.na(time_to_event) & !is.na(disease_status))

# Check the event distribution
cat("Event distribution (disease_status):\n")
print(table(complete_cases$disease_status))

# Step 4: Define the formula for calculating βsum (log hazard)
calculate_beta_sum <- function(age, sex, eGFR, logACR) {
  (-0.2201 * (age / 10 - 7.036)) +
  (0.2467 * (ifelse(sex == "Male", 1, 0) - 0.5642)) -
  (0.5567 * (eGFR / 5 - 7.222)) +
  (0.4510 * (logACR - 5.137))
}

# Apply the formula to calculate βsum
complete_cases <- complete_cases %>%
  mutate(beta_sum = calculate_beta_sum(age_precise, sex_at_birth, eGFR_MDRD, logACR))

# Remove any rows with infinite or NA beta_sum
complete_cases <- complete_cases %>%
  filter(is.finite(beta_sum) & !is.na(beta_sum))

# Step 5: Calculate the risk for two and five years using the updated formulas
complete_cases <- complete_cases %>%
  mutate(
    risk_2_years = 100 * (1 - 0.975^exp(beta_sum)),  # Two-Year Risk calculation
    risk_5_years = 100 * (1 - 0.9240^exp(beta_sum))  # Five-Year Risk calculation
  )

# Save the data before filtering
before_filtering <- complete_cases

# Step 6: Apply the filtering to create consistent_data
consistent_data <- complete_cases %>%
  filter(!is.na(risk_5_years) & !is.na(risk_2_years))

# Step 7: Define and create the 2-year and 5-year outcomes based on disease_status and time_to_event
consistent_data <- consistent_data %>%
  mutate(
    outcome_2_years = ifelse(disease_status == 1 & time_to_event <= 2 * 365.25, 1, 0),
    outcome_5_years = ifelse(disease_status == 1 & time_to_event <= 5 * 365.25, 1, 0)
  )

# Find the rows that were removed by comparing before and after datasets
removed_rows <- anti_join(before_filtering, consistent_data, by = "person_id")

# Print the removed rows
if (nrow(removed_rows) > 0) {
  cat("Rows that were removed during filtering:\n")
  print(removed_rows)
} else {
  cat("No rows were removed during filtering.\n")
}

# Step 8: Verify the risk values
summary(consistent_data$risk_5_years)
summary(consistent_data$risk_2_years)

# Count the number of person_id entries with event == 1 and event == 0
event_count <- consistent_data %>%
  group_by(event) %>%
  summarise(count = n_distinct(person_id))

# Print the results
cat("Number of person_id with event == 1:", event_count$count[event_count$event == 1], "\n")
cat("Number of person_id with event == 0:", event_count$count[event_count$event == 0], "\n")

# Check the event distribution for the 2-year and 5-year outcomes
cat("\n2-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_2_years))

cat("\n5-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_5_years))


# Evaluation
# Load necessary libraries
library(dplyr)
library(pROC)
library(survival)
library(foreach)
library(doParallel)
library(ggplot2)

# Function to calculate metrics with bootstrapping and specificity adjustment
calculate_metrics_with_bootstrap <- function(data, risk_col, outcome_col, time_col, time_limit, n_bootstrap = 1000) {
  
  # Record the start time
  start_time <- Sys.time()
  
  # Apply censoring: keep all data but treat events beyond the time limit as censored
  data_filtered <- data %>%
    mutate(
      censored_time = pmin(!!sym(time_col), time_limit * 365),
      event_status = ifelse(!!sym(outcome_col) == 1 & !!sym(time_col) <= time_limit * 365, 1, 0)
    )
  
  # Filter out rows with missing or invalid data
  data_filtered <- data_filtered %>%
    filter(!is.na(!!sym(risk_col)) & !is.na(event_status) & !is.na(censored_time))
  
  # If no events or no controls exist in the data, return NA
  if (length(unique(data_filtered$event_status)) < 2) {
    return(list(
      AUC = NA, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Not applicable", Cases = NA, Controls = NA
    ))
  }
  
  # Calculate ROC and AUC
  roc_curve <- roc(data_filtered$event_status, data_filtered[[risk_col]], levels = c(0, 1), direction = "<")
  auc_value <- as.numeric(auc(roc_curve))
  
  # Try to find the cutoff for specificity target 0.9
  cutoff_method <- "Specificity 0.9"
  optimal_cutoff <- tryCatch(
    {
      coords(roc_curve, x = 0.9, input = "specificity", ret = "threshold", transpose = TRUE)[1]
    },
    error = function(e) {
      NA
    }
  )
  
  # If the cutoff for specificity 0.9 is NA, try specificity 0.8
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Specificity 0.8"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = 0.8, input = "specificity", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the cutoff for specificity 0.8 is also NA, use the optimal cutoff
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Optimal Cutoff"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = "best", best.method = "closest.topleft", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the optimal_cutoff is not valid, return NA for metrics
  if (is.na(optimal_cutoff)) {
    return(list(
      AUC = auc_value, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Failed", Cases = sum(data_filtered$event_status == 1),
      Controls = sum(data_filtered$event_status == 0)
    ))
  }

  # Calculate predictions based on the new cutoff
  pred_class <- ifelse(data_filtered[[risk_col]] >= optimal_cutoff, 1, 0)

  # Calculate confusion matrix statistics based on the new cutoff
  confusion_mat <- table(Predicted = pred_class, Actual = data_filtered$event_status)

  # If confusion matrix is not 2x2, set metrics to NA
  if (!all(c(0, 1) %in% rownames(confusion_mat)) || !all(c(0, 1) %in% colnames(confusion_mat))) {
    sensitivity <- NA
    specificity <- NA
    ppv <- NA
    npv <- NA
  } else {
    sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
    specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])
    ppv <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
    npv <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  }

  # Bootstrapping AUC and C-statistic for confidence intervals
  auc_values <- numeric(n_bootstrap)
  c_stat_values <- numeric(n_bootstrap)

  bootstrapped_results <- foreach(i = 1:n_bootstrap, .combine = rbind, .packages = c("pROC", "survival")) %dopar% {
    bootstrap_sample <- data_filtered[sample(1:nrow(data_filtered), replace = TRUE), ]

    if (length(unique(bootstrap_sample$event_status)) < 2) {
      return(c(NA, NA))
    }

    roc_curve <- roc(bootstrap_sample$event_status, bootstrap_sample[[risk_col]])
    auc_val <- as.numeric(auc(roc_curve))

    cox_model_boot <- coxph(Surv(bootstrap_sample$censored_time, bootstrap_sample$event_status) ~ bootstrap_sample[[risk_col]], data = bootstrap_sample)
    c_stat_val <- as.numeric(summary(cox_model_boot)$concordance[1])

    return(c(auc_val, c_stat_val))
  }

  auc_values <- bootstrapped_results[, 1]
  c_stat_values <- bootstrapped_results[, 2]

  # Calculate 95% confidence intervals
  auc_ci <- quantile(auc_values[!is.na(auc_values)], probs = c(0.025, 0.975), na.rm = TRUE)
  c_stat_ci <- quantile(c_stat_values[!is.na(c_stat_values)], probs = c(0.025, 0.975), na.rm = TRUE)

  # Calculate Harrell's C-statistic for the full dataset
  cox_model <- coxph(Surv(censored_time, event_status) ~ data_filtered[[risk_col]], data = data_filtered)
  c_stat <- as.numeric(summary(cox_model)$concordance[1])

  # Record the end time
  end_time <- Sys.time()
  total_runtime <- end_time - start_time

  message("Number of bootstrap iterations run:", n_bootstrap)
  message("Total runtime for the bootstrapping process:", total_runtime, "seconds")

  # Return the metrics
  return(list(
    AUC = auc_value, AUC_Lower = auc_ci[1], AUC_Upper = auc_ci[2], 
    C_Statistic = c_stat, C_Stat_Lower = c_stat_ci[1], C_Stat_Upper = c_stat_ci[2],
    Sensitivity = sensitivity, Specificity = specificity, PPV = ppv,
    NPV = npv, Optimal_Cutoff = optimal_cutoff, Cutoff_Method = cutoff_method,
    Cases = sum(data_filtered$event_status == 1), Controls = sum(data_filtered$event_status == 0)
  ))
}

# Function to summarize metrics for each racial group
summarize_risk_metrics <- function(data, race_label, time_limit, n_bootstrap = 1000) {
  metrics <- calculate_metrics_with_bootstrap(data, paste0("risk_", time_limit, "_years"), paste0("outcome_", time_limit, "_years"), "time_to_event", time_limit, n_bootstrap)
  
  return(data.frame(
    Race = race_label,
    Time_Horizon = paste0(time_limit, " Years"),
    AUC = metrics$AUC,
    AUC_Lower_CI = metrics$AUC_Lower,
    AUC_Upper_CI = metrics$AUC_Upper,
    Harrell_C_Statistic = metrics$C_Statistic,
    C_Stat_Lower_CI = metrics$C_Stat_Lower,
    C_Stat_Upper_CI = metrics$C_Stat_Upper,
    Sensitivity = metrics$Sensitivity,
    Specificity = metrics$Specificity,
    PPV = metrics$PPV,
    NPV = metrics$NPV,
    Optimal_Cutoff = metrics$Optimal_Cutoff,
    Cutoff_Method = metrics$Cutoff_Method,
    Cases = metrics$Cases,
    Controls = metrics$Controls
  ))
}

# Evaluate metrics for each racial group and time horizon
results_all_2yr <- summarize_risk_metrics(consistent_data, "All Races", 2, n_bootstrap = 1000)
results_all_5yr <- summarize_risk_metrics(consistent_data, "All Races", 5, n_bootstrap = 1000)
results_black_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 2, n_bootstrap = 1000)
results_black_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 5, n_bootstrap = 1000)
results_white_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 2, n_bootstrap = 1000)
results_white_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 5, n_bootstrap = 1000)
results_asian_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 2, n_bootstrap = 1000)
results_asian_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 5, n_bootstrap = 1000)

# Combine results including "All Races" for the final table
final_results <- bind_rows(
  results_all_2yr, results_all_5yr,
  results_black_2yr, results_black_5yr,
  results_white_2yr, results_white_5yr,
  results_asian_2yr, results_asian_5yr
)

# Exclude "All Races" for the forest plot
final_results_filtered_MDRD <- final_results %>%
  filter(Race != "All Races")

# Display the final results table including "All Races"
print(final_results)

# Function to plot forest plot for metrics
plot_forest <- function(results_df, metric, lower_ci, upper_ci, title, reference_line) {
  ggplot(results_df, aes_string(x = metric, y = "Race")) +
    geom_point(size = 3, shape = 16, color = "blue") +  # Metric point estimates
    geom_errorbarh(aes_string(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  # 95% CI
    geom_vline(xintercept = reference_line, linetype = "dashed", color = "red") +  # Reference line
    facet_wrap(~ Time_Horizon, scales = "free_y") +  # Separate panels for each time horizon
    labs(
      title = title,
      x = metric,
      y = "Race"
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 14, face = "bold"),
      axis.text.x = element_text(size = 14),
      strip.text = element_text(size = 23, face = "bold"),
      panel.spacing = unit(1, "lines"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
    )
}

# Plot the forest plots for AUC and Harrell's C-statistic using the filtered data
forest_plot_auc <- plot_forest(final_results_filtered_MDRD, "AUC", "AUC_Lower_CI", "AUC_Upper_CI", "", reference_line = 0.5)
forest_plot_cstat <- plot_forest(final_results_filtered_MDRD, "Harrell_C_Statistic", "C_Stat_Lower_CI", "C_Stat_Upper_CI", "", reference_line = 0.5)

# Display the forest plots
print(forest_plot_auc)
print(forest_plot_cstat)

# Save the AUC forest plot
ggsave("MDRD_VHR_forest_plot_auc_filtered.png", plot = forest_plot_auc, width = 10, height = 8, dpi = 300)

# Save the Harrell's C-statistic forest plot
ggsave("MDRD_VHR_forest_plot_cstat_filtered.png", plot = forest_plot_cstat, width = 10, height = 8, dpi = 300)

# Stop the parallel backend after use
stopCluster(cl)
```

# CKD-EPI 2009 Population

```{r}
# Install doParallel package if it's not installed
# install.packages("doParallel")

# Load the parallel processing libraries
library(doParallel)

# Set up parallel backend to use multiple processors
cores <- detectCores() - 1  # Detect the number of cores and use all but one
cl <- makeCluster(cores)
registerDoParallel(cl)

# Load necessary libraries
library(dplyr)
library(survival)

# Load dataset
inrange_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine_albumin.csv")

# # Define a plausible range for eGFR and Albumin/Creatinine based on clinical thresholds for eGFR ≤ 60
# plausible_eGFR_min <- 0
# plausible_eGFR_max <- 60
# plausible_acr_min <- 0
# plausible_acr_max <- 3000
# albuminuria_cutoff <- 10

# Step 1: Select relevant columns and rename Albumin_Creatinine for consistency
person_filtered_KFRE <- inrange_person_with_summary %>%
  select(
    person_id,
    sex_at_birth,
    eGFR_ckd_epi_2009,
    Albumin_Creatinine = `Albumin.Creatinine`,
    age_precise,
    race,
    disease_status,
    time_to_event
  )


# Step 2: Data preprocessing and filtering based on the combination of eGFR and ACR for low-risk group
person_filtered_KFRE <- person_filtered_KFRE %>%
  mutate(
    event = disease_status
  ) %>%

  # Log-transform Albumin/Creatinine ratio (ACR)
  mutate(logACR = log(Albumin_Creatinine)) %>%
  # Ensure complete cases (remove rows with missing data)
  filter(complete.cases(.))


# Filter out rows with non-NA time_to_event values
case_control_time_to_event_counts <- person_filtered_KFRE %>%
  filter(!is.na(time_to_event)) %>%  # Keep only rows with non-NA time_to_event
  group_by(disease_status) %>%  # Assuming "disease_status" column indicates cases and controls
  summarise(count = n())  # Count the number of rows in each group

# Print the result
print("Number of cases and controls with non-NA time_to_event values:")
print(case_control_time_to_event_counts)


# Step 3: Verify summary statistics for eGFR and Albumin/Creatinine
summary(person_filtered_KFRE$eGFR_value)
summary(person_filtered_KFRE$Albumin_Creatinine)

# Check how many records are retained after filtering
cat("Number of records after filtering:", nrow(person_filtered_KFRE), "\n")

# Perform a complete case analysis
initial_row_count <- nrow(person_filtered_KFRE)

complete_cases <- person_filtered_KFRE %>%
  filter(complete.cases(.))

final_row_count <- nrow(complete_cases)

# Check if any rows have been removed
rows_removed <- initial_row_count - final_row_count

if (rows_removed > 0) {
  cat(rows_removed, "rows have been removed during the complete case analysis.\n")
} else {
  cat("No rows have been removed during the complete case analysis.\n")
}

# Report the number of complete cases
num_complete_cases <- nrow(complete_cases)
cat("Number of complete cases:", num_complete_cases, "\n")

# Remove any rows with NA in time_to_event or disease_status
complete_cases <- complete_cases %>%
  filter(!is.na(time_to_event) & !is.na(disease_status))

# Check the event distribution
cat("Event distribution (disease_status):\n")
print(table(complete_cases$disease_status))

# Step 4: Define the formula for calculating βsum (log hazard)
calculate_beta_sum <- function(age, sex, eGFR, logACR) {
  (-0.2201 * (age / 10 - 7.036)) +
  (0.2467 * (ifelse(sex == "Male", 1, 0) - 0.5642)) -
  (0.5567 * (eGFR / 5 - 7.222)) +
  (0.4510 * (logACR - 5.137))
}

# Apply the formula to calculate βsum
complete_cases <- complete_cases %>%
  mutate(beta_sum = calculate_beta_sum(age_precise, sex_at_birth, eGFR_ckd_epi_2009, logACR))

# Remove any rows with infinite or NA beta_sum
complete_cases <- complete_cases %>%
  filter(is.finite(beta_sum) & !is.na(beta_sum))

# Step 5: Calculate the risk for two and five years using the updated formulas
complete_cases <- complete_cases %>%
  mutate(
    risk_2_years = 100 * (1 - 0.975^exp(beta_sum)),  # Two-Year Risk calculation
    risk_5_years = 100 * (1 - 0.9240^exp(beta_sum))  # Five-Year Risk calculation
  )

# Save the data before filtering
before_filtering <- complete_cases

# Step 6: Apply the filtering to create consistent_data
consistent_data <- complete_cases %>%
  filter(!is.na(risk_5_years) & !is.na(risk_2_years))

# Step 7: Define and create the 2-year and 5-year outcomes based on disease_status and time_to_event
consistent_data <- consistent_data %>%
  mutate(
    outcome_2_years = ifelse(disease_status == 1 & time_to_event <= 2 * 365.25, 1, 0),
    outcome_5_years = ifelse(disease_status == 1 & time_to_event <= 5 * 365.25, 1, 0)
  )

# Find the rows that were removed by comparing before and after datasets
removed_rows <- anti_join(before_filtering, consistent_data, by = "person_id")

# Print the removed rows
if (nrow(removed_rows) > 0) {
  cat("Rows that were removed during filtering:\n")
  print(removed_rows)
} else {
  cat("No rows were removed during filtering.\n")
}

# Step 8: Verify the risk values
summary(consistent_data$risk_5_years)
summary(consistent_data$risk_2_years)

# Count the number of person_id entries with event == 1 and event == 0
event_count <- consistent_data %>%
  group_by(event) %>%
  summarise(count = n_distinct(person_id))

# Print the results
cat("Number of person_id with event == 1:", event_count$count[event_count$event == 1], "\n")
cat("Number of person_id with event == 0:", event_count$count[event_count$event == 0], "\n")

# Check the event distribution for the 2-year and 5-year outcomes
cat("\n2-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_2_years))

cat("\n5-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_5_years))

# Evaluation
# Load necessary libraries
library(dplyr)
library(pROC)
library(survival)
library(foreach)
library(doParallel)
library(ggplot2)

# Function to calculate metrics with bootstrapping and specificity adjustment
calculate_metrics_with_bootstrap <- function(data, risk_col, outcome_col, time_col, time_limit, n_bootstrap = 1000) {
  
  # Record the start time
  start_time <- Sys.time()
  
  # Apply censoring: keep all data but treat events beyond the time limit as censored
  data_filtered <- data %>%
    mutate(
      censored_time = pmin(!!sym(time_col), time_limit * 365),
      event_status = ifelse(!!sym(outcome_col) == 1 & !!sym(time_col) <= time_limit * 365, 1, 0)
    )
  
  # Filter out rows with missing or invalid data
  data_filtered <- data_filtered %>%
    filter(!is.na(!!sym(risk_col)) & !is.na(event_status) & !is.na(censored_time))
  
  # If no events or no controls exist in the data, return NA
  if (length(unique(data_filtered$event_status)) < 2) {
    return(list(
      AUC = NA, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Not applicable", Cases = NA, Controls = NA
    ))
  }
  
  # Calculate ROC and AUC
  roc_curve <- roc(data_filtered$event_status, data_filtered[[risk_col]], levels = c(0, 1), direction = "<")
  auc_value <- as.numeric(auc(roc_curve))
  
  # Try to find the cutoff for specificity target 0.9
  cutoff_method <- "Specificity 0.9"
  optimal_cutoff <- tryCatch(
    {
      coords(roc_curve, x = 0.9, input = "specificity", ret = "threshold", transpose = TRUE)[1]
    },
    error = function(e) {
      NA
    }
  )
  
  # If the cutoff for specificity 0.9 is NA, try specificity 0.8
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Specificity 0.8"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = 0.8, input = "specificity", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the cutoff for specificity 0.8 is also NA, use the optimal cutoff
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Optimal Cutoff"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = "best", best.method = "closest.topleft", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the optimal_cutoff is not valid, return NA for metrics
  if (is.na(optimal_cutoff)) {
    return(list(
      AUC = auc_value, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Failed", Cases = sum(data_filtered$event_status == 1),
      Controls = sum(data_filtered$event_status == 0)
    ))
  }

  # Calculate predictions based on the new cutoff
  pred_class <- ifelse(data_filtered[[risk_col]] >= optimal_cutoff, 1, 0)

  # Calculate confusion matrix statistics based on the new cutoff
  confusion_mat <- table(Predicted = pred_class, Actual = data_filtered$event_status)

  # If confusion matrix is not 2x2, set metrics to NA
  if (!all(c(0, 1) %in% rownames(confusion_mat)) || !all(c(0, 1) %in% colnames(confusion_mat))) {
    sensitivity <- NA
    specificity <- NA
    ppv <- NA
    npv <- NA
  } else {
    sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
    specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])
    ppv <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
    npv <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  }

  # Bootstrapping AUC and C-statistic for confidence intervals
  auc_values <- numeric(n_bootstrap)
  c_stat_values <- numeric(n_bootstrap)

  bootstrapped_results <- foreach(i = 1:n_bootstrap, .combine = rbind, .packages = c("pROC", "survival")) %dopar% {
    bootstrap_sample <- data_filtered[sample(1:nrow(data_filtered), replace = TRUE), ]

    if (length(unique(bootstrap_sample$event_status)) < 2) {
      return(c(NA, NA))
    }

    roc_curve <- roc(bootstrap_sample$event_status, bootstrap_sample[[risk_col]])
    auc_val <- as.numeric(auc(roc_curve))

    cox_model_boot <- coxph(Surv(bootstrap_sample$censored_time, bootstrap_sample$event_status) ~ bootstrap_sample[[risk_col]], data = bootstrap_sample)
    c_stat_val <- as.numeric(summary(cox_model_boot)$concordance[1])

    return(c(auc_val, c_stat_val))
  }

  auc_values <- bootstrapped_results[, 1]
  c_stat_values <- bootstrapped_results[, 2]

  # Calculate 95% confidence intervals
  auc_ci <- quantile(auc_values[!is.na(auc_values)], probs = c(0.025, 0.975), na.rm = TRUE)
  c_stat_ci <- quantile(c_stat_values[!is.na(c_stat_values)], probs = c(0.025, 0.975), na.rm = TRUE)

  # Calculate Harrell's C-statistic for the full dataset
  cox_model <- coxph(Surv(censored_time, event_status) ~ data_filtered[[risk_col]], data = data_filtered)
  c_stat <- as.numeric(summary(cox_model)$concordance[1])

  # Record the end time
  end_time <- Sys.time()
  total_runtime <- end_time - start_time

  message("Number of bootstrap iterations run:", n_bootstrap)
  message("Total runtime for the bootstrapping process:", total_runtime, "seconds")

  # Return the metrics
  return(list(
    AUC = auc_value, AUC_Lower = auc_ci[1], AUC_Upper = auc_ci[2], 
    C_Statistic = c_stat, C_Stat_Lower = c_stat_ci[1], C_Stat_Upper = c_stat_ci[2],
    Sensitivity = sensitivity, Specificity = specificity, PPV = ppv,
    NPV = npv, Optimal_Cutoff = optimal_cutoff, Cutoff_Method = cutoff_method,
    Cases = sum(data_filtered$event_status == 1), Controls = sum(data_filtered$event_status == 0)
  ))
}

# Function to summarize metrics for each racial group
summarize_risk_metrics <- function(data, race_label, time_limit, n_bootstrap = 1000) {
  metrics <- calculate_metrics_with_bootstrap(data, paste0("risk_", time_limit, "_years"), paste0("outcome_", time_limit, "_years"), "time_to_event", time_limit, n_bootstrap)
  
  return(data.frame(
    Race = race_label,
    Time_Horizon = paste0(time_limit, " Years"),
    AUC = metrics$AUC,
    AUC_Lower_CI = metrics$AUC_Lower,
    AUC_Upper_CI = metrics$AUC_Upper,
    Harrell_C_Statistic = metrics$C_Statistic,
    C_Stat_Lower_CI = metrics$C_Stat_Lower,
    C_Stat_Upper_CI = metrics$C_Stat_Upper,
    Sensitivity = metrics$Sensitivity,
    Specificity = metrics$Specificity,
    PPV = metrics$PPV,
    NPV = metrics$NPV,
    Optimal_Cutoff = metrics$Optimal_Cutoff,
    Cutoff_Method = metrics$Cutoff_Method,
    Cases = metrics$Cases,
    Controls = metrics$Controls
  ))
}

# Evaluate metrics for each racial group and time horizon
results_all_2yr <- summarize_risk_metrics(consistent_data, "All Races", 2, n_bootstrap = 1000)
results_all_5yr <- summarize_risk_metrics(consistent_data, "All Races", 5, n_bootstrap = 1000)
results_black_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 2, n_bootstrap = 1000)
results_black_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 5, n_bootstrap = 1000)
results_white_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 2, n_bootstrap = 1000)
results_white_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 5, n_bootstrap = 1000)
results_asian_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 2, n_bootstrap = 1000)
results_asian_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 5, n_bootstrap = 1000)

# Combine results including "All Races" for the final table
final_results <- bind_rows(
  results_all_2yr, results_all_5yr,
  results_black_2yr, results_black_5yr,
  results_white_2yr, results_white_5yr,
  results_asian_2yr, results_asian_5yr
)

# Exclude "All Races" for the forest plot
final_results_filtered_CKD2009 <- final_results %>%
  filter(Race != "All Races")

# Display the final results table including "All Races"
print(final_results)

# Function to plot forest plot for metrics
plot_forest <- function(results_df, metric, lower_ci, upper_ci, title, reference_line) {
  ggplot(results_df, aes_string(x = metric, y = "Race")) +
    geom_point(size = 3, shape = 16, color = "blue") +  # Metric point estimates
    geom_errorbarh(aes_string(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  # 95% CI
    geom_vline(xintercept = reference_line, linetype = "dashed", color = "red") +  # Reference line
    facet_wrap(~ Time_Horizon, scales = "free_y") +  # Separate panels for each time horizon
    labs(
      title = title,
      x = metric,
      y = "Race"
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 14, face = "bold"),
      axis.text.x = element_text(size = 14),
      strip.text = element_text(size = 23, face = "bold"),
      panel.spacing = unit(1, "lines"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
    )
}

# Plot the forest plots for AUC and Harrell's C-statistic using the filtered data
forest_plot_auc <- plot_forest(final_results_filtered_CKD2009, "AUC", "AUC_Lower_CI", "AUC_Upper_CI", "", reference_line = 0.5)
forest_plot_cstat <- plot_forest(final_results_filtered_CKD2009, "Harrell_C_Statistic", "C_Stat_Lower_CI", "C_Stat_Upper_CI", "", reference_line = 0.5)

# Display the forest plots
print(forest_plot_auc)
print(forest_plot_cstat)

# Save the AUC forest plot
ggsave("CKD2009_VHR_forest_plot_auc_filtered.png", plot = forest_plot_auc, width = 10, height = 8, dpi = 300)

# Save the Harrell's C-statistic forest plot
ggsave("CKD2009_VHR_forest_plot_cstat_filtered.png", plot = forest_plot_cstat, width = 10, height = 8, dpi = 300)

# Stop the parallel backend after use
stopCluster(cl)
```

### 

# CKD-EPI 2021 Population

```{r}
# Install doParallel package if it's not installed
# install.packages("doParallel")

# Load the parallel processing libraries
library(doParallel)

# Set up parallel backend to use multiple processors
cores <- detectCores() - 1  # Detect the number of cores and use all but one
cl <- makeCluster(cores)
registerDoParallel(cl)

# Load necessary libraries
library(dplyr)
library(survival)

# Load dataset
inrange_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine_albumin.csv")

# # Define a plausible range for eGFR and Albumin/Creatinine based on clinical thresholds for eGFR ≤ 60
# plausible_eGFR_min <- 0
# plausible_eGFR_max <- 60  # Kidney disease defined as eGFR < 60 mL/min/1.73 m²
# 
# plausible_acr_min <- 0
# plausible_acr_max <- 3000
# albuminuria_cutoff <- 10

# Step 1: Select relevant columns and rename Albumin_Creatinine for consistency
person_filtered_KFRE <- inrange_person_with_summary %>%
  select(
    person_id,
    sex_at_birth,
    eGFR_ckd_epi_2021,
    Albumin_Creatinine = `Albumin.Creatinine`,
    age_precise,
    race,
    disease_status,
    time_to_event
  )



# Step 2: Data preprocessing and filtering based on the combination of eGFR and ACR for low-risk group
person_filtered_KFRE <- person_filtered_KFRE %>%
  mutate(
    event = disease_status
  ) %>%

  # Log-transform Albumin/Creatinine ratio (ACR)
  mutate(logACR = log(Albumin_Creatinine)) %>%
  # Ensure complete cases (remove rows with missing data)
  filter(complete.cases(.))

# Filter out rows with non-NA time_to_event values
case_control_time_to_event_counts <- person_filtered_KFRE %>%
  filter(!is.na(time_to_event)) %>%  # Keep only rows with non-NA time_to_event
  group_by(disease_status) %>%  # Assuming "disease_status" column indicates cases and controls
  summarise(count = n())  # Count the number of rows in each group

# Print the result
print("Number of cases and controls with non-NA time_to_event values:")
print(case_control_time_to_event_counts)


# Step 3: Verify summary statistics for eGFR and Albumin/Creatinine
summary(person_filtered_KFRE$eGFR_value)
summary(person_filtered_KFRE$Albumin_Creatinine)

# Check how many records are retained after filtering
cat("Number of records after filtering:", nrow(person_filtered_KFRE), "\n")

# Perform a complete case analysis
initial_row_count <- nrow(person_filtered_KFRE)

complete_cases <- person_filtered_KFRE %>%
  filter(complete.cases(.))

final_row_count <- nrow(complete_cases)

# Check if any rows have been removed
rows_removed <- initial_row_count - final_row_count

if (rows_removed > 0) {
  cat(rows_removed, "rows have been removed during the complete case analysis.\n")
} else {
  cat("No rows have been removed during the complete case analysis.\n")
}

# Report the number of complete cases
num_complete_cases <- nrow(complete_cases)
cat("Number of complete cases:", num_complete_cases, "\n")

# Remove any rows with NA in time_to_event or disease_status
complete_cases <- complete_cases %>%
  filter(!is.na(time_to_event) & !is.na(disease_status))

# Check the event distribution
cat("Event distribution (disease_status):\n")
print(table(complete_cases$disease_status))

# Step 4: Define the formula for calculating βsum (log hazard)
calculate_beta_sum <- function(age, sex, eGFR, logACR) {
  (-0.2201 * (age / 10 - 7.036)) +
  (0.2467 * (ifelse(sex == "Male", 1, 0) - 0.5642)) -
  (0.5567 * (eGFR / 5 - 7.222)) +
  (0.4510 * (logACR - 5.137))
}

# Apply the formula to calculate βsum
complete_cases <- complete_cases %>%
  mutate(beta_sum = calculate_beta_sum(age_precise, sex_at_birth, eGFR_ckd_epi_2021, logACR))

# Remove any rows with infinite or NA beta_sum
complete_cases <- complete_cases %>%
  filter(is.finite(beta_sum) & !is.na(beta_sum))

# Step 5: Calculate the risk for two and five years using the updated formulas
complete_cases <- complete_cases %>%
  mutate(
    risk_2_years = 100 * (1 - 0.975^exp(beta_sum)),  # Two-Year Risk calculation
    risk_5_years = 100 * (1 - 0.9240^exp(beta_sum))  # Five-Year Risk calculation
  )

# Save the data before filtering
before_filtering <- complete_cases

# Step 6: Apply the filtering to create consistent_data
consistent_data <- complete_cases %>%
  filter(!is.na(risk_5_years) & !is.na(risk_2_years))

# Step 7: Define and create the 2-year and 5-year outcomes based on disease_status and time_to_event
consistent_data <- consistent_data %>%
  mutate(
    outcome_2_years = ifelse(disease_status == 1 & time_to_event <= 2 * 365.25, 1, 0),
    outcome_5_years = ifelse(disease_status == 1 & time_to_event <= 5 * 365.25, 1, 0)
  )

# Find the rows that were removed by comparing before and after datasets
removed_rows <- anti_join(before_filtering, consistent_data, by = "person_id")

# Print the removed rows
if (nrow(removed_rows) > 0) {
  cat("Rows that were removed during filtering:\n")
  print(removed_rows)
} else {
  cat("No rows were removed during filtering.\n")
}

# Step 8: Verify the risk values
summary(consistent_data$risk_5_years)
summary(consistent_data$risk_2_years)

# Count the number of person_id entries with event == 1 and event == 0
event_count <- consistent_data %>%
  group_by(event) %>%
  summarise(count = n_distinct(person_id))

# Print the results
cat("Number of person_id with event == 1:", event_count$count[event_count$event == 1], "\n")
cat("Number of person_id with event == 0:", event_count$count[event_count$event == 0], "\n")

# Check the event distribution for the 2-year and 5-year outcomes
cat("\n2-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_2_years))

cat("\n5-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_5_years))


# Evaluation
# Load necessary libraries
library(dplyr)
library(pROC)
library(survival)
library(foreach)
library(doParallel)
library(ggplot2)

# Function to calculate metrics with bootstrapping and specificity adjustment
calculate_metrics_with_bootstrap <- function(data, risk_col, outcome_col, time_col, time_limit, n_bootstrap = 1000) {
  
  # Record the start time
  start_time <- Sys.time()
  
  # Apply censoring: keep all data but treat events beyond the time limit as censored
  data_filtered <- data %>%
    mutate(
      censored_time = pmin(!!sym(time_col), time_limit * 365),
      event_status = ifelse(!!sym(outcome_col) == 1 & !!sym(time_col) <= time_limit * 365, 1, 0)
    )
  
  # Filter out rows with missing or invalid data
  data_filtered <- data_filtered %>%
    filter(!is.na(!!sym(risk_col)) & !is.na(event_status) & !is.na(censored_time))
  
  # If no events or no controls exist in the data, return NA
  if (length(unique(data_filtered$event_status)) < 2) {
    return(list(
      AUC = NA, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Not applicable", Cases = NA, Controls = NA
    ))
  }
  
  # Calculate ROC and AUC
  roc_curve <- roc(data_filtered$event_status, data_filtered[[risk_col]], levels = c(0, 1), direction = "<")
  auc_value <- as.numeric(auc(roc_curve))
  
  # Try to find the cutoff for specificity target 0.9
  cutoff_method <- "Specificity 0.9"
  optimal_cutoff <- tryCatch(
    {
      coords(roc_curve, x = 0.9, input = "specificity", ret = "threshold", transpose = TRUE)[1]
    },
    error = function(e) {
      NA
    }
  )
  
  # If the cutoff for specificity 0.9 is NA, try specificity 0.8
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Specificity 0.8"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = 0.8, input = "specificity", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the cutoff for specificity 0.8 is also NA, use the optimal cutoff
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Optimal Cutoff"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = "best", best.method = "closest.topleft", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the optimal_cutoff is not valid, return NA for metrics
  if (is.na(optimal_cutoff)) {
    return(list(
      AUC = auc_value, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Failed", Cases = sum(data_filtered$event_status == 1),
      Controls = sum(data_filtered$event_status == 0)
    ))
  }

  # Calculate predictions based on the new cutoff
  pred_class <- ifelse(data_filtered[[risk_col]] >= optimal_cutoff, 1, 0)

  # Calculate confusion matrix statistics based on the new cutoff
  confusion_mat <- table(Predicted = pred_class, Actual = data_filtered$event_status)

  # If confusion matrix is not 2x2, set metrics to NA
  if (!all(c(0, 1) %in% rownames(confusion_mat)) || !all(c(0, 1) %in% colnames(confusion_mat))) {
    sensitivity <- NA
    specificity <- NA
    ppv <- NA
    npv <- NA
  } else {
    sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
    specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])
    ppv <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
    npv <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  }

  # Bootstrapping AUC and C-statistic for confidence intervals
  auc_values <- numeric(n_bootstrap)
  c_stat_values <- numeric(n_bootstrap)

  bootstrapped_results <- foreach(i = 1:n_bootstrap, .combine = rbind, .packages = c("pROC", "survival")) %dopar% {
    bootstrap_sample <- data_filtered[sample(1:nrow(data_filtered), replace = TRUE), ]

    if (length(unique(bootstrap_sample$event_status)) < 2) {
      return(c(NA, NA))
    }

    roc_curve <- roc(bootstrap_sample$event_status, bootstrap_sample[[risk_col]])
    auc_val <- as.numeric(auc(roc_curve))

    cox_model_boot <- coxph(Surv(bootstrap_sample$censored_time, bootstrap_sample$event_status) ~ bootstrap_sample[[risk_col]], data = bootstrap_sample)
    c_stat_val <- as.numeric(summary(cox_model_boot)$concordance[1])

    return(c(auc_val, c_stat_val))
  }

  auc_values <- bootstrapped_results[, 1]
  c_stat_values <- bootstrapped_results[, 2]

  # Calculate 95% confidence intervals
  auc_ci <- quantile(auc_values[!is.na(auc_values)], probs = c(0.025, 0.975), na.rm = TRUE)
  c_stat_ci <- quantile(c_stat_values[!is.na(c_stat_values)], probs = c(0.025, 0.975), na.rm = TRUE)

  # Calculate Harrell's C-statistic for the full dataset
  cox_model <- coxph(Surv(censored_time, event_status) ~ data_filtered[[risk_col]], data = data_filtered)
  c_stat <- as.numeric(summary(cox_model)$concordance[1])

  # Record the end time
  end_time <- Sys.time()
  total_runtime <- end_time - start_time

  message("Number of bootstrap iterations run:", n_bootstrap)
  message("Total runtime for the bootstrapping process:", total_runtime, "seconds")

  # Return the metrics
  return(list(
    AUC = auc_value, AUC_Lower = auc_ci[1], AUC_Upper = auc_ci[2], 
    C_Statistic = c_stat, C_Stat_Lower = c_stat_ci[1], C_Stat_Upper = c_stat_ci[2],
    Sensitivity = sensitivity, Specificity = specificity, PPV = ppv,
    NPV = npv, Optimal_Cutoff = optimal_cutoff, Cutoff_Method = cutoff_method,
    Cases = sum(data_filtered$event_status == 1), Controls = sum(data_filtered$event_status == 0)
  ))
}

# Function to summarize metrics for each racial group
summarize_risk_metrics <- function(data, race_label, time_limit, n_bootstrap = 1000) {
  metrics <- calculate_metrics_with_bootstrap(data, paste0("risk_", time_limit, "_years"), paste0("outcome_", time_limit, "_years"), "time_to_event", time_limit, n_bootstrap)
  
  return(data.frame(
    Race = race_label,
    Time_Horizon = paste0(time_limit, " Years"),
    AUC = metrics$AUC,
    AUC_Lower_CI = metrics$AUC_Lower,
    AUC_Upper_CI = metrics$AUC_Upper,
    Harrell_C_Statistic = metrics$C_Statistic,
    C_Stat_Lower_CI = metrics$C_Stat_Lower,
    C_Stat_Upper_CI = metrics$C_Stat_Upper,
    Sensitivity = metrics$Sensitivity,
    Specificity = metrics$Specificity,
    PPV = metrics$PPV,
    NPV = metrics$NPV,
    Optimal_Cutoff = metrics$Optimal_Cutoff,
    Cutoff_Method = metrics$Cutoff_Method,
    Cases = metrics$Cases,
    Controls = metrics$Controls
  ))
}

# Evaluate metrics for each racial group and time horizon
results_all_2yr <- summarize_risk_metrics(consistent_data, "All Races", 2, n_bootstrap = 1000)
results_all_5yr <- summarize_risk_metrics(consistent_data, "All Races", 5, n_bootstrap = 1000)
results_black_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 2, n_bootstrap = 1000)
results_black_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 5, n_bootstrap = 1000)
results_white_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 2, n_bootstrap = 1000)
results_white_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 5, n_bootstrap = 1000)
results_asian_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 2, n_bootstrap = 1000)
results_asian_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 5, n_bootstrap = 1000)

# Combine results including "All Races" for the final table
final_results <- bind_rows(
  results_all_2yr, results_all_5yr,
  results_black_2yr, results_black_5yr,
  results_white_2yr, results_white_5yr,
  results_asian_2yr, results_asian_5yr
)

# Exclude "All Races" for the forest plot
final_results_filtered_CKD2021 <- final_results %>%
  filter(Race != "All Races")

# Display the final results table including "All Races"
print(final_results)

# Function to plot forest plot for metrics
plot_forest <- function(results_df, metric, lower_ci, upper_ci, title, reference_line) {
  ggplot(results_df, aes_string(x = metric, y = "Race")) +
    geom_point(size = 3, shape = 16, color = "blue") +  # Metric point estimates
    geom_errorbarh(aes_string(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  # 95% CI
    geom_vline(xintercept = reference_line, linetype = "dashed", color = "red") +  # Reference line
    facet_wrap(~ Time_Horizon, scales = "free_y") +  # Separate panels for each time horizon
    labs(
      title = title,
      x = metric,
      y = "Race"
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 14, face = "bold"),
      axis.text.x = element_text(size = 14),
      strip.text = element_text(size = 23, face = "bold"),
      panel.spacing = unit(1, "lines"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
    )
}

# Plot the forest plots for AUC and Harrell's C-statistic using the filtered data
forest_plot_auc <- plot_forest(final_results_filtered_CKD2021, "AUC", "AUC_Lower_CI", "AUC_Upper_CI", "", reference_line = 0.5)
forest_plot_cstat <- plot_forest(final_results_filtered_CKD2021, "Harrell_C_Statistic", "C_Stat_Lower_CI", "C_Stat_Upper_CI", "", reference_line = 0.5)

# Display the forest plots
print(forest_plot_auc)
print(forest_plot_cstat)

# Save the AUC forest plot
ggsave("CKD2021_VHR_forest_plot_auc_filtered.png", plot = forest_plot_auc, width = 10, height = 8, dpi = 300)

# Save the Harrell's C-statistic forest plot
ggsave("CKD2021_VHR_forest_plot_cstat_filtered.png", plot = forest_plot_cstat, width = 10, height = 8, dpi = 300)

```

### 

### Group AUC Comparison

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Assuming final_results_filtered_MDRD, final_results_filtered_CKD2009, and final_results_filtered_CKD2021 
# are the data frames containing the results for each model

# Add a column to identify each model
final_results_filtered_MDRD$Model <- "MDRD"
final_results_filtered_CKD2009$Model <- "CKD-EPI-2009"
final_results_filtered_CKD2021$Model <- "CKD-EPI-2021"

# Combine all the data frames
combined_results <- bind_rows(
  final_results_filtered_MDRD,
  final_results_filtered_CKD2009,
  final_results_filtered_CKD2021
)

# Reorder the levels for the Race factor to start with Black, followed by White, then Asian
combined_results$Race <- factor(combined_results$Race, levels = c("Black or African American", "White", "Asian"))

# Plotting function to create facets by time horizon and race, comparing the AUC of each model
plot_auc_comparison <- function(data) {
  ggplot(data, aes(x = Model, y = AUC, color = Model)) +
    geom_point(size = 6, stroke = 1.5) +  # Larger points with bold outline
    geom_errorbar(aes(ymin = AUC_Lower_CI, ymax = AUC_Upper_CI), width = 0.3, linewidth = 1.5) +  # Thicker error bars
    facet_grid(Time_Horizon ~ Race, scales = "free") +
    labs(
      title = "AUC Comparison Across Models",
      x = "Model",
      y = "AUC"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 14, angle = 45, hjust = 1, face = "bold"),  # Larger and bold text
      axis.text.y = element_text(size = 14, face = "bold"),  # Larger and bold text
      axis.title.x = element_text(size = 16, face = "bold"),  # Bold axis title
      axis.title.y = element_text(size = 16, face = "bold"),  # Bold axis title
      strip.text = element_text(size = 18, face = "bold"),  # Larger and bold facet labels for Race
      strip.placement = "outside",  # Move strip text outside the plot area
      strip.background = element_blank(),  # Remove default strip background
      plot.title = element_text(size = 20, face = "bold", hjust = 0.5, margin = margin(b = 15)),  # Add space below the title
      legend.title = element_text(size = 14, face = "bold"),  # Bold legend title
      legend.text = element_text(size = 12, face = "bold"),   # Bold legend text
      panel.spacing = unit(2.5, "lines"),  # Increase spacing between panels for better readability
      plot.margin = margin(t = 20, r = 20, b = 20, l = 20)  # Add extra margin around the plot for clarity
    ) +
    scale_color_manual(values = c("MDRD" = "blue", "CKD-EPI-2009" = "green", "CKD-EPI-2021" = "red")) +  # Distinct colors
    guides(color = guide_legend(override.aes = list(size = 5)))  # Larger legend key sizes
}

# Create the plot using the combined results
auc_comparison_plot <- plot_auc_comparison(combined_results)

# Display the plot
print(auc_comparison_plot)

# Save the plot as a high-resolution image
ggsave("AUC_Comparison_Facet_Plot.png", plot = auc_comparison_plot, width = 14, height = 8, dpi = 300)

```

### Group c statistics comparison

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Assuming final_results_filtered_MDRD, final_results_filtered_CKD2009, and final_results_filtered_CKD2021 
# are the data frames containing the results for each model

# Add a column to identify each model
final_results_filtered_MDRD$Model <- "MDRD"
final_results_filtered_CKD2009$Model <- "CKD-EPI-2009"
final_results_filtered_CKD2021$Model <- "CKD-EPI-2021"

# Combine all the data frames
combined_results <- bind_rows(
  final_results_filtered_MDRD,
  final_results_filtered_CKD2009,
  final_results_filtered_CKD2021
)

# Reorder the levels for the Race factor to start with Black, followed by White, then Asian
combined_results$Race <- factor(combined_results$Race, levels = c("Black or African American", "White", "Asian"))

# Plotting function to create facets by time horizon and race, comparing the Harrell's C-statistic of each model
plot_cstat_comparison <- function(data) {
  ggplot(data, aes(x = Model, y = Harrell_C_Statistic, color = Model)) +
    geom_point(size = 6, stroke = 1.5) +  # Larger points with bold outline
    geom_errorbar(aes(ymin = C_Stat_Lower_CI, ymax = C_Stat_Upper_CI), width = 0.3, linewidth = 1.5) +  # Thicker error bars
    facet_grid(Time_Horizon ~ Race, scales = "free") +
    labs(
      title = "Harrell's C-Statistic Comparison Across Models",
      x = "Model",
      y = "Harrell's C-Statistic"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 14, angle = 45, hjust = 1, face = "bold"),  # Larger and bold text
      axis.text.y = element_text(size = 14, face = "bold"),  # Larger and bold text
      axis.title.x = element_text(size = 16, face = "bold"),  # Bold axis title
      axis.title.y = element_text(size = 16, face = "bold"),  # Bold axis title
      strip.text = element_text(size = 18, face = "bold"),  # Larger and bold facet labels for Race
      strip.placement = "outside",  # Move strip text outside the plot area
      strip.background = element_blank(),  # Remove default strip background
      plot.title = element_text(size = 20, face = "bold", hjust = 0.5, margin = margin(b = 15)),  # Add space below the title
      legend.title = element_text(size = 14, face = "bold"),  # Bold legend title
      legend.text = element_text(size = 12, face = "bold"),   # Bold legend text
      panel.spacing = unit(2.5, "lines"),  # Increase spacing between panels for better readability
      plot.margin = margin(t = 20, r = 20, b = 20, l = 20)  # Add extra margin around the plot for clarity
    ) +
    scale_color_manual(values = c("MDRD" = "blue", "CKD-EPI-2009" = "green", "CKD-EPI-2021" = "red")) +  # Distinct colors
    guides(color = guide_legend(override.aes = list(size = 5)))  # Larger legend key sizes
}

# Create the plot using the combined results
cstat_comparison_plot <- plot_cstat_comparison(combined_results)

# Display the plot
print(cstat_comparison_plot)

# Save the plot as a high-resolution image
ggsave("C_Statistic_Comparison_Facet_Plot.png", plot = cstat_comparison_plot, width = 14, height = 8, dpi = 300)

```

## Case study: CKD-EPI_2021 VERY HIGH RISK AND HIGH RISK POPULATION

#### CKD-EPI-2021

```{r}
# Install doParallel package if it's not installed
# install.packages("doParallel")

# Load the parallel processing libraries
library(doParallel)

# Set up parallel backend to use multiple processors
cores <- detectCores() - 1  # Detect the number of cores and use all but one
cl <- makeCluster(cores)
registerDoParallel(cl)

# Load necessary libraries
library(dplyr)
library(survival)

# Load dataset
inrange_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine_albumin.csv")

# # Define a plausible range for eGFR and Albumin/Creatinine based on clinical thresholds for eGFR ≤ 60
# plausible_eGFR_min <- 0
# plausible_eGFR_max <- 60  # Kidney disease defined as eGFR < 60 mL/min/1.73 m²
# 
# plausible_acr_min <- 0
# plausible_acr_max <- 3000
# albuminuria_cutoff <- 10

# Step 1: Select relevant columns and rename Albumin_Creatinine for consistency
person_filtered_KFRE <- inrange_person_with_summary %>%
  select(
    person_id,
    sex_at_birth,
    eGFR_ckd_epi_2021,
    eGFR_ckd_epi_2009,
    eGFR_MDRD,
    Albumin_Creatinine = `Albumin.Creatinine`,
    age_precise,
    race,
    disease_status,
    time_to_event
  )



# Step 2: Data preprocessing and filtering based on the combination of eGFR and ACR for low-risk group
person_filtered_KFRE <- person_filtered_KFRE %>%
  mutate(
    event = disease_status
  ) %>%
  filter(
  # Low risk population
  (eGFR_ckd_epi_2021 >= 60 & Albumin_Creatinine < 30)
)%>%
  # Log-transform Albumin/Creatinine ratio (ACR)
  mutate(logACR = log(Albumin_Creatinine)) %>%
  # Ensure complete cases (remove rows with missing data)
  filter(complete.cases(.))

# Filter out rows with non-NA time_to_event values
case_control_time_to_event_counts <- person_filtered_KFRE %>%
  filter(!is.na(time_to_event)) %>%  # Keep only rows with non-NA time_to_event
  group_by(disease_status) %>%  # Assuming "disease_status" column indicates cases and controls
  summarise(count = n())  # Count the number of rows in each group

# Print the result
print("Number of cases and controls with non-NA time_to_event values:")
print(case_control_time_to_event_counts)


# Step 3: Verify summary statistics for eGFR and Albumin/Creatinine
summary(person_filtered_KFRE$eGFR_value)
summary(person_filtered_KFRE$Albumin_Creatinine)

# Check how many records are retained after filtering
cat("Number of records after filtering:", nrow(person_filtered_KFRE), "\n")

# Perform a complete case analysis
initial_row_count <- nrow(person_filtered_KFRE)

complete_cases <- person_filtered_KFRE %>%
  filter(complete.cases(.))

final_row_count <- nrow(complete_cases)

# Check if any rows have been removed
rows_removed <- initial_row_count - final_row_count

if (rows_removed > 0) {
  cat(rows_removed, "rows have been removed during the complete case analysis.\n")
} else {
  cat("No rows have been removed during the complete case analysis.\n")
}

# Report the number of complete cases
num_complete_cases <- nrow(complete_cases)
cat("Number of complete cases:", num_complete_cases, "\n")

# Remove any rows with NA in time_to_event or disease_status
complete_cases <- complete_cases %>%
  filter(!is.na(time_to_event) & !is.na(disease_status))

# Check the event distribution
cat("Event distribution (disease_status):\n")
print(table(complete_cases$disease_status))

# Step 4: Define the formula for calculating βsum (log hazard)
calculate_beta_sum <- function(age, sex, eGFR, logACR) {
  (-0.2201 * (age / 10 - 7.036)) +
  (0.2467 * (ifelse(sex == "Male", 1, 0) - 0.5642)) -
  (0.5567 * (eGFR / 5 - 7.222)) +
  (0.4510 * (logACR - 5.137))
}

# Apply the formula to calculate βsum
complete_cases <- complete_cases %>%
  mutate(beta_sum = calculate_beta_sum(age_precise, sex_at_birth, eGFR_ckd_epi_2021, logACR))

# Remove any rows with infinite or NA beta_sum
complete_cases <- complete_cases %>%
  filter(is.finite(beta_sum) & !is.na(beta_sum))

# Step 5: Calculate the risk for two and five years using the updated formulas
complete_cases <- complete_cases %>%
  mutate(
    risk_2_years = 100 * (1 - 0.975^exp(beta_sum)),  # Two-Year Risk calculation
    risk_5_years = 100 * (1 - 0.9240^exp(beta_sum))  # Five-Year Risk calculation
  )

# Save the data before filtering
before_filtering <- complete_cases

# Step 6: Apply the filtering to create consistent_data
consistent_data <- complete_cases %>%
  filter(!is.na(risk_5_years) & !is.na(risk_2_years))

# Step 7: Define and create the 2-year and 5-year outcomes based on disease_status and time_to_event
consistent_data <- consistent_data %>%
  mutate(
    outcome_2_years = ifelse(disease_status == 1 & time_to_event <= 2 * 365.25, 1, 0),
    outcome_5_years = ifelse(disease_status == 1 & time_to_event <= 5 * 365.25, 1, 0)
  )

# Find the rows that were removed by comparing before and after datasets
removed_rows <- anti_join(before_filtering, consistent_data, by = "person_id")

# Print the removed rows
if (nrow(removed_rows) > 0) {
  cat("Rows that were removed during filtering:\n")
  print(removed_rows)
} else {
  cat("No rows were removed during filtering.\n")
}

# Step 8: Verify the risk values
summary(consistent_data$risk_5_years)
summary(consistent_data$risk_2_years)

# Count the number of person_id entries with event == 1 and event == 0
event_count <- consistent_data %>%
  group_by(event) %>%
  summarise(count = n_distinct(person_id))

# Print the results
cat("Number of person_id with event == 1:", event_count$count[event_count$event == 1], "\n")
cat("Number of person_id with event == 0:", event_count$count[event_count$event == 0], "\n")

# Check the event distribution for the 2-year and 5-year outcomes
cat("\n2-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_2_years))

cat("\n5-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_5_years))


# Evaluation
# Load necessary libraries
library(dplyr)
library(pROC)
library(survival)
library(foreach)
library(doParallel)
library(ggplot2)

# Function to calculate metrics with bootstrapping and specificity adjustment
calculate_metrics_with_bootstrap <- function(data, risk_col, outcome_col, time_col, time_limit, n_bootstrap = 5000) {
  
  # Record the start time
  start_time <- Sys.time()
  
  # Apply censoring: keep all data but treat events beyond the time limit as censored
  data_filtered <- data %>%
    mutate(
      censored_time = pmin(!!sym(time_col), time_limit * 365),
      event_status = ifelse(!!sym(outcome_col) == 1 & !!sym(time_col) <= time_limit * 365, 1, 0)
    )
  
  # Filter out rows with missing or invalid data
  data_filtered <- data_filtered %>%
    filter(!is.na(!!sym(risk_col)) & !is.na(event_status) & !is.na(censored_time))
  
  # If no events or no controls exist in the data, return NA
  if (length(unique(data_filtered$event_status)) < 2) {
    return(list(
      AUC = NA, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Not applicable", Cases = NA, Controls = NA
    ))
  }
  
  # Calculate ROC and AUC
  roc_curve <- roc(data_filtered$event_status, data_filtered[[risk_col]], levels = c(0, 1), direction = "<")
  auc_value <- as.numeric(auc(roc_curve))
  
  # Try to find the cutoff for specificity target 0.9
  cutoff_method <- "Specificity 0.9"
  optimal_cutoff <- tryCatch(
    {
      coords(roc_curve, x = 0.9, input = "specificity", ret = "threshold", transpose = TRUE)[1]
    },
    error = function(e) {
      NA
    }
  )
  
  # If the cutoff for specificity 0.9 is NA, try specificity 0.8
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Specificity 0.8"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = 0.8, input = "specificity", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the cutoff for specificity 0.8 is also NA, use the optimal cutoff
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Optimal Cutoff"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = "best", best.method = "closest.topleft", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the optimal_cutoff is not valid, return NA for metrics
  if (is.na(optimal_cutoff)) {
    return(list(
      AUC = auc_value, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Failed", Cases = sum(data_filtered$event_status == 1),
      Controls = sum(data_filtered$event_status == 0)
    ))
  }

  # Calculate predictions based on the new cutoff
  pred_class <- ifelse(data_filtered[[risk_col]] >= optimal_cutoff, 1, 0)

  # Calculate confusion matrix statistics based on the new cutoff
  confusion_mat <- table(Predicted = pred_class, Actual = data_filtered$event_status)

  # If confusion matrix is not 2x2, set metrics to NA
  if (!all(c(0, 1) %in% rownames(confusion_mat)) || !all(c(0, 1) %in% colnames(confusion_mat))) {
    sensitivity <- NA
    specificity <- NA
    ppv <- NA
    npv <- NA
  } else {
    sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
    specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])
    ppv <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
    npv <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  }

  # Bootstrapping AUC and C-statistic for confidence intervals
  auc_values <- numeric(n_bootstrap)
  c_stat_values <- numeric(n_bootstrap)

  bootstrapped_results <- foreach(i = 1:n_bootstrap, .combine = rbind, .packages = c("pROC", "survival")) %dopar% {
    bootstrap_sample <- data_filtered[sample(1:nrow(data_filtered), replace = TRUE), ]

    if (length(unique(bootstrap_sample$event_status)) < 2) {
      return(c(NA, NA))
    }

    roc_curve <- roc(bootstrap_sample$event_status, bootstrap_sample[[risk_col]])
    auc_val <- as.numeric(auc(roc_curve))

    cox_model_boot <- coxph(Surv(bootstrap_sample$censored_time, bootstrap_sample$event_status) ~ bootstrap_sample[[risk_col]], data = bootstrap_sample)
    c_stat_val <- as.numeric(summary(cox_model_boot)$concordance[1])

    return(c(auc_val, c_stat_val))
  }

  auc_values <- bootstrapped_results[, 1]
  c_stat_values <- bootstrapped_results[, 2]

  # Calculate 95% confidence intervals
  auc_ci <- quantile(auc_values[!is.na(auc_values)], probs = c(0.025, 0.975), na.rm = TRUE)
  c_stat_ci <- quantile(c_stat_values[!is.na(c_stat_values)], probs = c(0.025, 0.975), na.rm = TRUE)

  # Calculate Harrell's C-statistic for the full dataset
  cox_model <- coxph(Surv(censored_time, event_status) ~ data_filtered[[risk_col]], data = data_filtered)
  c_stat <- as.numeric(summary(cox_model)$concordance[1])

  # Record the end time
  end_time <- Sys.time()
  total_runtime <- end_time - start_time

  message("Number of bootstrap iterations run:", n_bootstrap)
  message("Total runtime for the bootstrapping process:", total_runtime, "seconds")

  # Return the metrics
  return(list(
    AUC = auc_value, AUC_Lower = auc_ci[1], AUC_Upper = auc_ci[2], 
    C_Statistic = c_stat, C_Stat_Lower = c_stat_ci[1], C_Stat_Upper = c_stat_ci[2],
    Sensitivity = sensitivity, Specificity = specificity, PPV = ppv,
    NPV = npv, Optimal_Cutoff = optimal_cutoff, Cutoff_Method = cutoff_method,
    Cases = sum(data_filtered$event_status == 1), Controls = sum(data_filtered$event_status == 0)
  ))
}

# Function to summarize metrics for each racial group
summarize_risk_metrics <- function(data, race_label, time_limit, n_bootstrap = 5000) {
  metrics <- calculate_metrics_with_bootstrap(data, paste0("risk_", time_limit, "_years"), paste0("outcome_", time_limit, "_years"), "time_to_event", time_limit, n_bootstrap)
  
  return(data.frame(
    Race = race_label,
    Time_Horizon = paste0(time_limit, " Years"),
    AUC = metrics$AUC,
    AUC_Lower_CI = metrics$AUC_Lower,
    AUC_Upper_CI = metrics$AUC_Upper,
    Harrell_C_Statistic = metrics$C_Statistic,
    C_Stat_Lower_CI = metrics$C_Stat_Lower,
    C_Stat_Upper_CI = metrics$C_Stat_Upper,
    Sensitivity = metrics$Sensitivity,
    Specificity = metrics$Specificity,
    PPV = metrics$PPV,
    NPV = metrics$NPV,
    Optimal_Cutoff = metrics$Optimal_Cutoff,
    Cutoff_Method = metrics$Cutoff_Method,
    Cases = metrics$Cases,
    Controls = metrics$Controls
  ))
}

# Evaluate metrics for each racial group and time horizon
results_all_2yr <- summarize_risk_metrics(consistent_data, "All Races", 2, n_bootstrap = 5000)
results_all_5yr <- summarize_risk_metrics(consistent_data, "All Races", 5, n_bootstrap = 5000)
results_black_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 2, n_bootstrap = 5000)
results_black_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 5, n_bootstrap = 5000)
results_white_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 2, n_bootstrap = 5000)
results_white_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 5, n_bootstrap = 5000)
results_asian_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 2, n_bootstrap = 5000)
results_asian_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 5, n_bootstrap = 5000)

# Combine results including "All Races" for the final table
final_results <- bind_rows(
  results_all_2yr, results_all_5yr,
  results_black_2yr, results_black_5yr,
  results_white_2yr, results_white_5yr,
  results_asian_2yr, results_asian_5yr
)

# Exclude "All Races" for the forest plot
final_results_filtered_CKD2021 <- final_results %>%
  filter(Race != "All Races")

# Display the final results table including "All Races"
print(final_results)

# Function to plot forest plot for metrics
plot_forest <- function(results_df, metric, lower_ci, upper_ci, title, reference_line) {
  ggplot(results_df, aes_string(x = metric, y = "Race")) +
    geom_point(size = 3, shape = 16, color = "blue") +  # Metric point estimates
    geom_errorbarh(aes_string(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  # 95% CI
    geom_vline(xintercept = reference_line, linetype = "dashed", color = "red") +  # Reference line
    facet_wrap(~ Time_Horizon, scales = "free_y") +  # Separate panels for each time horizon
    labs(
      title = title,
      x = metric,
      y = "Race"
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 14, face = "bold"),
      axis.text.x = element_text(size = 14),
      strip.text = element_text(size = 23, face = "bold"),
      panel.spacing = unit(1, "lines"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
    )
}

# Plot the forest plots for AUC and Harrell's C-statistic using the filtered data
forest_plot_auc <- plot_forest(final_results_filtered_CKD2021, "AUC", "AUC_Lower_CI", "AUC_Upper_CI", "", reference_line = 0.5)
forest_plot_cstat <- plot_forest(final_results_filtered_CKD2021, "Harrell_C_Statistic", "C_Stat_Lower_CI", "C_Stat_Upper_CI", "", reference_line = 0.5)

# Display the forest plots
print(forest_plot_auc)
print(forest_plot_cstat)

# Save the AUC forest plot
ggsave("CKD2021_VHR_forest_plot_auc_filtered.png", plot = forest_plot_auc, width = 10, height = 8, dpi = 300)

# Save the Harrell's C-statistic forest plot
ggsave("CKD2021_VHR_forest_plot_cstat_filtered.png", plot = forest_plot_cstat, width = 10, height = 8, dpi = 300)

```

#### CKD-EPI-2009

```{r}
# Install doParallel package if it's not installed
# install.packages("doParallel")

# Load the parallel processing libraries
library(doParallel)

# Set up parallel backend to use multiple processors
cores <- detectCores() - 1  # Detect the number of cores and use all but one
cl <- makeCluster(cores)
registerDoParallel(cl)

# Load necessary libraries
library(dplyr)
library(survival)


# Step 4: Define the formula for calculating βsum (log hazard)
calculate_beta_sum <- function(age, sex, eGFR, logACR) {
  (-0.2201 * (age / 10 - 7.036)) +
  (0.2467 * (ifelse(sex == "Male", 1, 0) - 0.5642)) -
  (0.5567 * (eGFR / 5 - 7.222)) +
  (0.4510 * (logACR - 5.137))
}

# Apply the formula to calculate βsum
complete_cases <- complete_cases %>%
  mutate(beta_sum = calculate_beta_sum(age_precise, sex_at_birth, eGFR_ckd_epi_2009, logACR))

# Remove any rows with infinite or NA beta_sum
complete_cases <- complete_cases %>%
  filter(is.finite(beta_sum) & !is.na(beta_sum))

# Step 5: Calculate the risk for two and five years using the updated formulas
complete_cases <- complete_cases %>%
  mutate(
    risk_2_years = 100 * (1 - 0.975^exp(beta_sum)),  # Two-Year Risk calculation
    risk_5_years = 100 * (1 - 0.9240^exp(beta_sum))  # Five-Year Risk calculation
  )

# Save the data before filtering
before_filtering <- complete_cases

# Step 6: Apply the filtering to create consistent_data
consistent_data <- complete_cases %>%
  filter(!is.na(risk_5_years) & !is.na(risk_2_years))

# Step 7: Define and create the 2-year and 5-year outcomes based on disease_status and time_to_event
consistent_data <- consistent_data %>%
  mutate(
    outcome_2_years = ifelse(disease_status == 1 & time_to_event <= 2 * 365.25, 1, 0),
    outcome_5_years = ifelse(disease_status == 1 & time_to_event <= 5 * 365.25, 1, 0)
  )

# Find the rows that were removed by comparing before and after datasets
removed_rows <- anti_join(before_filtering, consistent_data, by = "person_id")

# Print the removed rows
if (nrow(removed_rows) > 0) {
  cat("Rows that were removed during filtering:\n")
  print(removed_rows)
} else {
  cat("No rows were removed during filtering.\n")
}

# Step 8: Verify the risk values
summary(consistent_data$risk_5_years)
summary(consistent_data$risk_2_years)

# Count the number of person_id entries with event == 1 and event == 0
event_count <- consistent_data %>%
  group_by(event) %>%
  summarise(count = n_distinct(person_id))

# Print the results
cat("Number of person_id with event == 1:", event_count$count[event_count$event == 1], "\n")
cat("Number of person_id with event == 0:", event_count$count[event_count$event == 0], "\n")

# Check the event distribution for the 2-year and 5-year outcomes
cat("\n2-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_2_years))

cat("\n5-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_5_years))

# Evaluation
# Load necessary libraries
library(dplyr)
library(pROC)
library(survival)
library(foreach)
library(doParallel)
library(ggplot2)

# Function to calculate metrics with bootstrapping and specificity adjustment
calculate_metrics_with_bootstrap <- function(data, risk_col, outcome_col, time_col, time_limit, n_bootstrap = 5000) {
  
  # Record the start time
  start_time <- Sys.time()
  
  # Apply censoring: keep all data but treat events beyond the time limit as censored
  data_filtered <- data %>%
    mutate(
      censored_time = pmin(!!sym(time_col), time_limit * 365),
      event_status = ifelse(!!sym(outcome_col) == 1 & !!sym(time_col) <= time_limit * 365, 1, 0)
    )
  
  # Filter out rows with missing or invalid data
  data_filtered <- data_filtered %>%
    filter(!is.na(!!sym(risk_col)) & !is.na(event_status) & !is.na(censored_time))
  
  # If no events or no controls exist in the data, return NA
  if (length(unique(data_filtered$event_status)) < 2) {
    return(list(
      AUC = NA, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Not applicable", Cases = NA, Controls = NA
    ))
  }
  
  # Calculate ROC and AUC
  roc_curve <- roc(data_filtered$event_status, data_filtered[[risk_col]], levels = c(0, 1), direction = "<")
  auc_value <- as.numeric(auc(roc_curve))
  
  # Try to find the cutoff for specificity target 0.9
  cutoff_method <- "Specificity 0.9"
  optimal_cutoff <- tryCatch(
    {
      coords(roc_curve, x = 0.9, input = "specificity", ret = "threshold", transpose = TRUE)[1]
    },
    error = function(e) {
      NA
    }
  )
  
  # If the cutoff for specificity 0.9 is NA, try specificity 0.8
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Specificity 0.8"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = 0.8, input = "specificity", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the cutoff for specificity 0.8 is also NA, use the optimal cutoff
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Optimal Cutoff"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = "best", best.method = "closest.topleft", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the optimal_cutoff is not valid, return NA for metrics
  if (is.na(optimal_cutoff)) {
    return(list(
      AUC = auc_value, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Failed", Cases = sum(data_filtered$event_status == 1),
      Controls = sum(data_filtered$event_status == 0)
    ))
  }

  # Calculate predictions based on the new cutoff
  pred_class <- ifelse(data_filtered[[risk_col]] >= optimal_cutoff, 1, 0)

  # Calculate confusion matrix statistics based on the new cutoff
  confusion_mat <- table(Predicted = pred_class, Actual = data_filtered$event_status)

  # If confusion matrix is not 2x2, set metrics to NA
  if (!all(c(0, 1) %in% rownames(confusion_mat)) || !all(c(0, 1) %in% colnames(confusion_mat))) {
    sensitivity <- NA
    specificity <- NA
    ppv <- NA
    npv <- NA
  } else {
    sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
    specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])
    ppv <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
    npv <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  }

  # Bootstrapping AUC and C-statistic for confidence intervals
  auc_values <- numeric(n_bootstrap)
  c_stat_values <- numeric(n_bootstrap)

  bootstrapped_results <- foreach(i = 1:n_bootstrap, .combine = rbind, .packages = c("pROC", "survival")) %dopar% {
    bootstrap_sample <- data_filtered[sample(1:nrow(data_filtered), replace = TRUE), ]

    if (length(unique(bootstrap_sample$event_status)) < 2) {
      return(c(NA, NA))
    }

    roc_curve <- roc(bootstrap_sample$event_status, bootstrap_sample[[risk_col]])
    auc_val <- as.numeric(auc(roc_curve))

    cox_model_boot <- coxph(Surv(bootstrap_sample$censored_time, bootstrap_sample$event_status) ~ bootstrap_sample[[risk_col]], data = bootstrap_sample)
    c_stat_val <- as.numeric(summary(cox_model_boot)$concordance[1])

    return(c(auc_val, c_stat_val))
  }

  auc_values <- bootstrapped_results[, 1]
  c_stat_values <- bootstrapped_results[, 2]

  # Calculate 95% confidence intervals
  auc_ci <- quantile(auc_values[!is.na(auc_values)], probs = c(0.025, 0.975), na.rm = TRUE)
  c_stat_ci <- quantile(c_stat_values[!is.na(c_stat_values)], probs = c(0.025, 0.975), na.rm = TRUE)

  # Calculate Harrell's C-statistic for the full dataset
  cox_model <- coxph(Surv(censored_time, event_status) ~ data_filtered[[risk_col]], data = data_filtered)
  c_stat <- as.numeric(summary(cox_model)$concordance[1])

  # Record the end time
  end_time <- Sys.time()
  total_runtime <- end_time - start_time

  message("Number of bootstrap iterations run:", n_bootstrap)
  message("Total runtime for the bootstrapping process:", total_runtime, "seconds")

  # Return the metrics
  return(list(
    AUC = auc_value, AUC_Lower = auc_ci[1], AUC_Upper = auc_ci[2], 
    C_Statistic = c_stat, C_Stat_Lower = c_stat_ci[1], C_Stat_Upper = c_stat_ci[2],
    Sensitivity = sensitivity, Specificity = specificity, PPV = ppv,
    NPV = npv, Optimal_Cutoff = optimal_cutoff, Cutoff_Method = cutoff_method,
    Cases = sum(data_filtered$event_status == 1), Controls = sum(data_filtered$event_status == 0)
  ))
}

# Function to summarize metrics for each racial group
summarize_risk_metrics <- function(data, race_label, time_limit, n_bootstrap = 5000) {
  metrics <- calculate_metrics_with_bootstrap(data, paste0("risk_", time_limit, "_years"), paste0("outcome_", time_limit, "_years"), "time_to_event", time_limit, n_bootstrap)
  
  return(data.frame(
    Race = race_label,
    Time_Horizon = paste0(time_limit, " Years"),
    AUC = metrics$AUC,
    AUC_Lower_CI = metrics$AUC_Lower,
    AUC_Upper_CI = metrics$AUC_Upper,
    Harrell_C_Statistic = metrics$C_Statistic,
    C_Stat_Lower_CI = metrics$C_Stat_Lower,
    C_Stat_Upper_CI = metrics$C_Stat_Upper,
    Sensitivity = metrics$Sensitivity,
    Specificity = metrics$Specificity,
    PPV = metrics$PPV,
    NPV = metrics$NPV,
    Optimal_Cutoff = metrics$Optimal_Cutoff,
    Cutoff_Method = metrics$Cutoff_Method,
    Cases = metrics$Cases,
    Controls = metrics$Controls
  ))
}

# Evaluate metrics for each racial group and time horizon
results_all_2yr <- summarize_risk_metrics(consistent_data, "All Races", 2, n_bootstrap = 5000)
results_all_5yr <- summarize_risk_metrics(consistent_data, "All Races", 5, n_bootstrap = 5000)
results_black_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 2, n_bootstrap = 5000)
results_black_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 5, n_bootstrap = 5000)
results_white_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 2, n_bootstrap = 5000)
results_white_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 5, n_bootstrap = 5000)
results_asian_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 2, n_bootstrap = 5000)
results_asian_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 5, n_bootstrap = 5000)

# Combine results including "All Races" for the final table
final_results <- bind_rows(
  results_all_2yr, results_all_5yr,
  results_black_2yr, results_black_5yr,
  results_white_2yr, results_white_5yr,
  results_asian_2yr, results_asian_5yr
)

# Exclude "All Races" for the forest plot
final_results_filtered_CKD2009 <- final_results %>%
  filter(Race != "All Races")

# Display the final results table including "All Races"
print(final_results)

# Function to plot forest plot for metrics
plot_forest <- function(results_df, metric, lower_ci, upper_ci, title, reference_line) {
  ggplot(results_df, aes_string(x = metric, y = "Race")) +
    geom_point(size = 3, shape = 16, color = "blue") +  # Metric point estimates
    geom_errorbarh(aes_string(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  # 95% CI
    geom_vline(xintercept = reference_line, linetype = "dashed", color = "red") +  # Reference line
    facet_wrap(~ Time_Horizon, scales = "free_y") +  # Separate panels for each time horizon
    labs(
      title = title,
      x = metric,
      y = "Race"
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 14, face = "bold"),
      axis.text.x = element_text(size = 14),
      strip.text = element_text(size = 23, face = "bold"),
      panel.spacing = unit(1, "lines"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
    )
}

# Plot the forest plots for AUC and Harrell's C-statistic using the filtered data
forest_plot_auc <- plot_forest(final_results_filtered_CKD2009, "AUC", "AUC_Lower_CI", "AUC_Upper_CI", "", reference_line = 0.5)
forest_plot_cstat <- plot_forest(final_results_filtered_CKD2009, "Harrell_C_Statistic", "C_Stat_Lower_CI", "C_Stat_Upper_CI", "", reference_line = 0.5)

# Display the forest plots
print(forest_plot_auc)
print(forest_plot_cstat)

# Save the AUC forest plot
ggsave("CKD2009_VHR_forest_plot_auc_filtered.png", plot = forest_plot_auc, width = 10, height = 8, dpi = 300)

# Save the Harrell's C-statistic forest plot
ggsave("CKD2009_VHR_forest_plot_cstat_filtered.png", plot = forest_plot_cstat, width = 10, height = 8, dpi = 300)

# Stop the parallel backend after use
stopCluster(cl)


```

#### MDRD

```{r}
# Install doParallel package if it's not installed
# install.packages("doParallel")

# Load the parallel processing libraries
library(doParallel)

# Set up parallel backend to use multiple processors
cores <- detectCores() - 1  # Detect the number of cores and use all but one
cl <- makeCluster(cores)
registerDoParallel(cl)

# Load necessary libraries
library(dplyr)
library(survival)


# Step 4: Define the formula for calculating βsum (log hazard)
calculate_beta_sum <- function(age, sex, eGFR, logACR) {
  (-0.2201 * (age / 10 - 7.036)) +
  (0.2467 * (ifelse(sex == "Male", 1, 0) - 0.5642)) -
  (0.5567 * (eGFR / 5 - 7.222)) +
  (0.4510 * (logACR - 5.137))
}

# Apply the formula to calculate βsum
complete_cases <- complete_cases %>%
  mutate(beta_sum = calculate_beta_sum(age_precise, sex_at_birth, eGFR_MDRD, logACR))

# Remove any rows with infinite or NA beta_sum
complete_cases <- complete_cases %>%
  filter(is.finite(beta_sum) & !is.na(beta_sum))

# Step 5: Calculate the risk for two and five years using the updated formulas
complete_cases <- complete_cases %>%
  mutate(
    risk_2_years = 100 * (1 - 0.975^exp(beta_sum)),  # Two-Year Risk calculation
    risk_5_years = 100 * (1 - 0.9240^exp(beta_sum))  # Five-Year Risk calculation
  )

# Save the data before filtering
before_filtering <- complete_cases

# Step 6: Apply the filtering to create consistent_data
consistent_data <- complete_cases %>%
  filter(!is.na(risk_5_years) & !is.na(risk_2_years))

# Step 7: Define and create the 2-year and 5-year outcomes based on disease_status and time_to_event
consistent_data <- consistent_data %>%
  mutate(
    outcome_2_years = ifelse(disease_status == 1 & time_to_event <= 2 * 365.25, 1, 0),
    outcome_5_years = ifelse(disease_status == 1 & time_to_event <= 5 * 365.25, 1, 0)
  )

# Find the rows that were removed by comparing before and after datasets
removed_rows <- anti_join(before_filtering, consistent_data, by = "person_id")

# Print the removed rows
if (nrow(removed_rows) > 0) {
  cat("Rows that were removed during filtering:\n")
  print(removed_rows)
} else {
  cat("No rows were removed during filtering.\n")
}

# Step 8: Verify the risk values
summary(consistent_data$risk_5_years)
summary(consistent_data$risk_2_years)

# Count the number of person_id entries with event == 1 and event == 0
event_count <- consistent_data %>%
  group_by(event) %>%
  summarise(count = n_distinct(person_id))

# Print the results
cat("Number of person_id with event == 1:", event_count$count[event_count$event == 1], "\n")
cat("Number of person_id with event == 0:", event_count$count[event_count$event == 0], "\n")

# Check the event distribution for the 2-year and 5-year outcomes
cat("\n2-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_2_years))

cat("\n5-Year Outcome Distribution:\n")
print(table(consistent_data$outcome_5_years))


# Evaluation
# Load necessary libraries
library(dplyr)
library(pROC)
library(survival)
library(foreach)
library(doParallel)
library(ggplot2)

# Function to calculate metrics with bootstrapping and specificity adjustment
calculate_metrics_with_bootstrap <- function(data, risk_col, outcome_col, time_col, time_limit, n_bootstrap = 5000) {
  
  # Record the start time
  start_time <- Sys.time()
  
  # Apply censoring: keep all data but treat events beyond the time limit as censored
  data_filtered <- data %>%
    mutate(
      censored_time = pmin(!!sym(time_col), time_limit * 365),
      event_status = ifelse(!!sym(outcome_col) == 1 & !!sym(time_col) <= time_limit * 365, 1, 0)
    )
  
  # Filter out rows with missing or invalid data
  data_filtered <- data_filtered %>%
    filter(!is.na(!!sym(risk_col)) & !is.na(event_status) & !is.na(censored_time))
  
  # If no events or no controls exist in the data, return NA
  if (length(unique(data_filtered$event_status)) < 2) {
    return(list(
      AUC = NA, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Not applicable", Cases = NA, Controls = NA
    ))
  }
  
  # Calculate ROC and AUC
  roc_curve <- roc(data_filtered$event_status, data_filtered[[risk_col]], levels = c(0, 1), direction = "<")
  auc_value <- as.numeric(auc(roc_curve))
  
  # Try to find the cutoff for specificity target 0.9
  cutoff_method <- "Specificity 0.9"
  optimal_cutoff <- tryCatch(
    {
      coords(roc_curve, x = 0.9, input = "specificity", ret = "threshold", transpose = TRUE)[1]
    },
    error = function(e) {
      NA
    }
  )
  
  # If the cutoff for specificity 0.9 is NA, try specificity 0.8
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Specificity 0.8"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = 0.8, input = "specificity", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the cutoff for specificity 0.8 is also NA, use the optimal cutoff
  if (is.na(optimal_cutoff)) {
    cutoff_method <- "Optimal Cutoff"
    optimal_cutoff <- tryCatch(
      {
        coords(roc_curve, x = "best", best.method = "closest.topleft", ret = "threshold", transpose = TRUE)[1]
      },
      error = function(e) {
        NA
      }
    )
  }
  
  # If the optimal_cutoff is not valid, return NA for metrics
  if (is.na(optimal_cutoff)) {
    return(list(
      AUC = auc_value, AUC_Lower = NA, AUC_Upper = NA, C_Statistic = NA,
      C_Stat_Lower = NA, C_Stat_Upper = NA, Sensitivity = NA,
      Specificity = NA, PPV = NA, NPV = NA, Optimal_Cutoff = NA,
      Cutoff_Method = "Failed", Cases = sum(data_filtered$event_status == 1),
      Controls = sum(data_filtered$event_status == 0)
    ))
  }

  # Calculate predictions based on the new cutoff
  pred_class <- ifelse(data_filtered[[risk_col]] >= optimal_cutoff, 1, 0)

  # Calculate confusion matrix statistics based on the new cutoff
  confusion_mat <- table(Predicted = pred_class, Actual = data_filtered$event_status)

  # If confusion matrix is not 2x2, set metrics to NA
  if (!all(c(0, 1) %in% rownames(confusion_mat)) || !all(c(0, 1) %in% colnames(confusion_mat))) {
    sensitivity <- NA
    specificity <- NA
    ppv <- NA
    npv <- NA
  } else {
    sensitivity <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
    specificity <- confusion_mat[1, 1] / sum(confusion_mat[, 1])
    ppv <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
    npv <- confusion_mat[1, 1] / sum(confusion_mat[1, ])
  }

  # Bootstrapping AUC and C-statistic for confidence intervals
  auc_values <- numeric(n_bootstrap)
  c_stat_values <- numeric(n_bootstrap)

  bootstrapped_results <- foreach(i = 1:n_bootstrap, .combine = rbind, .packages = c("pROC", "survival")) %dopar% {
    bootstrap_sample <- data_filtered[sample(1:nrow(data_filtered), replace = TRUE), ]

    if (length(unique(bootstrap_sample$event_status)) < 2) {
      return(c(NA, NA))
    }

    roc_curve <- roc(bootstrap_sample$event_status, bootstrap_sample[[risk_col]])
    auc_val <- as.numeric(auc(roc_curve))

    cox_model_boot <- coxph(Surv(bootstrap_sample$censored_time, bootstrap_sample$event_status) ~ bootstrap_sample[[risk_col]], data = bootstrap_sample)
    c_stat_val <- as.numeric(summary(cox_model_boot)$concordance[1])

    return(c(auc_val, c_stat_val))
  }

  auc_values <- bootstrapped_results[, 1]
  c_stat_values <- bootstrapped_results[, 2]

  # Calculate 95% confidence intervals
  auc_ci <- quantile(auc_values[!is.na(auc_values)], probs = c(0.025, 0.975), na.rm = TRUE)
  c_stat_ci <- quantile(c_stat_values[!is.na(c_stat_values)], probs = c(0.025, 0.975), na.rm = TRUE)

  # Calculate Harrell's C-statistic for the full dataset
  cox_model <- coxph(Surv(censored_time, event_status) ~ data_filtered[[risk_col]], data = data_filtered)
  c_stat <- as.numeric(summary(cox_model)$concordance[1])

  # Record the end time
  end_time <- Sys.time()
  total_runtime <- end_time - start_time

  message("Number of bootstrap iterations run:", n_bootstrap)
  message("Total runtime for the bootstrapping process:", total_runtime, "seconds")

  # Return the metrics
  return(list(
    AUC = auc_value, AUC_Lower = auc_ci[1], AUC_Upper = auc_ci[2], 
    C_Statistic = c_stat, C_Stat_Lower = c_stat_ci[1], C_Stat_Upper = c_stat_ci[2],
    Sensitivity = sensitivity, Specificity = specificity, PPV = ppv,
    NPV = npv, Optimal_Cutoff = optimal_cutoff, Cutoff_Method = cutoff_method,
    Cases = sum(data_filtered$event_status == 1), Controls = sum(data_filtered$event_status == 0)
  ))
}

# Function to summarize metrics for each racial group
summarize_risk_metrics <- function(data, race_label, time_limit, n_bootstrap = 5000) {
  metrics <- calculate_metrics_with_bootstrap(data, paste0("risk_", time_limit, "_years"), paste0("outcome_", time_limit, "_years"), "time_to_event", time_limit, n_bootstrap)
  
  return(data.frame(
    Race = race_label,
    Time_Horizon = paste0(time_limit, " Years"),
    AUC = metrics$AUC,
    AUC_Lower_CI = metrics$AUC_Lower,
    AUC_Upper_CI = metrics$AUC_Upper,
    Harrell_C_Statistic = metrics$C_Statistic,
    C_Stat_Lower_CI = metrics$C_Stat_Lower,
    C_Stat_Upper_CI = metrics$C_Stat_Upper,
    Sensitivity = metrics$Sensitivity,
    Specificity = metrics$Specificity,
    PPV = metrics$PPV,
    NPV = metrics$NPV,
    Optimal_Cutoff = metrics$Optimal_Cutoff,
    Cutoff_Method = metrics$Cutoff_Method,
    Cases = metrics$Cases,
    Controls = metrics$Controls
  ))
}

# Evaluate metrics for each racial group and time horizon
results_all_2yr <- summarize_risk_metrics(consistent_data, "All Races", 2, n_bootstrap = 5000)
results_all_5yr <- summarize_risk_metrics(consistent_data, "All Races", 5, n_bootstrap = 5000)
results_black_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 2, n_bootstrap = 5000)
results_black_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Black or African American"), "Black or African American", 5, n_bootstrap = 5000)
results_white_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 2, n_bootstrap = 5000)
results_white_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "White"), "White", 5, n_bootstrap = 5000)
results_asian_2yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 2, n_bootstrap = 5000)
results_asian_5yr <- summarize_risk_metrics(consistent_data %>% filter(race == "Asian"), "Asian", 5, n_bootstrap = 5000)

# Combine results including "All Races" for the final table
final_results <- bind_rows(
  results_all_2yr, results_all_5yr,
  results_black_2yr, results_black_5yr,
  results_white_2yr, results_white_5yr,
  results_asian_2yr, results_asian_5yr
)

# Exclude "All Races" for the forest plot
final_results_filtered_MDRD <- final_results %>%
  filter(Race != "All Races")

# Display the final results table including "All Races"
print(final_results)

# Function to plot forest plot for metrics
plot_forest <- function(results_df, metric, lower_ci, upper_ci, title, reference_line) {
  ggplot(results_df, aes_string(x = metric, y = "Race")) +
    geom_point(size = 3, shape = 16, color = "blue") +  # Metric point estimates
    geom_errorbarh(aes_string(xmin = lower_ci, xmax = upper_ci), height = 0.2, color = "black") +  # 95% CI
    geom_vline(xintercept = reference_line, linetype = "dashed", color = "red") +  # Reference line
    facet_wrap(~ Time_Horizon, scales = "free_y") +  # Separate panels for each time horizon
    labs(
      title = title,
      x = metric,
      y = "Race"
    ) +
    theme_minimal() +
    theme(
      axis.text.y = element_text(size = 14, face = "bold"),
      axis.text.x = element_text(size = 14),
      strip.text = element_text(size = 23, face = "bold"),
      panel.spacing = unit(1, "lines"),
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5)
    )
}

# Plot the forest plots for AUC and Harrell's C-statistic using the filtered data
forest_plot_auc <- plot_forest(final_results_filtered_MDRD, "AUC", "AUC_Lower_CI", "AUC_Upper_CI", "", reference_line = 0.5)
forest_plot_cstat <- plot_forest(final_results_filtered_MDRD, "Harrell_C_Statistic", "C_Stat_Lower_CI", "C_Stat_Upper_CI", "", reference_line = 0.5)

# Display the forest plots
print(forest_plot_auc)
print(forest_plot_cstat)

# Save the AUC forest plot
ggsave("MDRD_VHR_forest_plot_auc_filtered.png", plot = forest_plot_auc, width = 10, height = 8, dpi = 300)

# Save the Harrell's C-statistic forest plot
ggsave("MDRD_VHR_forest_plot_cstat_filtered.png", plot = forest_plot_cstat, width = 10, height = 8, dpi = 300)

# Stop the parallel backend after use
stopCluster(cl)


```

##### Group AUC Comparison

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Assuming final_results_filtered_MDRD, final_results_filtered_CKD2009, and final_results_filtered_CKD2021 
# are the data frames containing the results for each model

# Add a column to identify each model
final_results_filtered_MDRD$Model <- "MDRD"
final_results_filtered_CKD2009$Model <- "CKD-EPI-2009"
final_results_filtered_CKD2021$Model <- "CKD-EPI-2021"

# Combine all the data frames
combined_results <- bind_rows(
  final_results_filtered_MDRD,
  final_results_filtered_CKD2009,
  final_results_filtered_CKD2021
)

# Reorder the levels for the Race factor to start with Black, followed by White, then Asian
combined_results$Race <- factor(combined_results$Race, levels = c("Black or African American", "White", "Asian"))

# Plotting function to create facets by time horizon and race, comparing the AUC of each model
plot_auc_comparison <- function(data) {
  ggplot(data, aes(x = Model, y = AUC, color = Model)) +
    geom_point(size = 6, stroke = 1.5) +  # Larger points with bold outline
    geom_errorbar(aes(ymin = AUC_Lower_CI, ymax = AUC_Upper_CI), width = 0.3, linewidth = 1.5) +  # Thicker error bars
    facet_grid(Time_Horizon ~ Race, scales = "free") +
    labs(
      title = "AUC Comparison Across Models",
      x = "Model",
      y = "AUC"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 14, angle = 45, hjust = 1, face = "bold"),  # Larger and bold text
      axis.text.y = element_text(size = 14, face = "bold"),  # Larger and bold text
      axis.title.x = element_text(size = 16, face = "bold"),  # Bold axis title
      axis.title.y = element_text(size = 16, face = "bold"),  # Bold axis title
      strip.text = element_text(size = 18, face = "bold"),  # Larger and bold facet labels for Race
      strip.placement = "outside",  # Move strip text outside the plot area
      strip.background = element_blank(),  # Remove default strip background
      plot.title = element_text(size = 20, face = "bold", hjust = 0.5, margin = margin(b = 15)),  # Add space below the title
      legend.title = element_text(size = 14, face = "bold"),  # Bold legend title
      legend.text = element_text(size = 12, face = "bold"),   # Bold legend text
      panel.spacing = unit(1.5, "lines")  # Increase spacing between panels
    ) +
    scale_color_manual(values = c("MDRD" = "blue", "CKD-EPI-2009" = "green", "CKD-EPI-2021" = "red")) +  # Distinct colors
    guides(color = guide_legend(override.aes = list(size = 5)))  # Larger legend key sizes
}

# Create the plot using the combined results
auc_comparison_plot <- plot_auc_comparison(combined_results)

# Display the plot
print(auc_comparison_plot)

# Save the plot as a high-resolution image
ggsave("AUC_Comparison_Facet_Plot.png", plot = auc_comparison_plot, width = 14, height = 8, dpi = 300)

```

##### Group c statistics Comparison

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)

# Assuming final_results_filtered_MDRD, final_results_filtered_CKD2009, and final_results_filtered_CKD2021 
# are the data frames containing the results for each model

# Add a column to identify each model
final_results_filtered_MDRD$Model <- "MDRD"
final_results_filtered_CKD2009$Model <- "CKD-EPI-2009"
final_results_filtered_CKD2021$Model <- "CKD-EPI-2021"

# Combine all the data frames
combined_results <- bind_rows(
  final_results_filtered_MDRD,
  final_results_filtered_CKD2009,
  final_results_filtered_CKD2021
)

# Reorder the levels for the Race factor to start with Black, followed by White, then Asian
combined_results$Race <- factor(combined_results$Race, levels = c("Black or African American", "White", "Asian"))

# Plotting function to create facets by time horizon and race, comparing the Harrell's C-statistic of each model
plot_cstat_comparison <- function(data) {
  ggplot(data, aes(x = Model, y = Harrell_C_Statistic, color = Model)) +
    geom_point(size = 4) +
    geom_errorbar(aes(ymin = C_Stat_Lower_CI, ymax = C_Stat_Upper_CI), width = 0.2, linewidth = 1.2) +  # Use linewidth for thicker error bars
    facet_grid(Time_Horizon ~ Race, scales = "free") +
    labs(
      title = "Harrell's C-Statistic Comparison Across Models",
      x = "Model",
      y = "Harrell's C-Statistic"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(size = 14, angle = 45, hjust = 1, face = "bold"),  # Larger and bold text
      axis.text.y = element_text(size = 14, face = "bold"),  # Larger and bold text
      axis.title.x = element_text(size = 16, face = "bold"),  # Bold axis title
      axis.title.y = element_text(size = 16, face = "bold"),  # Bold axis title
      strip.text = element_text(size = 16, face = "bold"),  # Bold and larger facet labels
      strip.placement = "outside",  # Place strip labels outside the plot area
      strip.background = element_blank(),  # Remove default strip background
      plot.title = element_text(size = 20, face = "bold", hjust = 0.5, margin = margin(b = 20)),  # Add space below the title
      legend.title = element_text(size = 14, face = "bold"),  # Bold legend title
      legend.text = element_text(size = 12, face = "bold"),   # Bold legend text
      panel.spacing = unit(1.5, "lines")  # Increase space between panels for clarity
    ) +
    scale_color_manual(values = c("MDRD" = "blue", "CKD-EPI-2009" = "green", "CKD-EPI-2021" = "red")) +  # Distinct colors
    guides(color = guide_legend(override.aes = list(size = 4)))  # Larger legend key sizes
}

# Create the plot using the combined results
cstat_comparison_plot <- plot_cstat_comparison(combined_results)

# Display the plot
print(cstat_comparison_plot)

# Save the plot as a high-resolution image
ggsave("C_Statistic_Comparison_Facet_Plot.png", plot = cstat_comparison_plot, width = 14, height = 8, dpi = 300)

```

# Model comparison: Observed vs predicted

```{r}
library(knitr)
library(dplyr)
library(tidyr)
library(lubridate)
library(purrr)
library(stringr)

#install.packages("survival")
#install.packages("survminer")

# Load the necessary libraries
library(survival)

# install.packages("RColorBrewer")
library(RColorBrewer)

# Install and load necessary packages
#install.packages("caret")
#install.packages("ggplot2")
library(caret)
library(ggplot2)

# Load necessary libraries
#library(pROC)



# Create the MDRD 60 data frame with updated observed and predicted values
mdrd_greaterthan60 <- data.frame(
  race = c("Asian", "Black or African American", "White"),
  
  # Observed and predicted 2-year event rates from the plot
  observed_2_years = c(28 / 2750, 177 / 14593, 207 / 56992),
  predicted_2_years = c(4 / 2750, 33 / 14593, 62 / 56992),
  
  # Observed and predicted 5-year event rates from the plot
  observed_5_years = c(35 / 2750, 283 / 14593, 321 / 56992),
  predicted_5_years = c(12 / 2750, 88 / 14593, 178 / 56992),
  
  # Counts and totals for observed 2-year data
  observed_count_2_years = c(28, 177, 207),
  observed_total_2_years = c(2750, 14593, 56992),
  
  # Counts and totals for predicted 2-year data
  predicted_count_2_years = c(4, 33, 62),
  predicted_total_2_years = c(2750, 14593, 56992),
  
  # Counts and totals for observed 5-year data
  observed_count_5_years = c(35, 283, 321),
  observed_total_5_years = c(2750, 14593, 56992),
  
  # Counts and totals for predicted 5-year data
  predicted_count_5_years = c(12, 88, 178),
  predicted_total_5_years = c(2750, 14593, 56992)
)



# Save the data frame to a CSV file
#write.csv(mdrd_60, "mdrd_60.csv", row.names = FALSE)


# Create the CKD-EPI-2009-50 data frame with updated observed and predicted values from the image
ckd_epi_2009_greaterthan60 <- data.frame(
  race = c("Asian", "Black or African American", "White"),
  
  # Observed and predicted 2-year event rates from the plot
  observed_2_years = c(28 / 2750, 177 / 14593, 207 / 56992),
  predicted_2_years = c(4 / 2750, 36 / 14593, 64 / 56992),
  
  # Observed and predicted 5-year event rates from the plot
  observed_5_years = c(35 / 2750, 283 / 14593, 321 / 56992),
  predicted_5_years = c(12 / 2750, 98 / 14593, 184 / 56992),
  
  # Counts and totals for observed 2-year data
  observed_count_2_years = c(28, 177, 207),
  observed_total_2_years = c(2750, 14593, 56992),
  
  # Counts and totals for predicted 2-year data
  predicted_count_2_years = c(4, 36, 64),
  predicted_total_2_years = c(2750, 14593, 56992),
  
  # Counts and totals for observed 5-year data
  observed_count_5_years = c(35, 283, 321),
  observed_total_5_years = c(2750, 14593, 56992),
  
  # Counts and totals for predicted 5-year data
  predicted_count_5_years = c(12, 98, 184),
  predicted_total_5_years = c(2750, 14593, 56992)
)


# Save the data frame to a CSV file
#write.csv(ckd_epi_2009_60, "ckd_epi_2009_50.csv", row.names = FALSE)


# Create the CKD-EPI-2021-60 data frame with updated observed and predicted values from the image
ckd_epi_2021_greaterthan60 <- data.frame(
  race = c("Asian", "Black or African American", "White"),
  
  # Observed and predicted 2-year event rates from the plot
  observed_2_years = c(28 / 2750, 177 / 14593, 207 / 56992),
  predicted_2_years = c(4 / 2750, 42 / 14593, 55 / 56992),
  
  # Observed and predicted 5-year event rates from the plot
  observed_5_years = c(35 / 2750, 283 / 14593, 321 / 56992),
  predicted_5_years = c(11 / 2750, 114 / 14593, 155 / 56992),
  
  # Counts and totals for observed 2-year data
  observed_count_2_years = c(28, 177, 207),
  observed_total_2_years = c(2750, 14593, 56992),
  
  # Counts and totals for predicted 2-year data
  predicted_count_2_years = c(4, 42, 55),
  predicted_total_2_years = c(2750, 14593, 56992),
  
  # Counts and totals for observed 5-year data
  observed_count_5_years = c(35, 283, 321),
  observed_total_5_years = c(2750, 14593, 56992),
  
  # Counts and totals for predicted 5-year data
  predicted_count_5_years = c(11, 114, 155),
  predicted_total_5_years = c(2750, 14593, 56992)
)


# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# Combine the datasets into a single data frame with specified model names
combined_data <- bind_rows(
  mdrd_greaterthan60 %>% mutate(model = "MDRD"),
  ckd_epi_2009_greaterthan60 %>% mutate(model = "CKD-EPI 2009"),
  ckd_epi_2021_greaterthan60 %>% mutate(model = "CKD-EPI 2021")
)

# Create a separate column for the observed and predicted counts in the long format
combined_long <- combined_data %>%
  pivot_longer(
    cols = c(observed_2_years, predicted_2_years, observed_5_years, predicted_5_years),
    names_to = "measure_time",
    values_to = "probability"
  ) %>%
  # Split measure_time correctly into measure and time_period
  separate(measure_time, into = c("measure", "time_period"), sep = "_", extra = "drop", fill = "right") %>%
  mutate(
    measure = ifelse(measure == "observed", "Observed", "Predicted"),
    time_period = ifelse(time_period == "2", "2 Years", "5 Years"),
    observed_count = case_when(
      time_period == "2 Years" ~ observed_count_2_years,
      time_period == "5 Years" ~ observed_count_5_years
    ),
    observed_total = case_when(
      time_period == "2 Years" ~ observed_total_2_years,
      time_period == "5 Years" ~ observed_total_5_years
    ),
    predicted_count = case_when(
      time_period == "2 Years" ~ predicted_count_2_years,
      time_period == "5 Years" ~ predicted_count_5_years
    ),
    predicted_total = case_when(
      time_period == "2 Years" ~ predicted_total_2_years,
      time_period == "5 Years" ~ predicted_total_5_years
    ),
    label = ifelse(measure == "Observed", 
                   paste0(observed_count, "/", observed_total), 
                   paste0(predicted_count, "/", predicted_total))
  )

# Ensure that 'model' and 'race' columns are in the correct order
combined_long$model <- factor(combined_long$model, levels = c("MDRD", "CKD-EPI 2009", "CKD-EPI 2021"))
combined_long$race <- factor(combined_long$race, levels = c("White", "Black or African American", "Asian"))

# Create a dataset for the common observed bars for each race and time period
observed_data <- combined_long %>%
  filter(measure == "Observed") %>%
  group_by(race, time_period) %>%
  summarise(probability = mean(probability), observed_count = mean(observed_count), observed_total = mean(observed_total), .groups = 'drop') %>%
  mutate(model = "Observed", measure = "Observed", 
         label = paste0(observed_count, "/", observed_total))  # Add label for observed counts

# Combine observed and predicted data for the plot
combined_for_plot <- bind_rows(combined_long %>% filter(measure == "Predicted"), observed_data)

# Ensure 'model' is ordered correctly with "Observed" appearing first
combined_for_plot$model <- factor(combined_for_plot$model, levels = c("Observed", "MDRD", "CKD-EPI 2009", "CKD-EPI 2021"))

# Define colors for a more professional, grayscale-like palette
colors <- c("Observed" = "black", "Predicted" = "gray70")

# Plot with the common observed bar for each race and time period
final_plot <- ggplot(combined_for_plot, aes(x = model, y = probability * 100, fill = measure)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.6) +  # Reduced bar width for better clarity
  geom_text(aes(label = label), 
            position = position_dodge(width = 0.6), 
            vjust = 1.5, size = 4.5, color = "white", fontface = "bold") +  # Adjust label size, position, and color
  facet_wrap(~ race + time_period, ncol = 2, scales = "free_y", shrink = TRUE) +  # Use 'ncol = 2' to get 2 graphs per row
  labs(
    title = "Observed vs Predicted Probability of Kidney Failure by Race and Model",
    x = "Model Type",
    y = "Probability of Event (%)",
    fill = "Measurement"
  ) +
  scale_fill_manual(values = colors, 
                    labels = c("Observed", "Predicted")) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Increase x-axis text size
    axis.text.y = element_text(size = 12),  # Increase y-axis text size
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),  # Increase title size and bold it
    legend.position = "bottom",
    legend.text = element_text(size = 12),  # Adjust legend text size
    strip.text = element_text(size = 14, face = "bold"),  # Adjust facet label font size and make it bold
    panel.spacing = unit(1.5, "lines"),  # Increase spacing between facets for clarity
    panel.grid.major = element_blank(),  # Remove major gridlines for a cleaner look
    panel.grid.minor = element_blank(),  # Remove minor gridlines
    axis.line = element_line(color = "black"),  # Add axis lines for better separation
    legend.title = element_text(size = 12, face = "bold")  # Add bold legend title
  ) +
  coord_cartesian(ylim = c(0, NA))  # Let the y-axis automatically adjust per facet

# Display the improved plot
print(final_plot)

# Save the improved plot with increased resolution and adjusted dimensions for publication
ggsave("Lancet_Style_Observed_vs_Predicted_Probability_Figures_Inside_Bars.png", 
       plot = final_plot, dpi = 300, width = 16, height = 12)  # Adjusted width and height for publication

```

# Part 2

# MISSING DATA CHECK

## Remove Features with count less than 10

left with 43 predictors (excluding person_id, disease_status, time_to_event, and only counting 1 eGFR)

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)

# Load dataset
filtered_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine.csv")
colnames(filtered_person_with_summary)

# Step 1: Select and rename relevant columns
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(-age_reported,
         -Glomerular.filtration.rate.1.73.sq.M.predicted..Volume.Rate.Area..in.Serum..Plasma.or.Blood.by.Creatinine.based.formula..MDRD.,
         -Tobacco.smoking.status,
         -height,
         -weight,
         -gender,
         -Creatinine..Mass.volume..in.Body.fluid,
         -highest_smoking_status_rank) 

# Step 2: Filter out non-numeric columns and pivot longer
person_long <- filtered_person_with_summary %>%
  select(person_id, disease_status, where(is.numeric)) %>%
  pivot_longer(
    cols = -c(person_id, disease_status),
    names_to = "variable",
    values_to = "value"
  ) %>%
  filter(!is.na(value) & value != 0)  # Remove rows where the value is NA or zero

# Step 3: Count occurrences of disease_status for each variable
status_counts <- person_long %>%
  group_by(variable, disease_status) %>%
  summarise(count = n_distinct(person_id), .groups = 'drop')

# Step 4: Pivot the summary table to a wide format
summary_wide <- status_counts %>%
  pivot_wider(
    names_from = disease_status,
    values_from = count,
    names_prefix = "disease_status_",
    values_fill = list(count = 0)
  )

# Step 5: Filter out variables that have less than a count of 10 for either disease_status_0 or disease_status_1
filtered_summary <- summary_wide %>%
  filter(disease_status_0 >= 10 & disease_status_1 >= 10)

# Step 6: Extract the variable names that passed the filter
remaining_variables <- filtered_summary$variable

# Step 7: Retain only the person_id, disease_status, race, sex_at_birth, ethnicity, and the remaining variables
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(person_id, disease_status, race, sex_at_birth, ethnicity, all_of(remaining_variables))

# Step 8: Identify the dropped variables
all_variables <- names(select(filtered_person_with_summary, where(is.numeric)))
dropped_variables <- setdiff(all_variables, remaining_variables)

# Print the dropped variables if needed
#print(dropped_variables)

# View the updated column names
colnames(filtered_person_with_summary)

```

# Remove Conditions with perfect separation

48 with 43 predictors. No conditions were removed due to perfect separation

```{r}
# Check for perfect separation: columns with all 0s or all 1s
perfect_separation_cols <- filtered_person_with_summary %>%
  select(where(is.numeric)) %>%  # Select numeric columns (conditions are likely numeric binary)
  summarise_all(~ all(. == 0) | all(. == 1)) %>%  # Check for columns that are all 0s or all 1s
  pivot_longer(cols = everything(), names_to = "condition", values_to = "perfect_separation") %>%
  filter(perfect_separation) %>%  # Filter columns with perfect separation
  pull(condition)  # Get the names of these columns

# List the names of conditions with perfect separation
cat("Conditions removed due to perfect separation:\n")
print(perfect_separation_cols)

# Remove these columns from the dataset
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(-all_of(perfect_separation_cols))

# View the updated dataset without conditions that have perfect separation
print(colnames(filtered_person_with_summary))

```

# Check for multicolinearity

```{r}
# Load necessary libraries
library(dplyr)
library(corrr)
library(knitr)
library(kableExtra)

# Assuming filtered_person_with_summary is the dataset after filtration

# Step 1: Ensure that only numeric columns with variance are checked for correlation
filtered_data_no_constant <- filtered_person_with_summary %>%
  select(-person_id, -disease_status) %>%
  select(where(is.numeric)) %>%  # Ensure we are only dealing with numeric columns
  select_if(~ sd(., na.rm = TRUE) > 0)  # Ensure non-zero standard deviation

# Step 2: Calculate the correlation matrix for the filtered dataset
correlation_matrix <- filtered_data_no_constant %>%
  correlate(method = "pearson", use = "pairwise.complete.obs")

# Step 3: Identify pairs of variables with high correlations (e.g., |correlation| > 0.9)
highly_correlated_pairs <- correlation_matrix %>%
  stretch() %>%  # Convert the correlation matrix into a long format
  filter(abs(r) > 0.9, r != 1) %>%  # Keep only pairs with |correlation| > 0.9 and not self-correlation
  mutate(pair = paste(pmin(x, y), pmax(x, y), sep = "_")) %>%  # Create a unique identifier for pairs
  distinct(pair, .keep_all = TRUE) %>%  # Remove duplicates (e.g., (x,y) and (y,x))
  select(-pair)  # Remove the auxiliary 'pair' column

# Step 4: Prepare the table for the number of observations for each correlated pair
if (nrow(highly_correlated_pairs) > 0) {
  result_table <- data.frame(
    `Variable 1` = character(),
    `Variable 2` = character(),
    `Correlation` = numeric(),
    `Cases (Var 1)` = integer(),
    `Controls (Var 1)` = integer(),
    `Cases (Var 2)` = integer(),
    `Controls (Var 2)` = integer(),
    stringsAsFactors = FALSE
  )
  
  for (i in 1:nrow(highly_correlated_pairs)) {
    var1 <- highly_correlated_pairs$x[i]
    var2 <- highly_correlated_pairs$y[i]
    correlation <- highly_correlated_pairs$r[i]
    
    # Number of non-zero cases (disease_status == 1) and non-zero controls (disease_status == 0) for var1
    cases_var1 <- sum(filtered_person_with_summary$disease_status == 1 & 
                      filtered_person_with_summary[[var1]] != 0 & !is.na(filtered_person_with_summary[[var1]]))
    controls_var1 <- sum(filtered_person_with_summary$disease_status == 0 & 
                         filtered_person_with_summary[[var1]] != 0 & !is.na(filtered_person_with_summary[[var1]]))
    
    # Number of non-zero cases (disease_status == 1) and non-zero controls (disease_status == 0) for var2
    cases_var2 <- sum(filtered_person_with_summary$disease_status == 1 & 
                      filtered_person_with_summary[[var2]] != 0 & !is.na(filtered_person_with_summary[[var2]]))
    controls_var2 <- sum(filtered_person_with_summary$disease_status == 0 & 
                         filtered_person_with_summary[[var2]] != 0 & !is.na(filtered_person_with_summary[[var2]]))
    
    # Add the results to the table
    result_table <- rbind(result_table, data.frame(
      `Variable 1` = var1,
      `Variable 2` = var2,
      `Correlation` = round(correlation, 2),  # Round correlation to 2 decimal places
      `Cases (Var 1)` = cases_var1,
      `Controls (Var 1)` = controls_var1,
      `Cases (Var 2)` = cases_var2,
      `Controls (Var 2)` = controls_var2
    ))
  }
  
  # Print the result table with formatting for publication
  print(result_table)
} else {
  cat("No highly correlated variable pairs found (|correlation| > 0.9).\n")
}

# Print the column names of the original dataset
print(colnames(filtered_person_with_summary))

```

### Remove correlated data

```{r}
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(-Iron.binding.capacity..Mass.volume..in.Serum.or.Plasma, -eGFR_ckd_epi_2009)

```

Remove MDRD eGFR

```{r}
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(-eGFR_MDRD)
```

### Recheck for multicolinearity

```{r}
# Load necessary libraries
library(dplyr)
library(corrr)
library(knitr)
library(kableExtra)

# Assuming filtered_person_with_summary is the dataset after filtration

# Step 1: Ensure that only numeric columns are checked for variance
filtered_data_no_constant <- filtered_person_with_summary %>%
  select(-person_id, -disease_status) %>%
  select(where(is.numeric)) %>%  # Ensure we are only dealing with numeric columns
  select_if(~ !all(is.na(.)) && sd(., na.rm = TRUE) > 0)  # Ensure non-zero standard deviation, no NA values, and proper data type

# Step 2: Calculate the correlation matrix for the filtered dataset
correlation_matrix <- filtered_data_no_constant %>%
  correlate(method = "pearson", use = "pairwise.complete.obs")

# Step 3: Identify pairs of variables with high correlations (e.g., |correlation| > 0.9)
highly_correlated_pairs <- correlation_matrix %>%
  stretch() %>%  # Convert the correlation matrix into a long format
  filter(abs(r) > 0.9, r != 1)  # Keep only pairs with |correlation| > 0.9 and not self-correlation

# Step 4: Prepare the table for the number of observations for each correlated pair
if (nrow(highly_correlated_pairs) > 0) {
  result_table <- data.frame(
    `Variable 1` = character(),
    `Variable 2` = character(),
    `Correlation` = numeric(),
    `Cases (Var 1)` = integer(),
    `Controls (Var 1)` = integer(),
    `Cases (Var 2)` = integer(),
    `Controls (Var 2)` = integer(),
    stringsAsFactors = FALSE
  )
  
  for (i in 1:nrow(highly_correlated_pairs)) {
    var1 <- highly_correlated_pairs$x[i]
    var2 <- highly_correlated_pairs$y[i]
    correlation <- highly_correlated_pairs$r[i]
    
    # Number of non-zero cases (disease_status == 1) and non-zero controls (disease_status == 0) for var1
    cases_var1 <- sum(filtered_person_with_summary$disease_status == 1 & 
                      filtered_person_with_summary[[var1]] != 0 & !is.na(filtered_person_with_summary[[var1]]))
    controls_var1 <- sum(filtered_person_with_summary$disease_status == 0 & 
                         filtered_person_with_summary[[var1]] != 0 & !is.na(filtered_person_with_summary[[var1]]))
    
    # Number of non-zero cases (disease_status == 1) and non-zero controls (disease_status == 0) for var2
    cases_var2 <- sum(filtered_person_with_summary$disease_status == 1 & 
                      filtered_person_with_summary[[var2]] != 0 & !is.na(filtered_person_with_summary[[var2]]))
    controls_var2 <- sum(filtered_person_with_summary$disease_status == 0 & 
                         filtered_person_with_summary[[var2]] != 0 & !is.na(filtered_person_with_summary[[var2]]))
    
    # Add the results to the table
    result_table <- rbind(result_table, data.frame(
      `Variable 1` = var1,
      `Variable 2` = var2,
      `Correlation` = round(correlation, 2),  # Round correlation to 2 decimal places
      `Cases (Var 1)` = cases_var1,
      `Controls (Var 1)` = controls_var1,
      `Cases (Var 2)` = cases_var2,
      `Controls (Var 2)` = controls_var2
    ))
  }
  
  # Print the result table with formatting for publication
  print(result_table)
} else {
  cat("No highly correlated variable pairs found (|correlation| > 0.9).\n")
}

# Print the column names of the original dataset
print(colnames(filtered_person_with_summary))

# Save the data frame to a CSV file
write.csv(filtered_person_with_summary, "filtered_person_with_summary_ml.csv", row.names = FALSE)


```

40 predictors

```{r}
# Load necessary libraries
library(dplyr)
colnames(filtered_person_with_summary)
# Assuming the race column is named 'race' in your dataset 'data_ml'
# Check the distribution of races in the 'race' column
race_distribution <- filtered_person_with_summary %>%
  group_by(race, disease_status) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# Print the race distribution
print(race_distribution)

# Save the filtered_person_with_summary dataframe as refiltered_person_with_summary.csv
write.csv(filtered_person_with_summary, file = "refiltered_person_with_summary.csv", row.names = FALSE)

```

Data cleaning

```{r}
#filtered_person_with_summary <- read.csv("refiltered_person_with_summary.csv")

# # Create binary columns for creatinine strata based on sex_at_birth and serum_creatinine
# filtered_person_with_summary$Low_Creatinine <- ifelse(
#   (filtered_person_with_summary$sex_at_birth == "Male" & filtered_person_with_summary$serum_creatinine < 0.7) |
#   (filtered_person_with_summary$sex_at_birth == "Female" & filtered_person_with_summary$serum_creatinine < 0.6), 1, 0)
# 
# filtered_person_with_summary$Normal_Creatinine <- ifelse(
#   (filtered_person_with_summary$sex_at_birth == "Male" & filtered_person_with_summary$serum_creatinine >= 0.7 & filtered_person_with_summary$serum_creatinine <= 1.3) |
#   (filtered_person_with_summary$sex_at_birth == "Female" & filtered_person_with_summary$serum_creatinine >= 0.6 & filtered_person_with_summary$serum_creatinine <= 1.1), 1, 0)
# 
# filtered_person_with_summary$High_Creatinine <- ifelse(
#   (filtered_person_with_summary$sex_at_birth == "Male" & filtered_person_with_summary$serum_creatinine > 1.3) |
#   (filtered_person_with_summary$sex_at_birth == "Female" & filtered_person_with_summary$serum_creatinine > 1.1), 1, 0)
# 
# # Remove the original serum_creatinine column
# filtered_person_with_summary <- filtered_person_with_summary[, !colnames(filtered_person_with_summary) %in% "serum_creatinine"]

# 
# # Create binary variables for CKD stages based on eGFR values
# filtered_person_with_summary$eGFR_Normal_or_Stage1 <- ifelse(filtered_person_with_summary$eGFR_ckd_epi_2021 >= 90, 1, 0)
# filtered_person_with_summary$eGFR_Stage2 <- ifelse(filtered_person_with_summary$eGFR_ckd_epi_2021 >= 60 & filtered_person_with_summary$eGFR_ckd_epi_2021 < 90, 1, 0)
# filtered_person_with_summary$eGFR_Stage3a <- ifelse(filtered_person_with_summary$eGFR_ckd_epi_2021 >= 45 & filtered_person_with_summary$eGFR_ckd_epi_2021 < 60, 1, 0)
# filtered_person_with_summary$eGFR_Stage3b <- ifelse(filtered_person_with_summary$eGFR_ckd_epi_2021 >= 30 & filtered_person_with_summary$eGFR_ckd_epi_2021 < 45, 1, 0)
# filtered_person_with_summary$eGFR_Stage4 <- ifelse(filtered_person_with_summary$eGFR_ckd_epi_2021 >= 15 & filtered_person_with_summary$eGFR_ckd_epi_2021 < 30, 1, 0)
# filtered_person_with_summary$eGFR_Stage5 <- ifelse(filtered_person_with_summary$eGFR_ckd_epi_2021 < 15, 1, 0)
# 
# # Remove the original eGFR_ckd_epi_2021 column
# filtered_person_with_summary <- filtered_person_with_summary[, !colnames(filtered_person_with_summary) %in% "eGFR_ckd_epi_2021"]
# 
# 

# # Remove the predictor Ferritin..Mass.volume..in.Serum.or.Plasma from the dataset
# filtered_person_with_summary <- filtered_person_with_summary[, !(colnames(filtered_person_with_summary) == "Ferritin..Mass.volume..in.Serum.or.Plasma")]



# # Save the filtered_person_with_summary dataframe as refiltered_person_with_summary.csv
# write.csv(filtered_person_with_summary, file = "rerefiltered_person_with_summary.csv", row.names = FALSE)

```

# XG Boost Model

## Data preparation

```{r}
library(knitr)
library(dplyr)
library(tidyr)
library(lubridate)
library(purrr)
library(stringr)

#install.packages("survival")
#install.packages("survminer")

# Load the necessary libraries
library(survival)

# install.packages("RColorBrewer")
library(RColorBrewer)

# Install and load necessary packages
#install.packages("caret")
#install.packages("ggplot2")
library(caret)
library(ggplot2)

# Load necessary libraries
#library(pROC)

filtered_person_with_summary <- read.csv("rerefiltered_person_with_summary.csv")
# Filter the dataset to only include observations with eGFR_ckd_epi_2021 < 60
#filtered_person_with_summary <- filtered_person_with_summary %>% filter(eGFR_ckd_epi_2021 < 60)

# Create 'SexMale' and 'SexFemale' columns based on 'sex_at_birth'
filtered_person_with_summary$SexMale <- ifelse(filtered_person_with_summary$sex_at_birth == "Male", 1, 0)
filtered_person_with_summary$SexFemale <- ifelse(filtered_person_with_summary$sex_at_birth == "Female", 1, 0)

# Remove the original 'sex_at_birth' column
filtered_person_with_summary <- filtered_person_with_summary[, !colnames(filtered_person_with_summary) %in% "sex_at_birth"]

colnames(filtered_person_with_summary)
# Load necessary libraries
library(dplyr)
library(xgboost)
library(survival)
# Step 1: Replace all NA values in the dataset with 0
filtered_person_with_summary[is.na(filtered_person_with_summary)] <- 0

# Step 2: Ensure there are no more NA values
if (sum(is.na(filtered_person_with_summary)) != 0) {
  stop("There are still NA values in the data.")
}

# Step 3: Define the 5-year and 2-year time limits in days
five_years_in_days <- 5 * 365.25  # 1826.25 days
two_years_in_days <- 2 * 365.25   # 730.5 days

# Step 4: Censor or filter data for 5-year and 2-year events based on `time_to_event`
if (!"time_to_event" %in% colnames(filtered_person_with_summary)) {
  stop("Error: time_to_event column not found in the dataset.")
}

# Create event_5yr and time_to_event_5yr
filtered_person_with_summary$event_5yr <- ifelse(filtered_person_with_summary$time_to_event <= five_years_in_days & 
                                                 filtered_person_with_summary$disease_status == 1, 1, 0)
filtered_person_with_summary$time_to_event_5yr <- pmin(filtered_person_with_summary$time_to_event, five_years_in_days)

# Create event_2yr and time_to_event_2yr
filtered_person_with_summary$event_2yr <- ifelse(filtered_person_with_summary$time_to_event <= two_years_in_days & 
                                                 filtered_person_with_summary$disease_status == 1, 1, 0)
filtered_person_with_summary$time_to_event_2yr <- pmin(filtered_person_with_summary$time_to_event, two_years_in_days)

# Step 5: Remove the `time_to_event` column as it's no longer needed
filtered_person_with_summary <- subset(filtered_person_with_summary, select = -c(time_to_event))

# Step 6: Normalize numeric variables using log(variable + 1)
predictor_cols <- colnames(filtered_person_with_summary)[5:41]  # Adjust index for numeric columns
filtered_person_with_summary[predictor_cols] <- log(filtered_person_with_summary[predictor_cols] + 1)

# Step 7: Create binary race variables based on the race column
filtered_person_with_summary$raceBlack <- ifelse(filtered_person_with_summary$race == "Black or African American", 1, 0)
filtered_person_with_summary$raceWhite <- ifelse(filtered_person_with_summary$race == "White", 1, 0)
filtered_person_with_summary$raceAsian <- ifelse(filtered_person_with_summary$race == "Asian", 0, 0)  # Put 0 for train, Asians will only be in test set

# Step 8: Split Black and White data into 70% training and 30% test
set.seed(123)  # For reproducibility
# Splitting Black data
sample_size_black <- floor(0.7 * nrow(subset(filtered_person_with_summary, raceBlack == 1)))
train_indices_black <- sample(seq_len(nrow(subset(filtered_person_with_summary, raceBlack == 1))), size = sample_size_black)
train_data_black <- subset(filtered_person_with_summary, raceBlack == 1)[train_indices_black, ]
test_data_black <- subset(filtered_person_with_summary, raceBlack == 1)[-train_indices_black, ]

# Splitting White data
sample_size_white <- floor(0.7 * nrow(subset(filtered_person_with_summary, raceWhite == 1)))
train_indices_white <- sample(seq_len(nrow(subset(filtered_person_with_summary, raceWhite == 1))), size = sample_size_white)
train_data_white <- subset(filtered_person_with_summary, raceWhite == 1)[train_indices_white, ]
test_data_white <- subset(filtered_person_with_summary, raceWhite == 1)[-train_indices_white, ]

# Step 9: For Asians, 100% of data goes to the test set
test_data_asian <- subset(filtered_person_with_summary, race == "Asian")
test_data_asian$raceAsian <- 1  # Mark Asians for test

# Step 10: Combine the training data (only Black and White individuals)
train_data <- rbind(train_data_black, train_data_white)

# Step 11: Combine the test data (30% Black, 30% White, and 100% Asian)
test_data <- rbind(test_data_black, test_data_white, test_data_asian)

# Step 12: Filter out non-positive event times from training and test data
# For 2-year training data
valid_indices_train_2yr <- train_data$time_to_event_2yr > 0  # Keep only rows with positive time_to_event
train_data_2yr <- train_data[valid_indices_train_2yr, ]

# For 2-year test data
valid_indices_test_2yr <- test_data$time_to_event_2yr > 0
test_data_2yr <- test_data[valid_indices_test_2yr, ]

# For 5-year training data
valid_indices_train_5yr <- train_data$time_to_event_5yr > 0
train_data_5yr <- train_data[valid_indices_train_5yr, ]

# For 5-year test data
valid_indices_test_5yr <- test_data$time_to_event_5yr > 0
test_data_5yr <- test_data[valid_indices_test_5yr, ]

# Step 13: Create model matrices for 2-year and 5-year predictions

# Exclude the original "race" column to avoid duplicates
non_predictor_cols <- c("person_id", "disease_status", "event_2yr", "event_5yr", "time_to_event_2yr", "time_to_event_5yr", "race")

# 2-year training data (including the smoked_100_Cigs_lifetime variable)
X_train_2yr <- model.matrix(~ raceBlack + raceWhite + raceAsian + ethnicity + Acidosis + 
                              Acute.renal.failure.syndrome + Anemia + BMI + smoked_100_Cigs_lifetime + . - 1, 
                            data = train_data_2yr[, !(colnames(train_data_2yr) %in% non_predictor_cols)])
y_train_2yr <- train_data_2yr$event_2yr
time_train_2yr <- train_data_2yr$time_to_event_2yr

# 2-year test data (including the smoked_100_Cigs_lifetime variable)
X_test_2yr <- model.matrix(~ raceBlack + raceWhite + raceAsian + ethnicity + Acidosis + 
                             Acute.renal.failure.syndrome + Anemia + BMI + smoked_100_Cigs_lifetime + . - 1, 
                           data = test_data_2yr[, !(colnames(test_data_2yr) %in% non_predictor_cols)])
y_test_2yr <- test_data_2yr$event_2yr
time_test_2yr <- test_data_2yr$time_to_event_2yr

# 5-year training data (including the smoked_100_Cigs_lifetime variable)
X_train_5yr <- model.matrix(~ raceBlack + raceWhite + raceAsian + ethnicity + Acidosis + 
                              Acute.renal.failure.syndrome + Anemia + BMI + smoked_100_Cigs_lifetime + . - 1, 
                            data = train_data_5yr[, !(colnames(train_data_5yr) %in% non_predictor_cols)])
y_train_5yr <- train_data_5yr$event_5yr
time_train_5yr <- train_data_5yr$time_to_event_5yr

# 5-year test data (including the smoked_100_Cigs_lifetime variable)
X_test_5yr <- model.matrix(~ raceBlack + raceWhite + raceAsian + ethnicity + Acidosis + 
                             Acute.renal.failure.syndrome + Anemia + BMI + smoked_100_Cigs_lifetime + . - 1, 
                           data = test_data_5yr[, !(colnames(test_data_5yr) %in% non_predictor_cols)])
y_test_5yr <- test_data_5yr$event_5yr
time_test_5yr <- test_data_5yr$time_to_event_5yr

# Step 14: Print cases and controls with non-positive time to event for train and test data
# For 2-year training data
non_positive_train_2yr <- train_data[train_data$time_to_event_2yr <= 0, ]
non_positive_cases_train_2yr <- sum(non_positive_train_2yr$event_2yr == 1)
non_positive_controls_train_2yr <- sum(non_positive_train_2yr$event_2yr == 0)

# For 2-year test data
non_positive_test_2yr <- test_data[test_data$time_to_event_2yr <= 0, ]
non_positive_cases_test_2yr <- sum(non_positive_test_2yr$event_2yr == 1)
non_positive_controls_test_2yr <- sum(non_positive_test_2yr$event_2yr == 0)

# For 5-year training data
non_positive_train_5yr <- train_data[train_data$time_to_event_5yr <= 0, ]
non_positive_cases_train_5yr <- sum(non_positive_train_5yr$event_5yr == 1)
non_positive_controls_train_5yr <- sum(non_positive_train_5yr$event_5yr == 0)

# For 5-year test data
non_positive_test_5yr <- test_data[test_data$time_to_event_5yr <= 0, ]
non_positive_cases_test_5yr <- sum(non_positive_test_5yr$event_5yr == 1)
non_positive_controls_test_5yr <- sum(non_positive_test_5yr$event_5yr == 0)

# Step 15: Print the results
cat("2-Year Training Data: \n")
cat("Non-positive cases:", non_positive_cases_train_2yr, "\n")
cat("Non-positive controls:", non_positive_controls_train_2yr, "\n")
cat("Unique non-positive time to events:", unique(non_positive_train_2yr$time_to_event_2yr), "\n\n")

cat("2-Year Test Data: \n")
cat("Non-positive cases:", non_positive_cases_test_2yr, "\n")
cat("Non-positive controls:", non_positive_controls_test_2yr, "\n")
cat("Unique non-positive time to events:", unique(non_positive_test_2yr$time_to_event_2yr), "\n\n")

cat("5-Year Training Data: \n")
cat("Non-positive cases:", non_positive_cases_train_5yr, "\n")
cat("Non-positive controls:", non_positive_controls_train_5yr, "\n")
cat("Unique non-positive time to events:", unique(non_positive_train_5yr$time_to_event_5yr), "\n\n")

cat("5-Year Test Data: \n")
cat("Non-positive cases:", non_positive_cases_test_5yr, "\n")
cat("Non-positive controls:", non_positive_controls_test_5yr, "\n")
cat("Unique non-positive time to events:", unique(non_positive_test_5yr$time_to_event_5yr), "\n\n")

```

## Testing Proportional hazards assumptions: Multivariate

```{r}

# Load necessary libraries
library(survival)
library(dplyr)

# Function to test proportional hazards assumption and return a table with results
test_proportional_hazards_multivariate <- function(cox_model, outcome_type) {
  # Perform the proportional hazards assumption test
  ph_test <- cox.zph(cox_model)
  
  # Extract the p-values from the test
  ph_results <- ph_test$table[, "p"]
  
  # Create a data frame to store the covariate names and their PH assumption results
  results_df <- data.frame(
    Covariate = rownames(ph_test$table),
    PH_Assumption = ifelse(ph_results >= 0.05, "Holds", "Violated")
  )
  
  # Print the result table
  cat("\nProportional Hazards Assumption Test Results for", outcome_type, "Outcome:\n")
  print(results_df)
  
  return(results_df)  # Return the table for further use if needed
}

# Fit a multivariate Cox proportional hazards model for 2-year outcome
cox_model_2yr <- coxph(
  Surv(time_to_event_2yr, event_2yr) ~ race + ethnicity + Acidosis + Acute.renal.failure.syndrome +
    Anemia + Anemia.in.chronic.kidney.disease + Atherosclerosis.of.coronary.artery.without.angina.pectoris +
    BMI + Chronic.kidney.disease.stage.3 + Chronic.kidney.disease.stage.4 + Congestive.heart.failure +
     Diabetes.mellitus + Disorder.of.kidney.and.or.ureter + Disorder.of.muscle +
    Erythrocyte.distribution.width..Ratio..by.Automated.count + Essential.hypertension + Gout + 
    Hemoglobin.A1c.Hemoglobin.total.in.Blood + Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay +
    Hyperkalemia + Hypothyroidism + Iron..Mass.volume..in.Serum.or.Plasma + Iron.deficiency.anemia + 
    Iron.saturation..Mass.Fraction..in.Serum.or.Plasma + Parathyrin.intact..Mass.volume..in.Serum.or.Plasma +
    Peripheral.vascular.disease + Polyneuropathy.due.to.diabetes.mellitus + Protein..Mass.volume..in.Urine + Proteinuria +
    Renal.disorder.due.to.type.2.diabetes.mellitus + Systemic.lupus.erythematosus + Systolic.blood.pressure + 
    Transplanted.kidney.present + Triglyceride..Mass.volume..in.Serum.or.Plasma + Type.2.diabetes.mellitus +
    age_precise + smoked_100_Cigs_lifetime  +
    SexFemale + SexMale,
  data = filtered_person_with_summary
)

# Test proportional hazards assumption for the 2-year model
ph_violation_table_2yr <- test_proportional_hazards_multivariate(cox_model_2yr, "2-Year")


# Fit a multivariate Cox proportional hazards model for 5-year outcome
cox_model_5yr <- coxph(
  Surv(time_to_event_5yr, event_5yr) ~ race + ethnicity + Acidosis + Acute.renal.failure.syndrome +
    Anemia + Anemia.in.chronic.kidney.disease + Atherosclerosis.of.coronary.artery.without.angina.pectoris +
    BMI + Chronic.kidney.disease.stage.3 + Chronic.kidney.disease.stage.4 + Congestive.heart.failure +
     Diabetes.mellitus + Disorder.of.kidney.and.or.ureter + Disorder.of.muscle +
    Erythrocyte.distribution.width..Ratio..by.Automated.count + Essential.hypertension + Gout + 
    Hemoglobin.A1c.Hemoglobin.total.in.Blood + Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay +
    Hyperkalemia + Hypothyroidism + Iron..Mass.volume..in.Serum.or.Plasma + Iron.deficiency.anemia + 
    Iron.saturation..Mass.Fraction..in.Serum.or.Plasma + Parathyrin.intact..Mass.volume..in.Serum.or.Plasma +
    Peripheral.vascular.disease + Polyneuropathy.due.to.diabetes.mellitus + Protein..Mass.volume..in.Urine + Proteinuria +
    Renal.disorder.due.to.type.2.diabetes.mellitus + Systemic.lupus.erythematosus + Systolic.blood.pressure + 
    Transplanted.kidney.present + Triglyceride..Mass.volume..in.Serum.or.Plasma + Type.2.diabetes.mellitus +
    age_precise + smoked_100_Cigs_lifetime +
    SexFemale + SexMale,
  data = filtered_person_with_summary
)

# Test proportional hazards assumption for the 5-year model
ph_violation_table_5yr <- test_proportional_hazards_multivariate(cox_model_5yr, "5-Year")

```

### 

#### Counts before cleaning

```{r}
# Load necessary library for better data manipulation
library(dplyr)

# Define the race groups we are interested in
race_groups <- c("White", "Black or African American", "Asian")

# Function to calculate the number of cases and controls for both 2-year and 5-year events
count_cases_controls <- function(data, race_variable, event_2yr_variable, event_5yr_variable) {
  
  # Initialize an empty result data frame to store results
  result <- data.frame(Race = race_groups, 
                       Cases_2yr = integer(length(race_groups)), Controls_2yr = integer(length(race_groups)),
                       Cases_5yr = integer(length(race_groups)), Controls_5yr = integer(length(race_groups)))

  # Loop through each race group
  for (race in race_groups) {
    
    # Filter the data for the current race
    race_data <- data[data[[race_variable]] == race, ]
    
    # Calculate the number of 2-year cases and controls
    num_cases_2yr <- sum(race_data[[event_2yr_variable]] == 1, na.rm = TRUE)
    num_controls_2yr <- sum(race_data[[event_2yr_variable]] == 0, na.rm = TRUE)
    
    # Calculate the number of 5-year cases and controls
    num_cases_5yr <- sum(race_data[[event_5yr_variable]] == 1, na.rm = TRUE)
    num_controls_5yr <- sum(race_data[[event_5yr_variable]] == 0, na.rm = TRUE)
    
    # Store the results in the result data frame for each race group
    result[result$Race == race, "Cases_2yr"] <- num_cases_2yr
    result[result$Race == race, "Controls_2yr"] <- num_controls_2yr
    result[result$Race == race, "Cases_5yr"] <- num_cases_5yr
    result[result$Race == race, "Controls_5yr"] <- num_controls_5yr
  }
  
  # Add a row for the total (across all races)
  total_cases_2yr <- sum(data[[event_2yr_variable]] == 1, na.rm = TRUE)
  total_controls_2yr <- sum(data[[event_2yr_variable]] == 0, na.rm = TRUE)
  total_cases_5yr <- sum(data[[event_5yr_variable]] == 1, na.rm = TRUE)
  total_controls_5yr <- sum(data[[event_5yr_variable]] == 0, na.rm = TRUE)
  
  result <- rbind(result, 
                  data.frame(Race = "Total", 
                             Cases_2yr = total_cases_2yr, Controls_2yr = total_controls_2yr,
                             Cases_5yr = total_cases_5yr, Controls_5yr = total_controls_5yr))
  
  return(result)
}

# Calculate cases and controls for the training data for both 2-year and 5-year events
train_summary <- count_cases_controls(train_data, "race", "event_2yr", "event_5yr")

# Calculate cases and controls for the test data for both 2-year and 5-year events
test_summary <- count_cases_controls(test_data, "race", "event_2yr", "event_5yr")

# Combine the results for both training and test data into one dataset
combined_summary <- list(Train = train_summary, Test = test_summary)

# Print the results
print("Training Data Summary (2-year and 5-year):")
print(combined_summary$Train)

print("Test Data Summary (2-year and 5-year):")
print(combined_summary$Test)

```

#### Counts after cleaning

```{r}
# Load necessary library for better data manipulation
library(dplyr)

# Define the race groups we are interested in
race_groups <- c("White", "Black or African American", "Asian")

# Function to calculate the number of cases and controls for both 2-year and 5-year events, with positive time-to-event
count_cases_controls_positive_time <- function(data, race_variable, event_2yr_variable, event_5yr_variable, time_2yr_variable, time_5yr_variable) {
  
  # Initialize an empty result data frame to store results
  result <- data.frame(Race = race_groups, 
                       Cases_2yr_Positive = integer(length(race_groups)), Controls_2yr_Positive = integer(length(race_groups)),
                       Cases_5yr_Positive = integer(length(race_groups)), Controls_5yr_Positive = integer(length(race_groups)))
  
  # Loop through each race group
  for (race in race_groups) {
    
    # Filter the data for the current race and keep only rows with positive time-to-event
    race_data_2yr <- data[data[[race_variable]] == race & data[[time_2yr_variable]] > 0, ]
    race_data_5yr <- data[data[[race_variable]] == race & data[[time_5yr_variable]] > 0, ]
    
    # Calculate the number of 2-year cases and controls with positive time-to-event
    num_cases_2yr <- sum(race_data_2yr[[event_2yr_variable]] == 1, na.rm = TRUE)
    num_controls_2yr <- sum(race_data_2yr[[event_2yr_variable]] == 0, na.rm = TRUE)
    
    # Calculate the number of 5-year cases and controls with positive time-to-event
    num_cases_5yr <- sum(race_data_5yr[[event_5yr_variable]] == 1, na.rm = TRUE)
    num_controls_5yr <- sum(race_data_5yr[[event_5yr_variable]] == 0, na.rm = TRUE)
    
    # Store the results in the result data frame for each race group
    result[result$Race == race, "Cases_2yr_Positive"] <- num_cases_2yr
    result[result$Race == race, "Controls_2yr_Positive"] <- num_controls_2yr
    result[result$Race == race, "Cases_5yr_Positive"] <- num_cases_5yr
    result[result$Race == race, "Controls_5yr_Positive"] <- num_controls_5yr
  }
  
  # Add a row for the total (across all races) with positive time-to-event
  total_cases_2yr <- sum(data[[event_2yr_variable]] == 1 & data[[time_2yr_variable]] > 0, na.rm = TRUE)
  total_controls_2yr <- sum(data[[event_2yr_variable]] == 0 & data[[time_2yr_variable]] > 0, na.rm = TRUE)
  total_cases_5yr <- sum(data[[event_5yr_variable]] == 1 & data[[time_5yr_variable]] > 0, na.rm = TRUE)
  total_controls_5yr <- sum(data[[event_5yr_variable]] == 0 & data[[time_5yr_variable]] > 0, na.rm = TRUE)
  
  result <- rbind(result, 
                  data.frame(Race = "Total", 
                             Cases_2yr_Positive = total_cases_2yr, Controls_2yr_Positive = total_controls_2yr,
                             Cases_5yr_Positive = total_cases_5yr, Controls_5yr_Positive = total_controls_5yr))
  
  return(result)
}

# Calculate cases and controls with positive time-to-event for the training data
train_summary <- count_cases_controls_positive_time(train_data, "race", "event_2yr", "event_5yr", "time_to_event_2yr", "time_to_event_5yr")

# Calculate cases and controls with positive time-to-event for the test data
test_summary <- count_cases_controls_positive_time(test_data, "race", "event_2yr", "event_5yr", "time_to_event_2yr", "time_to_event_5yr")

# Combine the results for both training and test data into one dataset
combined_summary <- list(Train = train_summary, Test = test_summary)

# Print the results
cat("Training Data Summary (2-year and 5-year with positive time-to-event):\n")
print(combined_summary$Train)

cat("\nTest Data Summary (2-year and 5-year with positive time-to-event):\n")
print(combined_summary$Test)

```

## Race specific model

```{r}
# Load necessary libraries
library(xgboost)
library(pROC)
library(Hmisc)  # For Harrell's C-statistic
library(survival)
library(doParallel)
library(ggplot2)
library(dplyr)
library(caret)  # For cross-validation and parameter tuning
library(boot)   # For bootstrapping AUC confidence intervals

# Set up parallel backend for faster execution
cores <- detectCores() - 2  # Leave two cores free
registerDoParallel(cores)

# Set random seed for reproducibility
set.seed(123)

# Function to normalize data using log(x + 1)
normalize_data <- function(df) {
  return(log(df + 1))
}

# Define a robust but efficient hyperparameter grid for tuning
param_grid <- expand.grid(
  max_depth = c(4, 6),  
  min_child_weight = c(1, 2),  
  gamma = c(0, 0.2),  
  eta = c(0.05, 0.1),  
  subsample = c(0.8, 0.9),  
  colsample_bytree = c(0.8, 1),  
  alpha = c(0, 0.5),  
  lambda = c(1, 1.2),  
  n_estimators = c(300, 500)  
)

# Function for hyperparameter tuning using grid search with cross-validation
grid_search_xgboost <- function(X_train, time_train, event_status_train, X_val, time_val, event_status_val, param_grid, nfold = 5, early_stopping_rounds = 5) {
  best_score <- Inf
  best_model <- NULL
  best_params <- NULL
  
  # Convert training and validation data to DMatrix for XGBoost
  dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = time_train)
  dval <- xgb.DMatrix(data = as.matrix(X_val), label = time_val)
  setinfo(dtrain, "base_margin", event_status_train)
  setinfo(dval, "base_margin", event_status_val)
  
  # Watchlist to monitor training and validation
  watchlist <- list(train = dtrain, val = dval)
  
  # Iterate over each combination of parameters in the grid
  for (i in 1:nrow(param_grid)) {
    params <- list(
      max_depth = param_grid$max_depth[i],
      min_child_weight = param_grid$min_child_weight[i],
      gamma = param_grid$gamma[i],
      eta = param_grid$eta[i],
      subsample = param_grid$subsample[i],
      colsample_bytree = param_grid$colsample_bytree[i],
      alpha = param_grid$alpha[i],
      lambda = param_grid$lambda[i],
      objective = "survival:cox",
      eval_metric = "cox-nloglik",
      nthread = cores
    )
    
    # Train the model with early stopping using the validation set
    model <- xgb.train(
      params = params,
      data = dtrain,
      nrounds = param_grid$n_estimators[i],
      watchlist = watchlist,  
      early_stopping_rounds = early_stopping_rounds,
      verbose = 0
    )
    
    # Get the final evaluation metric (cox-nloglik)
    final_score <- model$best_score
    
    # Update the best model if we find a better score
    if (final_score < best_score) {
      best_score <- final_score
      best_model <- model
      best_params <- params
    }
  }
  
  # Print the best parameters
  print("Best Parameters:")
  print(best_params)
  
  return(list(best_model = best_model, best_params = best_params))
}

# Function to fit XGBoost model with early stopping and return variable importance
fit_xgboost_and_display <- function(X_data, time_to_event, event_status, title_prefix, early_stopping_rounds = 5, nfold = 3, val_size = 0.2) {
  
  # Split the data into training and validation sets
  set.seed(123)
  train_indices <- createDataPartition(event_status, p = 1 - val_size, list = FALSE)
  X_train <- X_data[train_indices, ]
  X_val <- X_data[-train_indices, ]
  time_train <- time_to_event[train_indices]
  time_val <- time_to_event[-train_indices]
  event_status_train <- event_status[train_indices]
  event_status_val <- event_status[-train_indices]
  
  # Run grid search to find the best hyperparameters using cross-validation
  grid_search_result <- grid_search_xgboost(X_train, time_train, event_status_train, X_val, time_val, event_status_val, param_grid, nfold, early_stopping_rounds)
  
  # Get the best model and parameters
  xgboost_model <- grid_search_result$best_model
  best_params <- grid_search_result$best_params
  
  # Print the best parameters
  print("Best Hyperparameters Found:")
  print(best_params)
  
  # Get variable importance
  importance_matrix <- xgb.importance(model = xgboost_model)
  
  # Plot variable importance
  importance_plot <- ggplot(importance_matrix, aes(x = reorder(Feature, Gain), y = Gain)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = paste(title_prefix, "Variable Importance"), x = "Variables", y = "Importance (Gain)") +
    theme_minimal()
  
  print(importance_plot)  # Display the plot
  
  return(list(model = xgboost_model, importance = importance_matrix, best_params = best_params))
}

# Function to prepare and normalize the data, ensuring clean input
prepare_data <- function(data, time_col, event_col, time_threshold) {
  valid_indices <- data[[time_col]] > 0
  
  # Censor observations beyond the threshold and normalize
  filtered_data <- data[valid_indices, ]
  filtered_data[[event_col]] <- ifelse(filtered_data[[time_col]] > time_threshold, 0, filtered_data[[event_col]])
  
  # Normalize numeric predictor variables
  normalized_data <- filtered_data %>%
    mutate(across(where(is.numeric), ~ normalize_data(.)))
  
  return(normalized_data)
}

# Function to evaluate the XGBoost model with metrics and bootstrapping for confidence intervals
evaluate_xgboost <- function(xgboost_model, X_test_data, y_test_data, time_test_data, train_column_names, n_bootstrap = 3000) {
  
  # Ensure the test data has the same columns as the training data
  X_test_data <- X_test_data[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for testing
  dtest <- xgb.DMatrix(data = as.matrix(X_test_data))
  
  # Predict risk scores
  risk_scores <- predict(xgboost_model, newdata = dtest)
  
  # Calculate Harrell's C-statistic (concordance index)
  survival_object <- Surv(time_test_data, y_test_data)
  c_stat <- rcorr.cens(risk_scores, survival_object)["C Index"]
  
  # Bootstrapping AUC to get confidence intervals
  auc_bootstrap <- boot(data = data.frame(y_test_data, risk_scores), 
                        statistic = function(data, indices) {
                          auc(roc(data[indices, 1], data[indices, 2]))
                        }, 
                        R = n_bootstrap)
  auc_ci <- boot.ci(auc_bootstrap, type = "perc")
  
  auc_value <- auc(roc(y_test_data, risk_scores))
  
  return(list(c_stat = c_stat, auc = auc_value, auc_ci = auc_ci))
}

# Measure the start time
start_time <- Sys.time()

# Data preparation for 2-year and 5-year predictions
two_years_in_days <- 2 * 365.25
five_years_in_days <- 5 * 365.25

# Prepare training data
train_data_2yr <- prepare_data(train_data, "time_to_event_2yr", "event_2yr", two_years_in_days)
X_train_2yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - 1, data = train_data_2yr)
time_train_2yr <- train_data_2yr$time_to_event_2yr
event_status_2yr <- train_data_2yr$event_2yr

train_data_5yr <- prepare_data(train_data, "time_to_event_5yr", "event_5yr", five_years_in_days)
X_train_5yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - 1, data = train_data_5yr)
time_train_5yr <- train_data_5yr$time_to_event_5yr
event_status_5yr <- train_data_5yr$event_5yr

# Train models
result_2yr <- fit_xgboost_and_display(X_train_2yr, time_train_2yr, event_status_2yr, "2-Year", early_stopping_rounds = 5, nfold = 3)
xgboost_model_2yr <- result_2yr$model

result_5yr <- fit_xgboost_and_display(X_train_5yr, time_train_5yr, event_status_5yr, "5-Year", early_stopping_rounds = 5, nfold = 3)
xgboost_model_5yr <- result_5yr$model

# Measure the end time and calculate total runtime
end_time <- Sys.time()
total_runtime <- end_time - start_time
cat("Total runtime: ", total_runtime, "\n")

# Function to perform bootstrapping to calculate AUC confidence intervals
bootstrap_auc <- function(xgboost_model, X_test, y_test, train_column_names, n_bootstrap = 3000) {
  # Ensure test data has the same columns as training data
  X_test <- X_test[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for the test data
  dtest <- xgb.DMatrix(data = as.matrix(X_test))
  
  # Define a function to calculate the AUC for a bootstrapped sample
  auc_bootstrap <- function(data, indices) {
    # Subset the data using the provided indices
    y_test_sample <- data[indices, 1]
    predictions_sample <- predict(xgboost_model, newdata = dtest)[indices]
    
    # Calculate the AUC for the sample
    auc_value <- auc(roc(y_test_sample, predictions_sample))
    return(auc_value)
  }
  
  # Perform bootstrapping
  boot_results <- boot(data = data.frame(y_test, predict(xgboost_model, newdata = dtest)), 
                       statistic = auc_bootstrap, R = n_bootstrap)
  
  # Calculate the 95% confidence interval for the AUC
  ci <- boot.ci(boot_results, type = "perc")
  
  # Extract the mean AUC and the confidence interval limits
  auc_mean <- mean(boot_results$t)
  auc_ci_lower <- ci$perc[4]
  auc_ci_upper <- ci$perc[5]
  
  return(list(auc_mean = auc_mean, auc_ci_lower = auc_ci_lower, auc_ci_upper = auc_ci_upper))
}

# Function to perform evaluation with bootstrapping for different race subgroups
evaluate_with_bootstrapping <- function(race_group, X_test, y_test, time_test, xgboost_model, train_column_names, n_bootstrap = 3000) {
  if (!is.null(race_group)) {
    race_indices <- X_test[, race_group] == 1
    X_test <- X_test[race_indices, ]
    y_test <- y_test[race_indices]
    time_test <- time_test[race_indices]
  }
  
  bootstrap_result <- bootstrap_auc(xgboost_model, X_test, y_test, train_column_names, n_bootstrap)
  
  return(bootstrap_result)
}

# List to store results
results_2yr_bootstrap <- list()
results_5yr_bootstrap <- list()

# Evaluate for the entire population and subgroups for both 2-year and 5-year models
population_and_subgroups <- list(
  "2-Year All" = NULL, 
  "2-Year Black" = "raceBlack", 
  "2-Year White" = "raceWhite", 
  "2-Year Asian" = "raceAsian", 
  "5-Year All" = NULL, 
  "5-Year Black" = "raceBlack", 
  "5-Year White" = "raceWhite", 
  "5-Year Asian" = "raceAsian"
)

# Run bootstrapping for each group
for (name in names(population_and_subgroups)) {
  group <- population_and_subgroups[[name]]
  if (grepl("^2-Year", name)) {
    results_2yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_2yr, y_test_2yr, time_test_2yr, xgboost_model_2yr, colnames(X_train_2yr), n_bootstrap = 3000)
  } else {
    results_5yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_5yr, y_test_5yr, time_test_5yr, xgboost_model_5yr, colnames(X_train_5yr), n_bootstrap = 3000)
  }
}

# Combine results into a data frame for easy reporting
results_table_bootstrap <- data.frame(
  Model = c(names(results_2yr_bootstrap), names(results_5yr_bootstrap)),
  AUC_Mean = c(sapply(results_2yr_bootstrap, function(x) x$auc_mean), sapply(results_5yr_bootstrap, function(x) x$auc_mean)),
  AUC_CI_Lower = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_lower), sapply(results_5yr_bootstrap, function(x) x$auc_ci_lower)),
  AUC_CI_Upper = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_upper), sapply(results_5yr_bootstrap, function(x) x$auc_ci_upper))
)

# Print the results table
print(results_table_bootstrap)

# Create a forest plot to display AUC with 95% confidence intervals, excluding "All" categories
results_table_bootstrap_filtered <- results_table_bootstrap %>%
  filter(!grepl("All", Model))

forest_plot <- ggplot(results_table_bootstrap_filtered, aes(x = AUC_Mean, y = Model)) +
  geom_point(size = 3, color = "black") +  # Add points for the mean AUC
  geom_errorbarh(aes(xmin = AUC_CI_Lower, xmax = AUC_CI_Upper), height = 0.2, size = 1) +  # Add horizontal error bars
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 0.8) +  # Add a vertical dashed line at AUC = 0.5
  labs(title = "Forest Plot of AUC with 95% Confidence Intervals for 2-Year and 5-Year Models",
       x = "Area Under the Curve (AUC)", y = "Model") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title.x = element_text(size = 16, face = "bold"),
    axis.title.y = element_text(size = 16, face = "bold"),
    axis.text.y = element_text(size = 14),  
    axis.text.x = element_text(size = 14),  
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank()
  ) +
  coord_cartesian(xlim = c(0, 1))  

# Display the plot
print(forest_plot)

# Stop parallel processing
stopImplicitCluster()

# Save the plot as a high-resolution PNG file
ggsave("Race_Specific_Forest_Plot_AUC_95CI_No_All_With_Reference.png", plot = forest_plot, dpi = 300, width = 10, height = 6)

# Optionally, save as a PDF for high-quality printing
ggsave("Race_Specific_Forest_Plot_AUC_95CI_No_All_With_Reference.pdf", plot = forest_plot, width = 10, height = 6)

```

## Race_free model:

```{r}
# Load necessary libraries
library(xgboost)
library(pROC)
library(Hmisc)  # For Harrell's C-statistic
library(survival)
library(doParallel)
library(ggplot2)
library(dplyr)
library(caret)  # For cross-validation and parameter tuning
library(boot)   # For bootstrapping AUC confidence intervals

# Set up parallel backend for faster execution
cores <- detectCores() - 2  # Leave two cores free
registerDoParallel(cores)

# Set random seed for reproducibility
set.seed(123)

# Function to normalize data using log(x + 1)
normalize_data <- function(df) {
  return(log(df + 1))
}

# Define a robust but efficient hyperparameter grid for tuning
param_grid <- expand.grid(
  max_depth = c(4, 6),  
  min_child_weight = c(1, 2),  
  gamma = c(0, 0.2),  
  eta = c(0.05, 0.1),  
  subsample = c(0.8, 0.9),  
  colsample_bytree = c(0.8, 1),  
  alpha = c(0, 0.5),  
  lambda = c(1, 1.2),  
  n_estimators = c(300, 500)  
)

# Function for hyperparameter tuning using grid search with cross-validation
grid_search_xgboost <- function(X_train, time_train, event_status_train, X_val, time_val, event_status_val, param_grid, nfold = 5, early_stopping_rounds = 5) {
  best_score <- Inf
  best_model <- NULL
  best_params <- NULL
  
  # Convert training and validation data to DMatrix for XGBoost
  dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = time_train)
  dval <- xgb.DMatrix(data = as.matrix(X_val), label = time_val)
  setinfo(dtrain, "base_margin", event_status_train)
  setinfo(dval, "base_margin", event_status_val)
  
  # Watchlist to monitor training and validation
  watchlist <- list(train = dtrain, val = dval)
  
  # Iterate over each combination of parameters in the grid
  for (i in 1:nrow(param_grid)) {
    params <- list(
      max_depth = param_grid$max_depth[i],
      min_child_weight = param_grid$min_child_weight[i],
      gamma = param_grid$gamma[i],
      eta = param_grid$eta[i],
      subsample = param_grid$subsample[i],
      colsample_bytree = param_grid$colsample_bytree[i],
      alpha = param_grid$alpha[i],
      lambda = param_grid$lambda[i],
      objective = "survival:cox",
      eval_metric = "cox-nloglik",
      nthread = cores
    )
    
    # Train the model with early stopping using the validation set
    model <- xgb.train(
      params = params,
      data = dtrain,
      nrounds = param_grid$n_estimators[i],
      watchlist = watchlist,  
      early_stopping_rounds = early_stopping_rounds,
      verbose = 0
    )
    
    # Get the final evaluation metric (cox-nloglik)
    final_score <- model$best_score
    
    # Update the best model if we find a better score
    if (final_score < best_score) {
      best_score <- final_score
      best_model <- model
      best_params <- params
    }
  }
  
  # Print the best parameters
  print("Best Parameters:")
  print(best_params)
  
  return(list(best_model = best_model, best_params = best_params))
}

# Function to fit XGBoost model with early stopping and return variable importance
fit_xgboost_and_display <- function(X_data, time_to_event, event_status, title_prefix, early_stopping_rounds = 5, nfold = 3, val_size = 0.2) {
  
  # Split the data into training and validation sets
  set.seed(123)
  train_indices <- createDataPartition(event_status, p = 1 - val_size, list = FALSE)
  X_train <- X_data[train_indices, ]
  X_val <- X_data[-train_indices, ]
  time_train <- time_to_event[train_indices]
  time_val <- time_to_event[-train_indices]
  event_status_train <- event_status[train_indices]
  event_status_val <- event_status[-train_indices]
  
  # Run grid search to find the best hyperparameters using cross-validation
  grid_search_result <- grid_search_xgboost(X_train, time_train, event_status_train, X_val, time_val, event_status_val, param_grid, nfold, early_stopping_rounds)
  
  # Get the best model and parameters
  xgboost_model <- grid_search_result$best_model
  best_params <- grid_search_result$best_params
  
  # Print the best parameters
  print("Best Hyperparameters Found:")
  print(best_params)
  
  # Get variable importance
  importance_matrix <- xgb.importance(model = xgboost_model)
  
  # Plot variable importance
  importance_plot <- ggplot(importance_matrix, aes(x = reorder(Feature, Gain), y = Gain)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = paste(title_prefix, "Variable Importance"), x = "Variables", y = "Importance (Gain)") +
    theme_minimal()
  
  print(importance_plot)  # Display the plot
  
  return(list(model = xgboost_model, importance = importance_matrix, best_params = best_params))
}

# Function to prepare and normalize the data, ensuring clean input
prepare_data <- function(data, time_col, event_col, time_threshold) {
  valid_indices <- data[[time_col]] > 0
  
  # Censor observations beyond the threshold and normalize
  filtered_data <- data[valid_indices, ]
  filtered_data[[event_col]] <- ifelse(filtered_data[[time_col]] > time_threshold, 0, filtered_data[[event_col]])
  
  # Normalize numeric predictor variables
  normalized_data <- filtered_data %>%
    mutate(across(where(is.numeric), ~ normalize_data(.)))
  
  return(normalized_data)
}

# Function to evaluate the XGBoost model with metrics and bootstrapping for confidence intervals
evaluate_xgboost <- function(xgboost_model, X_test_data, y_test_data, time_test_data, train_column_names, n_bootstrap = 3000) {
  
  # Ensure the test data has the same columns as the training data
  X_test_data <- X_test_data[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for testing
  dtest <- xgb.DMatrix(data = as.matrix(X_test_data))
  
  # Predict risk scores
  risk_scores <- predict(xgboost_model, newdata = dtest)
  
  # Calculate Harrell's C-statistic (concordance index)
  survival_object <- Surv(time_test_data, y_test_data)
  c_stat <- rcorr.cens(risk_scores, survival_object)["C Index"]
  
  # Bootstrapping AUC to get confidence intervals
  auc_bootstrap <- boot(data = data.frame(y_test_data, risk_scores), 
                        statistic = function(data, indices) {
                          auc(roc(data[indices, 1], data[indices, 2]))
                        }, 
                        R = n_bootstrap)
  auc_ci <- boot.ci(auc_bootstrap, type = "perc")
  
  auc_value <- auc(roc(y_test_data, risk_scores))
  
  return(list(c_stat = c_stat, auc = auc_value, auc_ci = auc_ci))
}

# Measure the start time
start_time <- Sys.time()

# Data preparation for 2-year and 5-year predictions
two_years_in_days <- 2 * 365.25
five_years_in_days <- 5 * 365.25

# Prepare training data
train_data_2yr <- prepare_data(train_data, "time_to_event_2yr", "event_2yr", two_years_in_days)
X_train_2yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - raceBlack -raceWhite -raceAsian - 1, data = train_data_2yr)
time_train_2yr <- train_data_2yr$time_to_event_2yr
event_status_2yr <- train_data_2yr$event_2yr

train_data_5yr <- prepare_data(train_data, "time_to_event_5yr", "event_5yr", five_years_in_days)
X_train_5yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - raceBlack -raceWhite -raceAsian - 1, data = train_data_5yr)
time_train_5yr <- train_data_5yr$time_to_event_5yr
event_status_5yr <- train_data_5yr$event_5yr

# Train models
result_2yr <- fit_xgboost_and_display(X_train_2yr, time_train_2yr, event_status_2yr, "2-Year", early_stopping_rounds = 5, nfold = 3)
xgboost_model_2yr <- result_2yr$model

result_5yr <- fit_xgboost_and_display(X_train_5yr, time_train_5yr, event_status_5yr, "5-Year", early_stopping_rounds = 5, nfold = 3)
xgboost_model_5yr <- result_5yr$model

# Measure the end time and calculate total runtime
end_time <- Sys.time()
total_runtime <- end_time - start_time
cat("Total runtime: ", total_runtime, "\n")

# Function to perform bootstrapping to calculate AUC confidence intervals
bootstrap_auc <- function(xgboost_model, X_test, y_test, train_column_names, n_bootstrap = 3000) {
  # Ensure test data has the same columns as training data
  X_test <- X_test[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for the test data
  dtest <- xgb.DMatrix(data = as.matrix(X_test))
  
  # Define a function to calculate the AUC for a bootstrapped sample
  auc_bootstrap <- function(data, indices) {
    # Subset the data using the provided indices
    y_test_sample <- data[indices, 1]
    predictions_sample <- predict(xgboost_model, newdata = dtest)[indices]
    
    # Calculate the AUC for the sample
    auc_value <- auc(roc(y_test_sample, predictions_sample))
    return(auc_value)
  }
  
  # Perform bootstrapping
  boot_results <- boot(data = data.frame(y_test, predict(xgboost_model, newdata = dtest)), 
                       statistic = auc_bootstrap, R = n_bootstrap)
  
  # Calculate the 95% confidence interval for the AUC
  ci <- boot.ci(boot_results, type = "perc")
  
  # Extract the mean AUC and the confidence interval limits
  auc_mean <- mean(boot_results$t)
  auc_ci_lower <- ci$perc[4]
  auc_ci_upper <- ci$perc[5]
  
  return(list(auc_mean = auc_mean, auc_ci_lower = auc_ci_lower, auc_ci_upper = auc_ci_upper))
}

# Function to perform evaluation with bootstrapping for different race subgroups
evaluate_with_bootstrapping <- function(race_group, X_test, y_test, time_test, xgboost_model, train_column_names, n_bootstrap = 3000) {
  if (!is.null(race_group)) {
    race_indices <- X_test[, race_group] == 1
    X_test <- X_test[race_indices, ]
    y_test <- y_test[race_indices]
    time_test <- time_test[race_indices]
  }
  
  bootstrap_result <- bootstrap_auc(xgboost_model, X_test, y_test, train_column_names, n_bootstrap)
  
  return(bootstrap_result)
}

# List to store results
results_2yr_bootstrap <- list()
results_5yr_bootstrap <- list()

# Evaluate for the entire population and subgroups for both 2-year and 5-year models
population_and_subgroups <- list(
  "2-Year All" = NULL, 
  "2-Year Black" = "raceBlack", 
  "2-Year White" = "raceWhite", 
  "2-Year Asian" = "raceAsian", 
  "5-Year All" = NULL, 
  "5-Year Black" = "raceBlack", 
  "5-Year White" = "raceWhite", 
  "5-Year Asian" = "raceAsian"
)

# Run bootstrapping for each group
for (name in names(population_and_subgroups)) {
  group <- population_and_subgroups[[name]]
  if (grepl("^2-Year", name)) {
    results_2yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_2yr, y_test_2yr, time_test_2yr, xgboost_model_2yr, colnames(X_train_2yr), n_bootstrap = 3000)
  } else {
    results_5yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_5yr, y_test_5yr, time_test_5yr, xgboost_model_5yr, colnames(X_train_5yr), n_bootstrap = 3000)
  }
}

# Combine results into a data frame for easy reporting
results_table_bootstrap <- data.frame(
  Model = c(names(results_2yr_bootstrap), names(results_5yr_bootstrap)),
  AUC_Mean = c(sapply(results_2yr_bootstrap, function(x) x$auc_mean), sapply(results_5yr_bootstrap, function(x) x$auc_mean)),
  AUC_CI_Lower = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_lower), sapply(results_5yr_bootstrap, function(x) x$auc_ci_lower)),
  AUC_CI_Upper = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_upper), sapply(results_5yr_bootstrap, function(x) x$auc_ci_upper))
)

# Print the results table
print(results_table_bootstrap)

# Create a forest plot to display AUC with 95% confidence intervals, excluding "All" categories
results_table_bootstrap_filtered <- results_table_bootstrap %>%
  filter(!grepl("All", Model))

forest_plot <- ggplot(results_table_bootstrap_filtered, aes(x = AUC_Mean, y = Model)) +
  geom_point(size = 3, color = "black") +  # Add points for the mean AUC
  geom_errorbarh(aes(xmin = AUC_CI_Lower, xmax = AUC_CI_Upper), height = 0.2, size = 1) +  # Add horizontal error bars
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 0.8) +  # Add a vertical dashed line at AUC = 0.5
  labs(title = "Forest Plot of AUC with 95% Confidence Intervals for 2-Year and 5-Year Models",
       x = "Area Under the Curve (AUC)", y = "Model") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title.x = element_text(size = 16, face = "bold"),
    axis.title.y = element_text(size = 16, face = "bold"),
    axis.text.y = element_text(size = 14),  
    axis.text.x = element_text(size = 14),  
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank()
  ) +
  coord_cartesian(xlim = c(0, 1))  

# Display the plot
print(forest_plot)

# Stop parallel processing
stopImplicitCluster()

# Save the plot as a high-resolution PNG file
ggsave("Race_Free_Forest_Plot_AUC_95CI_No_All_With_Reference.png", plot = forest_plot, dpi = 300, width = 10, height = 6)

# Optionally, save as a PDF for high-quality printing
ggsave("Race_Free_Forest_Plot_AUC_95CI_No_All_With_Reference.pdf", plot = forest_plot, width = 10, height = 6)

```

## Lab_free model- with race:

```{r}
# Load necessary libraries
library(xgboost)
library(pROC)
library(Hmisc)  # For Harrell's C-statistic
library(survival)
library(doParallel)
library(ggplot2)
library(dplyr)
library(caret)  # For cross-validation and parameter tuning
library(boot)   # For bootstrapping AUC confidence intervals

# Set up parallel backend for faster execution
cores <- detectCores() - 2  # Leave two cores free
registerDoParallel(cores)

# Set random seed for reproducibility
set.seed(123)

# Define lab columns to exclude
labs_columns <- c(
  "Creatinine..Mass.volume..in.Body.fluid", 
  "Erythrocyte.distribution.width..Ratio..by.Automated.count", 
  "Ferritin..Mass.volume..in.Serum.or.Plasma", 
  "Hemoglobin.A1c.Hemoglobin.total.in.Blood", 
  "Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay", 
  "Iron..Mass.volume..in.Serum.or.Plasma", 
  "Iron.saturation..Mass.Fraction..in.Serum.or.Plasma", 
  "Parathyrin.intact..Mass.volume..in.Serum.or.Plasma", 
  "Protein..Mass.volume..in.Urine", 
  "Triglyceride..Mass.volume..in.Serum.or.Plasma", 
  "eGFR_ckd_epi_2021", 
  "serum_creatinine"
)

# Function to normalize data using log(x + 1)
normalize_data <- function(df) {
  return(log(df + 1))
}

# Define a robust but efficient hyperparameter grid for tuning
param_grid <- expand.grid(
  max_depth = c(4, 6),  
  min_child_weight = c(1, 2),  
  gamma = c(0, 0.2),  
  eta = c(0.05, 0.1),  
  subsample = c(0.8, 0.9),  
  colsample_bytree = c(0.8, 1),  
  alpha = c(0, 0.5),  
  lambda = c(1, 1.2),  
  n_estimators = c(300, 500)  
)

# Function for hyperparameter tuning using grid search with cross-validation
grid_search_xgboost <- function(X_train, time_train, event_status_train, X_val, time_val, event_status_val, param_grid, nfold = 5, early_stopping_rounds = 5) {
  best_score <- Inf
  best_model <- NULL
  best_params <- NULL
  
  # Convert training and validation data to DMatrix for XGBoost
  dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = time_train)
  dval <- xgb.DMatrix(data = as.matrix(X_val), label = time_val)
  setinfo(dtrain, "base_margin", event_status_train)
  setinfo(dval, "base_margin", event_status_val)
  
  # Watchlist to monitor training and validation
  watchlist <- list(train = dtrain, val = dval)
  
  # Iterate over each combination of parameters in the grid
  for (i in 1:nrow(param_grid)) {
    params <- list(
      max_depth = param_grid$max_depth[i],
      min_child_weight = param_grid$min_child_weight[i],
      gamma = param_grid$gamma[i],
      eta = param_grid$eta[i],
      subsample = param_grid$subsample[i],
      colsample_bytree = param_grid$colsample_bytree[i],
      alpha = param_grid$alpha[i],
      lambda = param_grid$lambda[i],
      objective = "survival:cox",
      eval_metric = "cox-nloglik",
      nthread = cores
    )
    
    # Train the model with early stopping using the validation set
    model <- xgb.train(
      params = params,
      data = dtrain,
      nrounds = param_grid$n_estimators[i],
      watchlist = watchlist,  
      early_stopping_rounds = early_stopping_rounds,
      verbose = 0
    )
    
    # Get the final evaluation metric (cox-nloglik)
    final_score <- model$best_score
    
    # Update the best model if we find a better score
    if (final_score < best_score) {
      best_score <- final_score
      best_model <- model
      best_params <- params
    }
  }
  
  # Print the best parameters
  print("Best Parameters:")
  print(best_params)
  
  return(list(best_model = best_model, best_params = best_params))
}

# Function to fit XGBoost model with early stopping and return variable importance
fit_xgboost_and_display <- function(X_data, time_to_event, event_status, title_prefix, early_stopping_rounds = 5, nfold = 3, val_size = 0.2) {
  
  # Split the data into training and validation sets
  set.seed(123)
  train_indices <- createDataPartition(event_status, p = 1 - val_size, list = FALSE)
  X_train <- X_data[train_indices, ]
  X_val <- X_data[-train_indices, ]
  time_train <- time_to_event[train_indices]
  time_val <- time_to_event[-train_indices]
  event_status_train <- event_status[train_indices]
  event_status_val <- event_status[-train_indices]
  
  # Run grid search to find the best hyperparameters using cross-validation
  grid_search_result <- grid_search_xgboost(X_train, time_train, event_status_train, X_val, time_val, event_status_val, param_grid, nfold, early_stopping_rounds)
  
  # Get the best model and parameters
  xgboost_model <- grid_search_result$best_model
  best_params <- grid_search_result$best_params
  
  # Print the best parameters
  print("Best Hyperparameters Found:")
  print(best_params)
  
  # Get variable importance
  importance_matrix <- xgb.importance(model = xgboost_model)
  
  # Plot variable importance
  importance_plot <- ggplot(importance_matrix, aes(x = reorder(Feature, Gain), y = Gain)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = paste(title_prefix, "Variable Importance"), x = "Variables", y = "Importance (Gain)") +
    theme_minimal()
  
  print(importance_plot)  # Display the plot
  
  return(list(model = xgboost_model, importance = importance_matrix, best_params = best_params))
}

# Function to prepare and normalize the data, ensuring clean input
prepare_data <- function(data, time_col, event_col, time_threshold) {
  valid_indices <- data[[time_col]] > 0
  
  # Censor observations beyond the threshold and normalize
  filtered_data <- data[valid_indices, ]
  filtered_data[[event_col]] <- ifelse(filtered_data[[time_col]] > time_threshold, 0, filtered_data[[event_col]])
  
  # Normalize numeric predictor variables
  normalized_data <- filtered_data %>%
    mutate(across(where(is.numeric), ~ normalize_data(.)))
  
  return(normalized_data)
}

# Function to evaluate the XGBoost model with metrics and bootstrapping for confidence intervals
evaluate_xgboost <- function(xgboost_model, X_test_data, y_test_data, time_test_data, train_column_names, n_bootstrap = 3000) {
  
  # Ensure the test data has the same columns as the training data
  X_test_data <- X_test_data[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for testing
  dtest <- xgb.DMatrix(data = as.matrix(X_test_data))
  
  # Predict risk scores
  risk_scores <- predict(xgboost_model, newdata = dtest)
  
  # Calculate Harrell's C-statistic (concordance index)
  survival_object <- Surv(time_test_data, y_test_data)
  c_stat <- rcorr.cens(risk_scores, survival_object)["C Index"]
  
  # Bootstrapping AUC to get confidence intervals
  auc_bootstrap <- boot(data = data.frame(y_test_data, risk_scores), 
                        statistic = function(data, indices) {
                          auc(roc(data[indices, 1], data[indices, 2]))
                        }, 
                        R = n_bootstrap)
  auc_ci <- boot.ci(auc_bootstrap, type = "perc")
  
  auc_value <- auc(roc(y_test_data, risk_scores))
  
  return(list(c_stat = c_stat, auc = auc_value, auc_ci = auc_ci))
}

# Measure the start time
start_time <- Sys.time()

# Data preparation for 2-year and 5-year predictions
two_years_in_days <- 2 * 365.25
five_years_in_days <- 5 * 365.25


# Prepare training data
train_data_2yr <- prepare_data(train_data, "time_to_event_2yr", "event_2yr", two_years_in_days)

# Exclude the lab columns from the data
train_data_2yr <- train_data_2yr[, !(colnames(train_data_2yr) %in% labs_columns)]

X_train_2yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - 1, data = train_data_2yr)
time_train_2yr <- train_data_2yr$time_to_event_2yr
event_status_2yr <- train_data_2yr$event_2yr

train_data_5yr <- prepare_data(train_data, "time_to_event_5yr", "event_5yr", five_years_in_days)

# Exclude the lab columns from the data
train_data_5yr <- train_data_5yr[, !(colnames(train_data_5yr) %in% labs_columns)]

X_train_5yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race  - 1, data = train_data_5yr)
time_train_5yr <- train_data_5yr$time_to_event_5yr
event_status_5yr <- train_data_5yr$event_5yr

# Train models
result_2yr <- fit_xgboost_and_display(X_train_2yr, time_train_2yr, event_status_2yr, "2-Year", early_stopping_rounds = 5, nfold = 3)
xgboost_model_2yr <- result_2yr$model

result_5yr <- fit_xgboost_and_display(X_train_5yr, time_train_5yr, event_status_5yr, "5-Year", early_stopping_rounds = 5, nfold = 3)
xgboost_model_5yr <- result_5yr$model

# Measure the end time and calculate total runtime
end_time <- Sys.time()
total_runtime <- end_time - start_time
cat("Total runtime: ", total_runtime, "\n")

# Function to perform bootstrapping to calculate AUC confidence intervals
bootstrap_auc <- function(xgboost_model, X_test, y_test, train_column_names, n_bootstrap = 3000) {
  # Ensure test data has the same columns as training data
  X_test <- X_test[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for the test data
  dtest <- xgb.DMatrix(data = as.matrix(X_test))
  
  # Define a function to calculate the AUC for a bootstrapped sample
  auc_bootstrap <- function(data, indices) {
    # Subset the data using the provided indices
    y_test_sample <- data[indices, 1]
    predictions_sample <- predict(xgboost_model, newdata = dtest)[indices]
    
    # Calculate the AUC for the sample
    auc_value <- auc(roc(y_test_sample, predictions_sample))
    return(auc_value)
  }
  
  # Perform bootstrapping
  boot_results <- boot(data = data.frame(y_test, predict(xgboost_model, newdata = dtest)), 
                       statistic = auc_bootstrap, R = n_bootstrap)
  
  # Calculate the 95% confidence interval for the AUC
  ci <- boot.ci(boot_results, type = "perc")
  
  # Extract the mean AUC and the confidence interval limits
  auc_mean <- mean(boot_results$t)
  auc_ci_lower <- ci$perc[4]
  auc_ci_upper <- ci$perc[5]
  
  return(list(auc_mean = auc_mean, auc_ci_lower = auc_ci_lower, auc_ci_upper = auc_ci_upper))
}

# Function to perform evaluation with bootstrapping for different race subgroups
evaluate_with_bootstrapping <- function(race_group, X_test, y_test, time_test, xgboost_model, train_column_names, n_bootstrap = 3000) {
  if (!is.null(race_group)) {
    race_indices <- X_test[, race_group] == 1
    X_test <- X_test[race_indices, ]
    y_test <- y_test[race_indices]
    time_test <- time_test[race_indices]
  }
  
  bootstrap_result <- bootstrap_auc(xgboost_model, X_test, y_test, train_column_names, n_bootstrap)
  
  return(bootstrap_result)
}

# List to store results
results_2yr_bootstrap <- list()
results_5yr_bootstrap <- list()

# Evaluate for the entire population and subgroups for both 2-year and 5-year models
population_and_subgroups <- list(
  "2-Year All" = NULL, 
  "2-Year Black" = "raceBlack", 
  "2-Year White" = "raceWhite", 
  "2-Year Asian" = "raceAsian", 
  "5-Year All" = NULL, 
  "5-Year Black" = "raceBlack", 
  "5-Year White" = "raceWhite", 
  "5-Year Asian" = "raceAsian"
)

# Run bootstrapping for each group
for (name in names(population_and_subgroups)) {
  group <- population_and_subgroups[[name]]
  if (grepl("^2-Year", name)) {
    results_2yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_2yr, y_test_2yr, time_test_2yr, xgboost_model_2yr, colnames(X_train_2yr), n_bootstrap = 3000)
  } else {
    results_5yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_5yr, y_test_5yr, time_test_5yr, xgboost_model_5yr, colnames(X_train_5yr), n_bootstrap = 3000)
  }
}

# Combine results into a data frame for easy reporting
results_table_bootstrap <- data.frame(
  Model = c(names(results_2yr_bootstrap), names(results_5yr_bootstrap)),
  AUC_Mean = c(sapply(results_2yr_bootstrap, function(x) x$auc_mean), sapply(results_5yr_bootstrap, function(x) x$auc_mean)),
  AUC_CI_Lower = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_lower), sapply(results_5yr_bootstrap, function(x) x$auc_ci_lower)),
  AUC_CI_Upper = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_upper), sapply(results_5yr_bootstrap, function(x) x$auc_ci_upper))
)

# Print the results table
print(results_table_bootstrap)

# Create a forest plot to display AUC with 95% confidence intervals, excluding "All" categories
results_table_bootstrap_filtered <- results_table_bootstrap %>%
  filter(!grepl("All", Model))

forest_plot <- ggplot(results_table_bootstrap_filtered, aes(x = AUC_Mean, y = Model)) +
  geom_point(size = 3, color = "black") +  # Add points for the mean AUC
  geom_errorbarh(aes(xmin = AUC_CI_Lower, xmax = AUC_CI_Upper), height = 0.2, size = 1) +  # Add horizontal error bars
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 0.8) +  # Add a vertical dashed line at AUC = 0.5
  labs(title = "Forest Plot of AUC with 95% Confidence Intervals for 2-Year and 5-Year Models",
       x = "Area Under the Curve (AUC)", y = "Model") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title.x = element_text(size = 16, face = "bold"),
    axis.title.y = element_text(size = 16, face = "bold"),
    axis.text.y = element_text(size = 14),  
    axis.text.x = element_text(size = 14),  
    panel.grid.major = element_blank(),  
    panel.grid.minor = element_blank()
  ) +
  coord_cartesian(xlim = c(0, 1))  

# Display the plot
print(forest_plot)

# Stop parallel processing
stopImplicitCluster()

# Save the plot as a high-resolution PNG file
ggsave("Labfree_withrace_Forest_Plot_AUC_95CI_No_All_With_Reference.png", plot = forest_plot, dpi = 300, width = 10, height = 6)

# Optionally, save as a PDF for high-quality printing
ggsave("Labfree_withrace_Forest_Plot_AUC_95CI_No_All_With_Reference.pdf", plot = forest_plot, width = 10, height = 6)

```

## Lab_free model- without race:

```{r}
# Load necessary libraries
library(xgboost)
library(pROC)
library(Hmisc)  # For Harrell's C-statistic
library(survival)
library(doParallel)
library(ggplot2)
library(dplyr)
library(caret)  # For cross-validation and parameter tuning

# Set up parallel backend for faster execution
cores <- detectCores() - 1
registerDoParallel(cores)

# Set random seed for reproducibility
set.seed(123)

# Define lab columns to exclude
labs_columns <- c(
  "Creatinine..Mass.volume..in.Body.fluid", 
  "Erythrocyte.distribution.width..Ratio..by.Automated.count", 
  "Ferritin..Mass.volume..in.Serum.or.Plasma", 
  "Hemoglobin.A1c.Hemoglobin.total.in.Blood", 
  "Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay", 
  "Iron..Mass.volume..in.Serum.or.Plasma", 
  "Iron.saturation..Mass.Fraction..in.Serum.or.Plasma", 
  "Parathyrin.intact..Mass.volume..in.Serum.or.Plasma", 
  "Protein..Mass.volume..in.Urine", 
  "Triglyceride..Mass.volume..in.Serum.or.Plasma", 
  "eGFR_ckd_epi_2021", 
  "serum_creatinine",
  "raceBlack", "raceWhite", "raceAsian"
)

# Define a robust but efficient hyperparameter grid for tuning
param_grid <- expand.grid(
  max_depth = c(4, 6),  
  min_child_weight = c(1, 2),  
  gamma = c(0, 0.2),  
  eta = c(0.05, 0.1),  
  subsample = c(0.8, 0.9),  
  colsample_bytree = c(0.8, 1),  
  alpha = c(0, 0.5),  
  lambda = c(1, 1.2),  
  n_estimators = c(300, 500)  
)

# Normalization function (log(x + 1)) to transform skewed data
normalize_data <- function(df) {
  return(log(df + 1))
}

# Optimal Parameters for XGBoost Cox model
optimal_params <- list(
  max_depth = 6,
  min_child_weight = 2,
  gamma = 0.5,
  eta = 0.1,                    # Learning rate
  subsample = 1,                # Full sampling
  colsample_bytree = 1,         # Full column sampling
  objective = "survival:cox",   # Cox proportional hazards objective
  eval_metric = "cox-nloglik",  # Evaluation metric for Cox models
  nthread = cores               # Number of threads to use
)

# Function to fit XGBoost model and display variable importance
fit_xgboost_and_display <- function(X_data, time_to_event, event_status, title_prefix, params, nrounds) {
  
  # Convert the data to DMatrix, which is optimized for XGBoost
  dtrain <- xgb.DMatrix(data = as.matrix(X_data), label = time_to_event)
  
  # Set base_margin to indicate censoring (1 = event occurred, 0 = censored)
  setinfo(dtrain, "base_margin", event_status)
  
  # Train the XGBoost model with the provided parameters and number of rounds
  xgboost_model <- xgboost(
    params = params, 
    data = dtrain, 
    nrounds = nrounds,  # Use nrounds to control the number of boosting rounds
    verbose = 0  # Suppress output
  )
  
  # Get the feature importance
  importance_matrix <- xgb.importance(model = xgboost_model)
  
  # Display the selected variables and their importance
  print(paste("Selected Variables by XGBoost for", title_prefix, "Prediction:"))
  print(importance_matrix)
  
  # Create a variable importance plot
  p <- ggplot(importance_matrix, aes(x = reorder(Feature, Gain), y = Gain)) +
    geom_bar(stat = "identity") +
    coord_flip() +  # Flip the plot to make it horizontal
    labs(title = paste(title_prefix, "Variable Importance Plot (XGBoost)"), 
         x = "Variables", 
         y = "Importance (Gain)") +
    theme_minimal()
  
  # Display the plot
  print(p)
  
  # Return the final model and feature importance
  return(list(model = xgboost_model, importance = importance_matrix))
}

# Function to prepare and normalize the data
prepare_data <- function(data, time_col, event_col, time_threshold, labs_columns) {
  # Filter out rows with non-positive time_to_event
  valid_indices <- data[[time_col]] > 0
  
  # Filter only rows with positive time to event
  filtered_data <- data[valid_indices, ]
  
  # Censor observations that exceed the time threshold (2 years or 5 years)
  filtered_data[[event_col]] <- ifelse(filtered_data[[time_col]] > time_threshold, 0, filtered_data[[event_col]])
  
  # Normalize the predictor variables with log(x + 1)
  normalized_data <- filtered_data %>%
    mutate(across(where(is.numeric), ~ normalize_data(.)))
  
  # Remove lab columns from the dataset
  normalized_data <- normalized_data[, !colnames(normalized_data) %in% labs_columns]
  
  return(normalized_data)
}

# Function to ensure test data includes all columns present in the training data
clean_test_data <- function(X_test, time_test, event_status, train_colnames) {
  
  # Ensure that the test data includes only observations with positive time-to-event
  valid_indices <- time_test > 0
  X_test_cleaned <- X_test[valid_indices, , drop = FALSE]
  time_test_cleaned <- time_test[valid_indices]
  event_status_cleaned <- event_status[valid_indices]
  
  # Remove columns not present in the training set (e.g., lab-related columns)
  X_test_cleaned <- X_test_cleaned[, colnames(X_test_cleaned) %in% train_colnames, drop = FALSE]
  
  # Add missing columns (if any) from the training set, initializing with 0s
  missing_cols <- setdiff(train_colnames, colnames(X_test_cleaned))
  if (length(missing_cols) > 0) {
    for (col in missing_cols) {
      X_test_cleaned[[col]] <- 0  # Add missing columns with 0s
    }
  }
  
  # Ensure the columns are in the same order as the training data
  X_test_cleaned <- X_test_cleaned[, train_colnames, drop = FALSE]
  
  return(list(X_test = X_test_cleaned, time_test = time_test_cleaned, event_status = event_status_cleaned))
}

# Function to evaluate the XGBoost model on the test data
evaluate_xgboost <- function(xgboost_model, X_test_data, y_test_data, time_test_data, train_column_names) {
  
  # Ensure the test data has the same columns as the training data
  X_test_data <- X_test_data[, train_column_names, drop = FALSE]
  
  # Set feature names for the test data
  dtest <- xgb.DMatrix(data = as.matrix(X_test_data))
  colnames(dtest) <- train_column_names  # Explicitly set column names
  
  # Predict risk scores using the XGBoost model
  risk_scores <- predict(xgboost_model, newdata = dtest)
  
  # Calculate Harrell's C-statistic using time-to-event data
  survival_object <- Surv(time_test_data, y_test_data)
  
  # Calculate Harrell's C-statistic (concordance index)
  c_stat <- rcorr.cens(risk_scores, survival_object)["C Index"]
  
  # Calculate AUC using the ROC curve
  roc_curve <- roc(y_test_data, risk_scores)
  auc_value <- auc(roc_curve)
  
  return(list(c_stat = c_stat, auc = auc_value))
}

# Step 1: Data preparation for 2-year and 5-year predictions
two_years_in_days <- 2 * 365.25
five_years_in_days <- 5 * 365.25

# Prepare the training data for 2-year prediction, excluding lab columns
train_data_2yr <- prepare_data(train_data, "time_to_event_2yr", "event_2yr", two_years_in_days, labs_columns)
X_train_2yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - 1, 
                            data = train_data_2yr)
time_train_2yr <- train_data_2yr$time_to_event_2yr
event_status_2yr <- train_data_2yr$event_2yr

# Prepare the training data for 5-year prediction, excluding lab columns
train_data_5yr <- prepare_data(train_data, "time_to_event_5yr", "event_5yr", five_years_in_days, labs_columns)
X_train_5yr <- model.matrix(~ . - event_2yr - event_5yr - time_to_event_2yr - time_to_event_5yr - disease_status - person_id - race - 1, 
                            data = train_data_5yr)
time_train_5yr <- train_data_5yr$time_to_event_5yr
event_status_5yr <- train_data_5yr$event_5yr

# Step 2: Train XGBoost models for 2-year and 5-year predictions using the optimal parameters

# Train and display results for the 2-year XGBoost model
result_2yr <- fit_xgboost_and_display(X_train_2yr, time_train_2yr, event_status_2yr, "2-Year", optimal_params, nrounds = 100)
xgboost_model_2yr <- result_2yr$model
importance_2yr <- result_2yr$importance  # Variable importance for 2-year model

# Train and display results for the 5-year XGBoost model
result_5yr <- fit_xgboost_and_display(X_train_5yr, time_train_5yr, event_status_5yr, "5-Year", optimal_params, nrounds = 100)
xgboost_model_5yr <- result_5yr$model
importance_5yr <- result_5yr$importance  # Variable importance for 5-year model

# Step 3: Display the final parameters
print("Final Hyperparameters for the model:")
print(optimal_params)

# Step 4: Stop parallel processing
stopImplicitCluster()

library(dplyr)
library(pROC)
library(boot)
library(ggplot2)

# Function to perform bootstrapping to calculate AUC confidence intervals
bootstrap_auc <- function(xgboost_model, X_test, y_test, train_column_names, n_bootstrap = 3000) {
  # Ensure test data has the same columns as training data
  X_test <- X_test[, train_column_names, drop = FALSE]
  
  # Create a DMatrix for the test data
  dtest <- xgb.DMatrix(data = as.matrix(X_test))
  
  # Define a function to calculate the AUC for a bootstrapped sample
  auc_bootstrap <- function(data, indices) {
    # Subset the data using the provided indices
    y_test_sample <- data[indices, 1]
    predictions_sample <- predict(xgboost_model, newdata = dtest)[indices]
    
    # Calculate the AUC for the sample
    auc_value <- auc(roc(y_test_sample, predictions_sample))
    return(auc_value)
  }
  
  # Perform bootstrapping
  boot_results <- boot(data = data.frame(y_test, predict(xgboost_model, newdata = dtest)), 
                       statistic = auc_bootstrap, R = n_bootstrap)
  
  # Calculate the 95% confidence interval for the AUC
  ci <- boot.ci(boot_results, type = "perc")
  
  # Extract the mean AUC and the confidence interval limits
  auc_mean <- mean(boot_results$t)
  auc_ci_lower <- ci$perc[4]
  auc_ci_upper <- ci$perc[5]
  
  return(list(auc_mean = auc_mean, auc_ci_lower = auc_ci_lower, auc_ci_upper = auc_ci_upper))
}

# Perform evaluation with bootstrapping for the full population and subgroups
evaluate_with_bootstrapping <- function(race_group, X_test, y_test, time_test, xgboost_model, train_column_names, n_bootstrap = 3000) {
  if (!is.null(race_group)) {
    race_indices <- X_test[, race_group] == 1
    X_test <- X_test[race_indices, ]
    y_test <- y_test[race_indices]
    time_test <- time_test[race_indices]
  }
  
  bootstrap_result <- bootstrap_auc(xgboost_model, X_test, y_test, train_column_names, n_bootstrap)
  
  return(bootstrap_result)
}

# List to store results
results_2yr_bootstrap <- list()
results_5yr_bootstrap <- list()

# Evaluate for the entire population and subgroups for both 2-year and 5-year models
population_and_subgroups <- list(
  "2-Year All" = NULL, 
  "2-Year Black" = "raceBlack", 
  "2-Year White" = "raceWhite", 
  "2-Year Asian" = "raceAsian", 
  "5-Year All" = NULL, 
  "5-Year Black" = "raceBlack", 
  "5-Year White" = "raceWhite", 
  "5-Year Asian" = "raceAsian"
)

# Run bootstrapping for each group
for (name in names(population_and_subgroups)) {
  group <- population_and_subgroups[[name]]
  if (grepl("^2-Year", name)) {
    results_2yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_2yr, y_test_2yr, time_test_2yr, xgboost_model_2yr, colnames(X_train_2yr), n_bootstrap = 3000)
  } else {
    results_5yr_bootstrap[[name]] <- evaluate_with_bootstrapping(group, X_test_5yr, y_test_5yr, time_test_5yr, xgboost_model_5yr, colnames(X_train_5yr), n_bootstrap = 3000)
  }
}

# Combine results into a data frame for easy reporting
results_table_bootstrap <- data.frame(
  Model = c(names(results_2yr_bootstrap), names(results_5yr_bootstrap)),
  AUC_Mean = c(sapply(results_2yr_bootstrap, function(x) x$auc_mean), sapply(results_5yr_bootstrap, function(x) x$auc_mean)),
  AUC_CI_Lower = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_lower), sapply(results_5yr_bootstrap, function(x) x$auc_ci_lower)),
  AUC_CI_Upper = c(sapply(results_2yr_bootstrap, function(x) x$auc_ci_upper), sapply(results_5yr_bootstrap, function(x) x$auc_ci_upper))
)

# Print the results table
print(results_table_bootstrap)

library(ggplot2)

# Filter out "All" categories from the dataset
results_table_bootstrap_filtered <- results_table_bootstrap %>%
  filter(!grepl("All", Model))

# Create a forest plot to display AUC with 95% confidence intervals, excluding "All" categories
forest_plot <- ggplot(results_table_bootstrap_filtered, aes(x = AUC_Mean, y = Model)) +
  geom_point(size = 3, color = "black") +  # Add points for the mean AUC
  geom_errorbarh(aes(xmin = AUC_CI_Lower, xmax = AUC_CI_Upper), height = 0.2, size = 1) +  # Add horizontal error bars
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red", size = 0.8) +  # Add a vertical dashed line at AUC = 0.5
  labs(title = "Forest Plot of AUC with 95% Confidence Intervals for 2-Year and 5-Year Models",
       x = "Area Under the Curve (AUC)", y = "Model") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title.x = element_text(size = 16, face = "bold"),
    axis.title.y = element_text(size = 16, face = "bold"),
    axis.text.y = element_text(size = 14),  # Increase the y-axis text size for better readability
    axis.text.x = element_text(size = 14),  # Increase the x-axis text size for better readability
    panel.grid.major = element_blank(),  # Remove major grid lines for a cleaner look
    panel.grid.minor = element_blank()
  ) +
  coord_cartesian(xlim = c(0, 1))  # Set the x-axis limits to 0-1 for better interpretation

# Display the plot
print(forest_plot)

# Save the plot as a high-resolution PNG file
ggsave("Labfree_withoutrace_Forest_Plot_AUC_95CI_No_All_With_Reference.png", plot = forest_plot, dpi = 300, width = 10, height = 6)

# Optionally, save as a PDF for high-quality printing
ggsave("Labfree_withoutrace_Forest_Plot_AUC_95CI_No_All_With_Reference.pdf", plot = forest_plot, width = 10, height = 6)

```

```         
```

## 

# Cox Model

### MISSING DATA CHECK

Remove Features with count less than 10

```{r}
# Load necessary libraries
library(dplyr)
library(tidyr)

# Load dataset
filtered_person_with_summary <- read.csv("person_with_summary_inrange_indexdate_creatnine.csv")


# Step 1: Select and rename relevant columns
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(-age_reported,
         -Glomerular.filtration.rate.1.73.sq.M.predicted..Volume.Rate.Area..in.Serum..Plasma.or.Blood.by.Creatinine.based.formula..MDRD.,
         -Tobacco.smoking.status,
         -height,
         -weight,
         -gender) %>%
  rename(smoking = highest_smoking_status_rank)

# Step 2: Filter out non-numeric columns and pivot longer
person_long <- filtered_person_with_summary %>%
  select(person_id, disease_status, where(is.numeric)) %>%
  pivot_longer(
    cols = -c(person_id, disease_status),
    names_to = "variable",
    values_to = "value"
  ) %>%
  filter(!is.na(value) & value != 0)  # Remove rows where the value is NA or zero

# Step 3: Count occurrences of disease_status for each variable
status_counts <- person_long %>%
  group_by(variable, disease_status) %>%
  summarise(count = n_distinct(person_id), .groups = 'drop')

# Step 4: Pivot the summary table to a wide format
summary_wide <- status_counts %>%
  pivot_wider(
    names_from = disease_status,
    values_from = count,
    names_prefix = "disease_status_",
    values_fill = list(count = 0)
  )

# Step 5: Filter out variables that have less than a count of 10 for either disease_status_0 or disease_status_1
filtered_summary <- summary_wide %>%
  filter(disease_status_0 >= 10 & disease_status_1 >= 10)

# Step 6: Extract the variable names that passed the filter
remaining_variables <- filtered_summary$variable

# Step 7: Retain only the person_id, disease_status, race, sex_at_birth, ethnicity, and the remaining variables
filtered_person_with_summary <- filtered_person_with_summary %>%
  select(person_id, disease_status, race, sex_at_birth, ethnicity, all_of(remaining_variables))

# Step 8: Identify the dropped variables
all_variables <- names(select(filtered_person_with_summary, where(is.numeric)))
dropped_variables <- setdiff(all_variables, remaining_variables)

# Print the dropped variables if needed
#print(dropped_variables)

# View the updated column names
colnames(filtered_person_with_summary)

# Save the filtered_person_with_summary dataset as a .csv file
write.csv(filtered_person_with_summary, "my_dataframe.csv", row.names = FALSE)


```

### Data preprocessing

```{r}
library(dplyr)
library(knitr) # For kable to display tables nicely

# Load the dataset
my_dataframe <- read.csv("my_dataframe.csv")

# Filter `my_dataframe` to include only observations with a positive `time_to_event`
my_dataframe <- my_dataframe %>% 
  filter(time_to_event > 0)

# Define the columns to remove
col_remove <- c(
  'gender','person_id','date_of_birth','index_date','censored_date','event_date', 
  'age_reported','disease_date', 'Nephrectomy','Hemodialysis','censored_date',
  'event_date',"Acute.glomerulonephritis",
  "height", "weight", "Nephritic.syndrome", "age_reported", 
  "Peripheral.circulatory.disorder.due.to.type.1.diabetes.mellitus", 
  "Complication.of.renal.dialysis", "Membranous.glomerulonephritis", "doxercalciferol", 
  "midodrine", "Iron.saturation..Mass.Fraction..in.Serum.or.Plasma", 
  "Iron.binding.capacity..Mass.volume..in.Serum.or.Plasma", "highest_smoking_status_rank", 
  "Tobacco.smoking.status", "insulin.aspart..human", 
  "Ketoacidosis.due.to.type.1.diabetes.mellitus", "Systemic.lupus.erythematosus", 
  "Ferritin..Mass.volume..in.Serum.or.Plasma", "Hypertensive.heart.and.chronic.kidney.disease", 
  "eGFR_MDRD", "eGFR_ckd_epi_2009", 
  "Glomerular.filtration.rate.1.73.sq.M.predicted..Volume.Rate.Area..in.Serum..Plasma.or.Blood.by.Creatinine.based.formula..MDRD.", "Transplanted.kidney.present", "Acute.renal.failure.syndrome"
)

# Remove specified columns from my_dataframe
my_dataframe <- my_dataframe[, !(names(my_dataframe) %in% col_remove)]

# Check if `person_id` is available for merging; if not, use rownames
if (!"person_id" %in% colnames(my_dataframe)) {
  my_dataframe <- my_dataframe %>% mutate(person_id = row_number())
}

# Separate data by race for custom sampling
black_data <- my_dataframe %>% filter(race == "Black or African American")
white_data <- my_dataframe %>% filter(race == "White")
asian_data <- my_dataframe %>% filter(race == "Asian")

# Set seed for reproducibility
set.seed(123)

# Sample 70% of Black or African American and White for training data
black_train <- black_data %>% sample_frac(0.7)
white_train <- white_data %>% sample_frac(0.7)

# The remaining 30% of Black or African American and White for test data
black_test <- anti_join(black_data, black_train, by = "person_id")
white_test <- anti_join(white_data, white_train, by = "person_id")

# All Asian individuals go into the test set
asian_test <- asian_data

# Combine training data
train_data <- bind_rows(black_train, white_train) %>%
  mutate(raceAsian = 0)  # Add dummy variable raceAsian with 0 for all rows in train data

# Combine test data and add `raceAsian` column for consistency
test_data <- bind_rows(black_test, white_test, asian_test) %>%
  mutate(raceAsian = if_else(race == "Asian", 1, 0))

# Calculate race proportions for train and test sets, ensuring all races are represented
train_race_proportion <- prop.table(table(factor(train_data$race, levels = c("Black or African American", "White", "Asian")))) * 100
test_race_proportion <- prop.table(table(factor(test_data$race, levels = c("Black or African American", "White", "Asian")))) * 100

# Create a summary table for race proportions
race_proportion_table <- data.frame(
  Race = c("Black or African American", "White", "Asian"),
  Train_Proportion = round(as.numeric(train_race_proportion), 1),
  Test_Proportion = round(as.numeric(test_race_proportion), 1)
)

# Calculate dimensions for train and test sets
dimension_table <- data.frame(
  Set = c("Train", "Test"),
  Rows = c(nrow(train_data), nrow(test_data)),
  Columns = c(ncol(train_data), ncol(test_data))
)

# Display the tables
cat("Race Proportion Table:\n")
print(kable(race_proportion_table, format = "markdown"))

cat("\nDimension Table:\n")
print(kable(dimension_table, format = "markdown"))

```

### Variable selection: Lasso

```{r}
colnames(train_data)
# Load necessary libraries
library(survival)
library(ggplot2)
library(dplyr)

# Step 1: Define the formula for the Cox model using all available variables
# This assumes "time_to_event" is the time variable and "disease_status" as the event indicator.
# Adjust the formula by removing or modifying variable names if necessary.

# Define the lab-free variables as a vector of column names
cox_formula_lab_free <- c(
  "disease_status",
  "race",
  "sex_at_birth",
  "ethnicity",
  "Acidosis",
  "Acute.renal.failure.syndrome",
  "Anemia",
  "Anemia.in.chronic.kidney.disease",
  "Atherosclerosis.of.coronary.artery.without.angina.pectoris",
  "BMI",
  "Chronic.kidney.disease.stage.3",
  "Chronic.kidney.disease.stage.4",
  "Congestive.heart.failure",
  "Creatinine..Mass.volume..in.Body.fluid",
  "Diabetes.mellitus",
  "Disorder.of.kidney.and.or.ureter",
  "Disorder.of.muscle",
  "Erythrocyte.distribution.width..Ratio..by.Automated.count",
  "Essential.hypertension",
  "Gout",
  "Hemoglobin.A1c.Hemoglobin.total.in.Blood",
  "Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay",
  "Hyperkalemia",
  "Hypothyroidism",
  "Iron..Mass.volume..in.Serum.or.Plasma",
  "Iron.deficiency.anemia",
  "Parathyrin.intact..Mass.volume..in.Serum.or.Plasma",
  "Peripheral.vascular.disease",
  "Polyneuropathy.due.to.diabetes.mellitus",
  "Protein..Mass.volume..in.Urine",
  "Proteinuria",
  "Renal.disorder.due.to.type.2.diabetes.mellitus",
  "Systolic.blood.pressure",
  "Transplanted.kidney.present",
  "Triglyceride..Mass.volume..in.Serum.or.Plasma",
  "Type.2.diabetes.mellitus",
  "age_precise",
  "eGFR_ckd_epi_2021",
  "serum_creatinine",
  "smoking",
  "time_to_event",
  "person_id"
)


# # Define lab-free variables excluding lab-related variables
# cox_formula_lab_free <- c(
#   "disease_status",
#   "race",
#   "sex_at_birth",
#   "ethnicity",
#   "Acidosis",
#   "Acute.renal.failure.syndrome",
#   "Anemia",
#   "Anemia.in.chronic.kidney.disease",
#   "Atherosclerosis.of.coronary.artery.without.angina.pectoris",
#   "BMI",
#   "Chronic.kidney.disease.stage.3",
#   "Chronic.kidney.disease.stage.4",
#   "Congestive.heart.failure",
#   "Diabetes.mellitus",
#   "Disorder.of.kidney.and.or.ureter",
#   "Disorder.of.muscle",
#   "Essential.hypertension",
#   "Gout",
#   "Hypothyroidism",
#   "Iron.deficiency.anemia",
#   "Peripheral.vascular.disease",
#   "Polyneuropathy.due.to.diabetes.mellitus",
#   "Proteinuria",
#   "Renal.disorder.due.to.type.2.diabetes.mellitus",
#   "Systolic.blood.pressure",
#   "Transplanted.kidney.present",
#   "Type.2.diabetes.mellitus",
#   "age_precise",
#   "smoking",
#   "time_to_event",
#   "person_id",
#   "raceAsian"
# )


# Load necessary libraries
library(survival)
library(glmnet)
library(dplyr)
library(ggplot2)

# Step 1: Define lab-free formula and filter complete cases
cox_formula <- as.formula(paste("~", paste(cox_formula_lab_free, collapse = " + ")))

# Filter the data to include only rows with complete cases for relevant variables
relevant_columns <- c("time_to_event", "disease_status", cox_formula_lab_free)
train_data_filtered <- train_data %>%
  select(all_of(relevant_columns)) %>%
  drop_na()

# Step 2: Restrict the time-to-event to 5 years (1825 days) to reduce censoring
train_data_filtered <- train_data_filtered %>%
  filter(time_to_event <= 1825)

# Re-prepare X and y after filtering
X <- model.matrix(cox_formula, data = train_data_filtered)[, -1]  # Remove intercept column
y <- Surv(train_data_filtered$time_to_event, train_data_filtered$disease_status)  # Define survival response

# Step 3: Use cross-validation with a higher starting lambda and Elastic Net (alpha = 0.5)
tryCatch({
  cv_fit <- cv.glmnet(X, y, family = "cox", alpha = 0, lambda = seq(0.1, 0.001, length = 100), maxit = 1e6)
  best_lambda <- cv_fit$lambda.min
  
  # Step 4: Refit the penalized Cox model with the optimal lambda from cross-validation
  penalized_cox_model <- glmnet(X, y, family = "cox", alpha = 0, lambda = best_lambda, maxit = 1e6)

  # Step 5: Extract non-zero coefficients
  non_zero_coefs <- coef(penalized_cox_model, s = best_lambda)
  non_zero_coefs <- non_zero_coefs[non_zero_coefs != 0]

  # Check if there are any non-zero coefficients before proceeding
  if (length(non_zero_coefs) > 0) {
    # Create a data frame of variable importance
    var_importance <- data.frame(
      Variable = rownames(non_zero_coefs),
      Importance = abs(as.vector(non_zero_coefs))  # Convert to vector for plotting
    ) %>%
      arrange(desc(Importance))

    # Step 6: Plot Variable Importance
    ggplot(var_importance, aes(x = reorder(Variable, Importance), y = Importance)) +
      geom_bar(stat = "identity", fill = "steelblue") +
      coord_flip() +
      labs(title = "Variable Importance in Penalized Cox Model (Elastic Net)", x = "Variables", y = "Absolute Coefficient Estimate") +
      theme_minimal()
  } else {
    cat("No non-zero coefficients were found. Consider further adjusting lambda or simplifying the model.\n")
  }
}, error = function(e) {
  cat("Elastic Net failed. Trying Ridge Regression as an alternative.\n")

  # Step 3 (Alternative): Ridge regression if Elastic Net fails
  penalized_cox_model <- glmnet(X, y, family = "cox", alpha = 0, maxit = 1e6)

  # Extract non-zero coefficients for Ridge
  non_zero_coefs <- coef(penalized_cox_model, s = 0.1)
  non_zero_coefs <- non_zero_coefs[non_zero_coefs != 0]

  # Check if there are any non-zero coefficients before proceeding
  if (length(non_zero_coefs) > 0) {
    var_importance <- data.frame(
      Variable = rownames(non_zero_coefs),
      Importance = abs(as.vector(non_zero_coefs))
    ) %>%
      arrange(desc(Importance))

    ggplot(var_importance, aes(x = reorder(Variable, Importance), y = Importance)) +
      geom_bar(stat = "identity", fill = "steelblue") +
      coord_flip() +
      labs(title = "Variable Importance in Penalized Cox Model (Ridge Regression)", x = "Variables", y = "Absolute Coefficient Estimate") +
      theme_minimal()
  } else {
    cat("No non-zero coefficients were found in Ridge model. Further adjustments may be necessary.\n")
  }
})

```

### One variable cox

```{r}
# Load necessary libraries
library(dplyr)
library(survival)

# Replace all NA values in train_data with 0
train_data[is.na(train_data)] <- 0

# Verify that there are no NA values left in the dataset
print(sum(is.na(train_data)))  # This should print 0 if all NA values are replaced

# Identify predictor variables (excluding outcome and ID)
predictor_vars <- setdiff(names(train_data), c("time_to_event", "disease_status", "person_id"))

# Convert numeric variables to log(x + 1) and binary variables to factors
train_data <- train_data %>%
  mutate(across(all_of(predictor_vars), ~ {
    if (is.numeric(.)) {
      log(. + 1)  # Apply log(x + 1) transformation for numeric predictors
    } else if (n_distinct(.) == 2) {
      as.factor(.)  # Convert binary variables to factors
    } else {
      .  # Leave other types as is
    }
  }))

# Initialize an empty data frame to store results
cox_results <- data.frame(Variable = character(),
                          p_value = numeric(),
                          Significance = character(),
                          stringsAsFactors = FALSE)

# Run Cox PH model for each variable individually
for (var in predictor_vars) {
  # Check that the variable is either numeric or factor
  if (is.numeric(train_data[[var]]) || is.factor(train_data[[var]])) {
    # Fit Cox model with one variable at a time
    cox_model <- coxph(Surv(time_to_event, disease_status) ~ get(var), data = train_data)
    
    # Get the p-value
    p_val <- summary(cox_model)$coefficients[,"Pr(>|z|)"]
    
    # Check if p-value < 0.25 and mark it with an asterisk if true
    signif <- ifelse(p_val < 0.25, "*", "")
    
    # Append results to the results data frame
    cox_results <- rbind(cox_results, data.frame(Variable = var, 
                                                 p_value = p_val, 
                                                 Significance = signif))
  } else {
    message(paste("Skipping variable:", var, "- not numeric or factor."))
  }
}

# Arrange results by p-value and print the most significant first
cox_results <- cox_results %>% arrange(p_value)

# Print the sorted results table with most significant variables first
print(cox_results)

```

### Model fitting on 70% of data

```{r}
# Complete case
my_dataframe <- train_data
colnames(train_data)

# Assuming `outcome` column has 1 for cases and 0 for controls
case_control_counts <- train_data %>%
  group_by(race, disease_status) %>%
  summarise(count = n()) %>%
  ungroup()

# Print the counts
print(case_control_counts)


# Load necessary libraries
library(dplyr)
library(survival)
library(rms)
library(Hmisc)
library(pec)
library(tibble)  # for rownames_to_column


# Step 1: Define the truncation year and threshold
stop_year <- 5  # Truncation at year 5
threshold <- 60  # Include observations with eGFR_ckd_epi_2021 < threshold

# Step 2: Data preparation
stop_time <- stop_year * 365.25
df_complete <- my_dataframe

# Replace NA values in time_to_event with stop_time
df_complete$time_to_event[is.na(df_complete$time_to_event)] <- stop_time

# Create time_to_event_2 and outcome variables
df_complete <- df_complete %>%
  mutate(
    time_to_event_2 = ifelse(time_to_event <= stop_time, time_to_event, stop_time),
    outcome = ifelse(disease_status == 1 & time_to_event <= stop_time, 1, 0)
  )


# Step 3: Filter and select relevant columns
df_filtered <- df_complete %>%
  filter(eGFR_ckd_epi_2021 < threshold) %>%
  dplyr::select(
    race,
    sex_at_birth,
    ethnicity,
    Acidosis,
    Anemia,
    Anemia.in.chronic.kidney.disease,
    Atherosclerosis.of.coronary.artery.without.angina.pectoris,
    BMI,
    Chronic.kidney.disease.stage.3,
    Chronic.kidney.disease.stage.4,
    Congestive.heart.failure,
    Creatinine..Mass.volume..in.Body.fluid,
    Diabetes.mellitus,
    Disorder.of.kidney.and.or.ureter,
    Disorder.of.muscle,
    Erythrocyte.distribution.width..Ratio..by.Automated.count,
    Essential.hypertension,
    Gout,
    Hemoglobin.A1c.Hemoglobin.total.in.Blood,
    Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay,
    Hyperkalemia,
    Hypothyroidism,
    Iron..Mass.volume..in.Serum.or.Plasma,
    Iron.deficiency.anemia,
    Parathyrin.intact..Mass.volume..in.Serum.or.Plasma,
    Peripheral.vascular.disease,
    Polyneuropathy.due.to.diabetes.mellitus,
    Protein..Mass.volume..in.Urine,
    Proteinuria,
    Renal.disorder.due.to.type.2.diabetes.mellitus,
    Systolic.blood.pressure,
    Triglyceride..Mass.volume..in.Serum.or.Plasma,
    Type.2.diabetes.mellitus,
    age_precise,
    eGFR_ckd_epi_2021,
    serum_creatinine,
    smoking,
    time_to_event_2,
    outcome
  )


# Step 4: Split data by race
# Source group: Both Black or African American and White individuals
dat_src <- df_filtered %>% filter(race %in% c('Black or African American', 'White'))

# Target group 1: Black or African American individuals
dat_tar_black <- df_filtered %>% filter(race == 'Black or African American')

# Target group 2: White individuals
dat_tar_white <- df_filtered %>% filter(race == 'White')

# Target group 3: Asian individuals
dat_tar_asian <- df_filtered %>% filter(race == 'Asian')

# Prepare data for model fitting
prepare_data_for_model <- function(data) {
  y <- data$outcome
  x <- data.matrix(data %>% dplyr::select(eGFR_ckd_epi_2021, BMI, age_precise))
  # Apply log(x+1) normalization
  x <- scale(log(x + 1))
  list(y = y, x = x)
}

# Prepare source and target datasets
source_data <- prepare_data_for_model(dat_src)
target_data_black <- prepare_data_for_model(dat_tar_black)
target_data_white <- prepare_data_for_model(dat_tar_white)
target_data_asian <- prepare_data_for_model(dat_tar_asian)


# Set up the datadist object for the predictor variables in dat_src
dd <- datadist(dat_src)  # Create datadist for predictor variables
options(datadist = "dd") # Set the datadist option for rms functions


# Step 5: Cox model fitting for source and target groups
cox_s <- rms::cph(Surv(time_to_event_2, outcome) ~ sex_at_birth + BMI + age_precise, data = dat_src, x = TRUE, y = TRUE, surv = TRUE)

# Step 6: Predictions and evaluation for each target group
time_test <- seq(0, 1.5, 0.01)
surv_s <- predictSurvProb(cox_s, newdata = dat_src, times = time_test)
surv_t_black <- predictSurvProb(cox_s, newdata = dat_tar_black, times = time_test)
surv_t_white <- predictSurvProb(cox_s, newdata = dat_tar_white, times = time_test)
surv_t_asian <- predictSurvProb(cox_s, newdata = dat_tar_asian, times = time_test)

# Evaluation using C-index and Integrated Brier Score (IBS) for each group
C_index <- c(
  Black = 1 - rcorr.cens(exp(as.matrix(dat_tar_black[, c("eGFR_ckd_epi_2021", "BMI", "age_precise")]) %*% coef(cox_s)), Surv(dat_tar_black$time_to_event_2, dat_tar_black$outcome))['C Index'],
  White = 1 - rcorr.cens(exp(as.matrix(dat_tar_white[, c("eGFR_ckd_epi_2021", "BMI", "age_precise")]) %*% coef(cox_s)), Surv(dat_tar_white$time_to_event_2, dat_tar_white$outcome))['C Index'],
  Asian = 1 - rcorr.cens(exp(as.matrix(dat_tar_asian[, c("eGFR_ckd_epi_2021", "BMI", "age_precise")]) %*% coef(cox_s)), Surv(dat_tar_asian$time_to_event_2, dat_tar_asian$outcome))['C Index']
)


# Step 7: Create results dataframe for each race
results <- data.frame(Group = c('Black or African American', 'White', 'Asian'), C_index = C_index)
print(results)

# Construct the Cox model equation as a string
cox_equation <- paste0("h(t) = h0(t) * exp(", 
                       paste(names(coef(cox_s)), round(coef(cox_s), 4), sep = " * ", collapse = " + "), 
                       ")")

# Print the Cox model equation
cat("Cox Model Equation:\n", cox_equation, "\n")


# Generate the summary of the Cox model
cox_summary <- summary(cox_s)
print(cox_summary)


# Assuming you've already loaded necessary libraries and fit the model
# Extract coefficients from the Cox model
coef_values <- abs(coef(cox_s))
var_importance <- data.frame(
  Variable = names(coef_values),
  Importance = coef_values
)

# Sort by importance (largest first)
var_importance <- var_importance %>%
  arrange(desc(Importance))

# Plot Variable Importance
library(ggplot2)
ggplot(var_importance, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Variable Importance in Cox Model", x = "Variables", y = "Absolute Coefficient Estimate")


# Test the proportional hazards assumption
# Convert rms::cph model to survival::coxph to use cox.zph
cox_s_coxph <- coxph(Surv(time_to_event_2, outcome) ~ eGFR_ckd_epi_2021 + BMI + age_precise, data = dat_src)

# Perform the proportional hazards test
ph_test <- cox.zph(cox_s_coxph)

# Extract p-values from the test and create a data frame with "Holds" or "Violated" labels
ph_results <- as.data.frame(ph_test$table[, "p"])
colnames(ph_results) <- "p_value"
ph_results$Assumption <- ifelse(ph_results$p_value < 0.05, "Violated", "Holds")

# Add variable names as a column and clean up the table
ph_results <- ph_results %>%
  rownames_to_column("Variable") %>%
  select(Variable, p_value, Assumption)

# Print the results
print(ph_results)

# Plot the Schoenfeld residuals to visually inspect proportionality
#plot(ph_test)
# Clear datadist option after you are done
options(datadist = NULL)


# The p-value for each covariate tests the null hypothesis that
# there is no time-dependent effect. A small p-value (<0.05)
# suggests that the effect of the covariate may change over time.

# 2. Plot Schoenfeld residuals to visualize time interaction for each covariate
plot(ph_test)

# 3. Interpret the results:
# - If a variable shows a significant p-value (typically <0.05), this indicates
#   that the effect of that variable on the hazard rate may change over time,
#   violating the proportional hazards assumption.
# - A non-significant p-value suggests "No Time Interaction," meaning
#   the variable's effect remains proportional over time.
```

### Evalution on 30% of data

```{r}

# Complete case
my_dataframe <- test_data

# # Assuming `outcome` column has 1 for cases and 0 for controls
# case_control_counts <- test_data %>%
#   group_by(race, disease_status) %>%
#   summarise(count = n()) %>%
#   ungroup()
# 
# # Print the counts
# print(case_control_counts)

# Load necessary libraries
library(dplyr)
library(survival)
library(rms)
library(Hmisc)
library(pec)

# Step 1: Define the truncation year and threshold
stop_year <- 5  # Truncation at year 5
threshold <- 300  # Include observations with eGFR_ckd_epi_2021 < threshold

# Step 2: Data preparation
stop_time <- stop_year * 365.25
df_complete <- my_dataframe

# Replace NA values in time_to_event with stop_time
df_complete$time_to_event[is.na(df_complete$time_to_event)] <- stop_time

# Create time_to_event_2 and outcome variables
df_complete <- df_complete %>%
  mutate(
    time_to_event_2 = ifelse(time_to_event <= stop_time, time_to_event, stop_time),
    outcome = ifelse(disease_status == 1 & time_to_event <= stop_time, 1, 0)
  )

# Step 3: Filter and select relevant columns
df_filtered <- df_complete %>%
  filter(eGFR_ckd_epi_2021 < threshold) %>%
  dplyr::select(
    race,
    sex_at_birth,
    ethnicity,
    Acidosis,
    Anemia,
    Anemia.in.chronic.kidney.disease,
    Atherosclerosis.of.coronary.artery.without.angina.pectoris,
    BMI,
    Chronic.kidney.disease.stage.3,
    Chronic.kidney.disease.stage.4,
    Congestive.heart.failure,
    Creatinine..Mass.volume..in.Body.fluid,
    Diabetes.mellitus,
    Disorder.of.kidney.and.or.ureter,
    Disorder.of.muscle,
    Erythrocyte.distribution.width..Ratio..by.Automated.count,
    Essential.hypertension,
    Gout,
    Hemoglobin.A1c.Hemoglobin.total.in.Blood,
    Hepatitis.B.virus.surface.Ag..Presence..in.Serum.or.Plasma.by.Immunoassay,
    Hyperkalemia,
    Hypothyroidism,
    Iron..Mass.volume..in.Serum.or.Plasma,
    Iron.deficiency.anemia,
    Parathyrin.intact..Mass.volume..in.Serum.or.Plasma,
    Peripheral.vascular.disease,
    Polyneuropathy.due.to.diabetes.mellitus,
    Protein..Mass.volume..in.Urine,
    Proteinuria,
    Renal.disorder.due.to.type.2.diabetes.mellitus,
    Systolic.blood.pressure,
    Triglyceride..Mass.volume..in.Serum.or.Plasma,
    Type.2.diabetes.mellitus,
    age_precise,
    eGFR_ckd_epi_2021,
    serum_creatinine,
    smoking,
    time_to_event_2,
    outcome
  )

# Step 4: Split data by race
# Target group 1: Black or African American individuals
dat_tar_black <- df_filtered %>% filter(race == 'Black or African American')

# Target group 2: White individuals
dat_tar_white <- df_filtered %>% filter(race == 'White')

# Target group 3: Asian individuals
dat_tar_asian <- df_filtered %>% filter(race == 'Asian')

# Prepare source and target datasets
target_data_black <- prepare_data_for_model(dat_tar_black)
target_data_white <- prepare_data_for_model(dat_tar_white)
target_data_asian <- prepare_data_for_model(dat_tar_asian)


# Step 5: Predictions and evaluation for each target group
time_test <- seq(0, 1.5, 0.01)
surv_s <- predictSurvProb(cox_s, newdata = dat_src, times = time_test)
surv_t_black <- predictSurvProb(cox_s, newdata = dat_tar_black, times = time_test)
surv_t_white <- predictSurvProb(cox_s, newdata = dat_tar_white, times = time_test)
surv_t_asian <- predictSurvProb(cox_s, newdata = dat_tar_asian, times = time_test)

# Evaluation using C-index and Integrated Brier Score (IBS) for each group
C_index <- c(
  Black = 1 - rcorr.cens(exp(as.matrix(dat_tar_black[, c("eGFR_ckd_epi_2021", "BMI", "age_precise")]) %*% coef(cox_s)), Surv(dat_tar_black$time_to_event_2, dat_tar_black$outcome))['C Index'],
  White = 1 - rcorr.cens(exp(as.matrix(dat_tar_white[, c("eGFR_ckd_epi_2021", "BMI", "age_precise")]) %*% coef(cox_s)), Surv(dat_tar_white$time_to_event_2, dat_tar_white$outcome))['C Index'],
  Asian = 1 - rcorr.cens(exp(as.matrix(dat_tar_asian[, c("eGFR_ckd_epi_2021", "BMI", "age_precise")]) %*% coef(cox_s)), Surv(dat_tar_asian$time_to_event_2, dat_tar_asian$outcome))['C Index']
)

# Step 6: Create results dataframe for each race
results <- data.frame(Group = c('Black or African American', 'White', 'Asian'), C_index = C_index)
print(results)
## output the variable importance

```
